"""
æ™ºèƒ½æ•°æ®åº“è¿ç§»å·¥å…· v2.0
- è‡ªåŠ¨æ£€æµ‹å­—æ®µ
- ç±»å‹è½¬æ¢å®¹é”™
- è‡ªåŠ¨åˆ›å»ºç¼ºå¤±è¡¨
- è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
"""
import asyncio
import time
from typing import Dict, List, Any, Optional
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy import text, inspect
from sqlalchemy.exc import SQLAlchemyError
from astrbot.api import logger  # ä½¿ç”¨ astrbot æ¡†æ¶çš„ logger

from ..models.orm import (
    Base,
    UserAffection,
    AffectionInteraction,
    UserConversationHistory,
    UserDiversity,
    Memory,
    MemoryEmbedding,
    MemorySummary,
    CompositePsychologicalState,
    PsychologicalStateComponent,
    PsychologicalStateHistory,
    UserSocialProfile,
    UserSocialRelationComponent,
    SocialRelationHistory,
    SocialRelationAnalysisResult,
    SocialNetworkNode,
    SocialNetworkEdge
)


class SmartDatabaseMigrator:
    """
    æ™ºèƒ½æ•°æ®åº“è¿ç§»å·¥å…·

    ç‰¹æ€§:
    1. è‡ªåŠ¨æ£€æµ‹æ—§è¡¨æ˜¯å¦å­˜åœ¨
    2. è‡ªåŠ¨åˆ›å»ºç¼ºå¤±çš„æ–°è¡¨
    3. æ™ºèƒ½å­—æ®µæ˜ å°„å’Œç±»å‹è½¬æ¢
    4. è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
    5. é€è¡Œå®¹é”™å¤„ç†
    """

    def __init__(self, db_url: str):
        """
        åˆå§‹åŒ–è¿ç§»å·¥å…·

        Args:
            db_url: æ•°æ®åº“ URL (æ”¯æŒ SQLite å’Œ MySQL)
        """
        self.db_url = db_url

        # åˆ›å»ºå¼•æ“
        if 'sqlite' in db_url:
            if not db_url.startswith('sqlite+aiosqlite'):
                db_url = f"sqlite+aiosqlite:///{db_url.replace('sqlite:///', '')}"

        self.engine = create_async_engine(db_url, echo=False)
        self.session_factory = async_sessionmaker(
            self.engine,
            class_=AsyncSession,
            expire_on_commit=False
        )

        # è¡¨æ˜ å°„é…ç½®
        self.table_models = {
            'user_affections': UserAffection,
            'affection_interactions': AffectionInteraction,
            'user_conversation_history': UserConversationHistory,
            'user_diversity': UserDiversity,
            'memories': Memory,
            'memory_embeddings': MemoryEmbedding,
            'memory_summaries': MemorySummary,
            'composite_psychological_states': CompositePsychologicalState,
            'psychological_state_components': PsychologicalStateComponent,
            'psychological_state_history': PsychologicalStateHistory,
            'user_social_profiles': UserSocialProfile,
            'user_social_relation_components': UserSocialRelationComponent,
            'social_relation_history': SocialRelationHistory,
        }

        logger.info("ğŸš€ [æ•°æ®è¿ç§»] æ™ºèƒ½è¿ç§»å·¥å…·åˆå§‹åŒ–å®Œæˆ")

    async def migrate_all(self):
        """æ‰§è¡Œå®Œæ•´çš„æ™ºèƒ½è¿ç§»"""
        logger.info("=" * 70)
        logger.info("ğŸ”„ å¼€å§‹æ™ºèƒ½æ•°æ®è¿ç§»æµç¨‹")
        logger.info("=" * 70)

        start_time = time.time()

        try:
            # 1. åˆ›å»ºæ–°è¡¨ç»“æ„
            await self._create_tables()

            # 2. æ£€æµ‹ç°æœ‰è¡¨
            existing_tables = await self._detect_existing_tables()
            logger.info(f"ğŸ“Š æ£€æµ‹åˆ° {len(existing_tables)} ä¸ªç°æœ‰è¡¨")

            # 3. é€è¡¨è¿ç§»æ•°æ®
            total_migrated = 0
            for table_name, model_class in self.table_models.items():
                if table_name in existing_tables:
                    count = await self._migrate_table(table_name, model_class)
                    total_migrated += count
                else:
                    logger.info(f"[è¿ç§»] {table_name} - ä¸å­˜åœ¨äºæ—§æ•°æ®åº“ï¼Œå·²åˆ›å»ºç©ºè¡¨")

            # 4. éªŒè¯è¿ç§»
            await self._verify_migration()

            elapsed = time.time() - start_time
            logger.info("=" * 70)
            logger.info(f"âœ… æ•°æ®è¿ç§»å®Œæˆï¼")
            logger.info(f"ğŸ“Š å…±è¿ç§» {total_migrated} æ¡è®°å½•")
            logger.info(f"â±ï¸  è€—æ—¶: {elapsed:.2f} ç§’")
            logger.info("=" * 70)

        except Exception as e:
            logger.error(f"âŒ æ•°æ®è¿ç§»å¤±è´¥: {e}", exc_info=True)
            raise

    async def _create_tables(self):
        """åˆ›å»ºæ–°è¡¨ç»“æ„"""
        logger.info("ğŸ“ [æ­¥éª¤ 1/4] åˆ›å»º/æ›´æ–°è¡¨ç»“æ„...")

        async with self.engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)

        logger.info("âœ… è¡¨ç»“æ„å‡†å¤‡å®Œæˆ")

    async def _detect_existing_tables(self) -> List[str]:
        """æ£€æµ‹ç°æœ‰è¡¨"""
        logger.info("ğŸ” [æ­¥éª¤ 2/4] æ£€æµ‹ç°æœ‰è¡¨...")

        async with self.session_factory() as session:
            if 'sqlite' in self.db_url:
                result = await session.execute(
                    text("SELECT name FROM sqlite_master WHERE type='table'")
                )
            else:
                result = await session.execute(text("SHOW TABLES"))

            tables = [row[0] for row in result.fetchall()]

        return tables

    async def _migrate_table(self, table_name: str, model_class) -> int:
        """
        è¿ç§»å•ä¸ªè¡¨

        Returns:
            æˆåŠŸè¿ç§»çš„è®°å½•æ•°
        """
        logger.info(f"ğŸ“¦ [è¿ç§»] {table_name}...")

        try:
            async with self.session_factory() as session:
                # æŸ¥è¯¢æ—§æ•°æ®
                result = await session.execute(text(f"SELECT * FROM {table_name}"))
                rows = result.fetchall()

                if not rows:
                    logger.info(f"  â””â”€ è¡¨ä¸ºç©ºï¼Œè·³è¿‡")
                    return 0

                columns = list(result.keys())
                logger.info(f"  â”œâ”€ æ‰¾åˆ° {len(rows)} æ¡è®°å½•")
                logger.info(f"  â”œâ”€ å­—æ®µ: {', '.join(columns)}")

                # è·å–æ¨¡å‹å­—æ®µ
                model_columns = [c.name for c in model_class.__table__.columns]
                logger.debug(f"  â”œâ”€ æ¨¡å‹å­—æ®µ: {', '.join(model_columns)}")

                # æ£€æŸ¥å­—æ®µåŒ¹é…åº¦
                missing_fields = set(model_columns) - set(columns) - {'id'}
                extra_fields = set(columns) - set(model_columns)

                if missing_fields:
                    logger.warning(f"  â”œâ”€ âš ï¸ ç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}")
                if extra_fields:
                    logger.debug(f"  â”œâ”€ é¢å¤–å­—æ®µ(å°†å¿½ç•¥): {', '.join(extra_fields)}")

                # é€è¡Œè½¬æ¢å’Œæ’å…¥
                success_count = 0
                error_count = 0

                for i, row in enumerate(rows):
                    try:
                        # è½¬æ¢ä¸ºå­—å…¸
                        row_dict = dict(zip(columns, row))

                        # æ™ºèƒ½ç±»å‹è½¬æ¢
                        converted_data = await self._smart_convert(
                            row_dict,
                            model_class,
                            model_columns
                        )

                        # åˆ›å»ºå¯¹è±¡
                        obj = model_class(**converted_data)
                        session.add(obj)

                        success_count += 1

                        # æ¯100æ¡æäº¤ä¸€æ¬¡
                        if (i + 1) % 100 == 0:
                            await session.commit()
                            logger.debug(f"  â”œâ”€ å·²å¤„ç† {i + 1}/{len(rows)} æ¡")

                    except Exception as row_error:
                        error_count += 1
                        logger.warning(f"  â”œâ”€ âš ï¸ ç¬¬ {i+1} è¡Œè¿ç§»å¤±è´¥: {row_error}")
                        logger.debug(f"  â”‚   æ•°æ®: {dict(zip(columns, row))}")

                # æœ€ç»ˆæäº¤
                await session.commit()

                # è¾“å‡ºç»“æœ
                if error_count > 0:
                    logger.warning(
                        f"  â””â”€ âš ï¸ å®Œæˆ: æˆåŠŸ {success_count} æ¡ï¼Œå¤±è´¥ {error_count} æ¡"
                    )
                else:
                    logger.info(f"  â””â”€ âœ… æˆåŠŸè¿ç§» {success_count} æ¡è®°å½•")

                return success_count

        except Exception as e:
            logger.error(f"  â””â”€ âŒ è¡¨è¿ç§»å¤±è´¥: {e}")
            logger.error(f"     é”™è¯¯ç±»å‹: {type(e).__name__}")
            return 0

    async def _smart_convert(
        self,
        row_dict: Dict[str, Any],
        model_class,
        model_columns: List[str]
    ) -> Dict[str, Any]:
        """
        æ™ºèƒ½ç±»å‹è½¬æ¢

        Args:
            row_dict: åŸå§‹è¡Œæ•°æ®
            model_class: ç›®æ ‡æ¨¡å‹ç±»
            model_columns: æ¨¡å‹å­—æ®µåˆ—è¡¨

        Returns:
            è½¬æ¢åçš„æ•°æ®å­—å…¸
        """
        result = {}

        for col_name in model_columns:
            if col_name not in row_dict:
                # å­—æ®µä¸å­˜åœ¨ï¼Œè·³è¿‡æˆ–ä½¿ç”¨é»˜è®¤å€¼
                continue

            value = row_dict[col_name]

            # è·å–å­—æ®µç±»å‹
            col_type = None
            for col in model_class.__table__.columns:
                if col.name == col_name:
                    col_type = col.type
                    break

            if value is None:
                result[col_name] = None
                continue

            # æ™ºèƒ½ç±»å‹è½¬æ¢
            try:
                # String ç±»å‹
                if hasattr(col_type, 'python_type') and col_type.python_type == str:
                    result[col_name] = str(value)

                # Integer ç±»å‹
                elif hasattr(col_type, 'python_type') and col_type.python_type == int:
                    if isinstance(value, float):
                        result[col_name] = int(value)
                    else:
                        result[col_name] = int(value) if value else 0

                # Float ç±»å‹
                elif hasattr(col_type, 'python_type') and col_type.python_type == float:
                    result[col_name] = float(value) if value else 0.0

                # BigInteger (æ—¶é—´æˆ³)
                elif 'BIGINT' in str(col_type) or 'timestamp' in col_name.lower():
                    if isinstance(value, float):
                        result[col_name] = int(value)
                    else:
                        result[col_name] = int(value) if value else int(time.time())

                # Text/JSON (ä¿æŒåŸæ ·)
                else:
                    result[col_name] = value

            except Exception as convert_error:
                logger.debug(
                    f"å­—æ®µ {col_name} è½¬æ¢å¤±è´¥: {convert_error}, "
                    f"åŸå€¼: {value} ({type(value)})"
                )
                result[col_name] = value

        return result

    async def _verify_migration(self):
        """éªŒè¯è¿ç§»æ•°æ®å®Œæ•´æ€§"""
        logger.info("âœ… [æ­¥éª¤ 4/4] éªŒè¯æ•°æ®å®Œæ•´æ€§...")

        async with self.session_factory() as session:
            for table_name in self.table_models.keys():
                try:
                    result = await session.execute(
                        text(f"SELECT COUNT(*) FROM {table_name}")
                    )
                    count = result.scalar()

                    if count > 0:
                        logger.info(f"  â”œâ”€ {table_name}: {count} æ¡è®°å½•")
                    else:
                        logger.debug(f"  â”œâ”€ {table_name}: ç©ºè¡¨")

                except Exception as e:
                    logger.error(f"  â”œâ”€ {table_name}: éªŒè¯å¤±è´¥ - {e}")

        logger.info("  â””â”€ éªŒè¯å®Œæˆ")

    async def close(self):
        """å…³é—­è¿æ¥"""
        await self.engine.dispose()


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================

async def auto_migrate(db_url: str):
    """
    è‡ªåŠ¨è¿ç§»æ•°æ®åº“

    Args:
        db_url: æ•°æ®åº“ URL

    Examples:
        # SQLite
        await auto_migrate('./data/database.db')

        # MySQL
        await auto_migrate('mysql+aiomysql://user:pass@localhost/dbname')
    """
    migrator = SmartDatabaseMigrator(db_url)

    try:
        await migrator.migrate_all()
    finally:
        await migrator.close()


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("ç”¨æ³•: python migration_tool_v2.py <database_url>")
        print("ç¤ºä¾‹: python migration_tool_v2.py ./data/database.db")
        sys.exit(1)

    db_url = sys.argv[1]
    asyncio.run(auto_migrate(db_url))
