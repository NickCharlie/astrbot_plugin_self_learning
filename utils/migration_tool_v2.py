"""
æ™ºèƒ½æ•°æ®åº“è¿ç§»å·¥å…· v2.0
- è‡ªåŠ¨æ£€æµ‹å­—æ®µ
- ç±»å‹è½¬æ¢å®¹é”™
- è‡ªåŠ¨åˆ›å»ºç¼ºå¤±è¡¨
- è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
"""
import asyncio
import time
from typing import Dict, List, Any, Optional
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy import text, inspect
from sqlalchemy.exc import SQLAlchemyError
from astrbot.api import logger  # ä½¿ç”¨ astrbot æ¡†æ¶çš„ logger

from ..models.orm import (
    Base,
    UserAffection,
    AffectionInteraction,
    UserConversationHistory,
    UserDiversity,
    Memory,
    MemoryEmbedding,
    MemorySummary,
    CompositePsychologicalState,
    PsychologicalStateComponent,
    PsychologicalStateHistory,
    UserSocialProfile,
    UserSocialRelationComponent,
    SocialRelationHistory,
    SocialRelationAnalysisResult,
    SocialNetworkNode,
    SocialNetworkEdge
)


class SmartDatabaseMigrator:
    """
    æ™ºèƒ½æ•°æ®åº“è¿ç§»å·¥å…·

    ç‰¹æ€§:
    1. è‡ªåŠ¨æ£€æµ‹æ—§è¡¨æ˜¯å¦å­˜åœ¨
    2. è‡ªåŠ¨åˆ›å»ºç¼ºå¤±çš„æ–°è¡¨
    3. æ™ºèƒ½å­—æ®µæ˜ å°„å’Œç±»å‹è½¬æ¢
    4. è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
    5. é€è¡Œå®¹é”™å¤„ç†
    6. æ”¯æŒè·¨æ•°æ®åº“è¿ç§»ï¼ˆSQLite â†’ MySQLï¼‰
    """

    def __init__(self, source_db_url: str, target_db_url: str = None):
        """
        åˆå§‹åŒ–è¿ç§»å·¥å…·

        Args:
            source_db_url: æºæ•°æ®åº“ URL (æ”¯æŒ SQLite å’Œ MySQL)
            target_db_url: ç›®æ ‡æ•°æ®åº“ URL (å¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨æºæ•°æ®åº“ï¼Œç”¨äºin-placeè¿ç§»)
        """
        self.source_db_url = source_db_url
        self.target_db_url = target_db_url or source_db_url

        # åˆ¤æ–­æ˜¯å¦ä¸ºè·¨æ•°æ®åº“è¿ç§»
        self.is_cross_db_migration = (source_db_url != self.target_db_url)

        # åˆ›å»ºæºæ•°æ®åº“å¼•æ“
        if 'sqlite' in source_db_url:
            if not source_db_url.startswith('sqlite+aiosqlite'):
                source_db_url = f"sqlite+aiosqlite:///{source_db_url.replace('sqlite:///', '')}"

        self.source_engine = create_async_engine(source_db_url, echo=False)
        self.source_session_factory = async_sessionmaker(
            self.source_engine,
            class_=AsyncSession,
            expire_on_commit=False
        )

        # åˆ›å»ºç›®æ ‡æ•°æ®åº“å¼•æ“
        target_url = self.target_db_url
        if 'sqlite' in target_url:
            if not target_url.startswith('sqlite+aiosqlite'):
                target_url = f"sqlite+aiosqlite:///{target_url.replace('sqlite:///', '')}"

        self.target_engine = create_async_engine(target_url, echo=False)
        self.target_session_factory = async_sessionmaker(
            self.target_engine,
            class_=AsyncSession,
            expire_on_commit=False
        )

        # è¡¨æ˜ å°„é…ç½® - ORM æ¨¡å‹è¡¨
        self.table_models = {
            'user_affections': UserAffection,
            'affection_interactions': AffectionInteraction,
            'user_conversation_history': UserConversationHistory,
            'user_diversity': UserDiversity,
            'memories': Memory,
            'memory_embeddings': MemoryEmbedding,
            'memory_summaries': MemorySummary,
            'composite_psychological_states': CompositePsychologicalState,
            'psychological_state_components': PsychologicalStateComponent,
            'psychological_state_history': PsychologicalStateHistory,
            'user_social_profiles': UserSocialProfile,
            'user_social_relation_components': UserSocialRelationComponent,
            'social_relation_history': SocialRelationHistory,
        }

        # ä¼ ç»Ÿ DatabaseManager ç®¡ç†çš„è¡¨ï¼ˆæ—  ORM æ¨¡å‹ï¼‰
        self.traditional_tables = [
            'raw_messages',              # åŸå§‹æ¶ˆæ¯
            'bot_messages',              # Bot æ¶ˆæ¯
            'filtered_messages',         # ç­›é€‰åæ¶ˆæ¯
            'learning_batches',          # å­¦ä¹ æ‰¹æ¬¡
            'persona_update_records',    # äººæ ¼æ›´æ–°è®°å½•
            'reinforcement_learning_results',  # å¼ºåŒ–å­¦ä¹ ç»“æœ
            'strategy_optimization_results',   # ç­–ç•¥ä¼˜åŒ–ç»“æœ
            'learning_performance_history',    # å­¦ä¹ æ€§èƒ½å†å²
            'llm_call_statistics',       # LLM è°ƒç”¨ç»Ÿè®¡
            'jargon',                    # é»‘è¯/æœ¯è¯­
            'social_relations',          # ç¤¾äº¤å…³ç³»
            'expression_patterns',       # è¡¨è¾¾æ¨¡å¼
            'language_style_patterns',   # è¯­è¨€é£æ ¼æ¨¡å¼
            'topic_summaries',           # è¯é¢˜æ‘˜è¦
            'style_learning_records',    # é£æ ¼å­¦ä¹ è®°å½•
            'style_learning_reviews',    # é£æ ¼å­¦ä¹ å®¡æ ¸
            'persona_fusion_history',    # äººæ ¼èåˆå†å²
            'persona_update_reviews',    # äººæ ¼æ›´æ–°å®¡æ ¸
        ]

        if self.is_cross_db_migration:
            logger.info(f"ğŸš€ [æ•°æ®è¿ç§»] è·¨æ•°æ®åº“è¿ç§»æ¨¡å¼")
            logger.info(f"   æºæ•°æ®åº“: {self._mask_url(source_db_url)}")
            logger.info(f"   ç›®æ ‡æ•°æ®åº“: {self._mask_url(self.target_db_url)}")
        else:
            logger.info("ğŸš€ [æ•°æ®è¿ç§»] æœ¬åœ°è¿ç§»æ¨¡å¼ (In-place)")

    def _mask_url(self, url: str) -> str:
        """éšè—æ•°æ®åº“ URL ä¸­çš„å¯†ç """
        if '@' in url:
            # mysql+aiomysql://user:password@host:port/db
            parts = url.split('@')
            if ':' in parts[0]:
                prefix = parts[0].rsplit(':', 1)[0]
                return f"{prefix}:****@{parts[1]}"
        return url

    async def migrate_all(self):
        """æ‰§è¡Œå®Œæ•´çš„æ™ºèƒ½è¿ç§»"""
        logger.info("=" * 70)
        logger.info("ğŸ”„ å¼€å§‹æ™ºèƒ½æ•°æ®è¿ç§»æµç¨‹")
        logger.info("=" * 70)

        start_time = time.time()

        try:
            # 1. åˆ›å»ºæ–°è¡¨ç»“æ„
            await self._create_tables()

            # 2. æ£€æµ‹ç°æœ‰è¡¨
            existing_tables = await self._detect_existing_tables()
            logger.info(f"ğŸ“Š æ£€æµ‹åˆ° {len(existing_tables)} ä¸ªç°æœ‰è¡¨")

            # 3. é€è¡¨è¿ç§»æ•°æ® - ORM æ¨¡å‹è¡¨
            total_migrated = 0
            logger.info(f"ğŸ“¦ [æ­¥éª¤ 3/5] è¿ç§» ORM æ¨¡å‹è¡¨...")
            for table_name, model_class in self.table_models.items():
                if table_name in existing_tables:
                    count = await self._migrate_table(table_name, model_class)
                    total_migrated += count
                else:
                    logger.info(f"[è¿ç§»] {table_name} - ä¸å­˜åœ¨äºæ—§æ•°æ®åº“ï¼Œå·²åˆ›å»ºç©ºè¡¨")

            # 4. è¿ç§»ä¼ ç»Ÿè¡¨ï¼ˆæ—  ORM æ¨¡å‹ï¼‰
            logger.info(f"ğŸ“¦ [æ­¥éª¤ 4/5] è¿ç§»ä¼ ç»Ÿè¡¨ï¼ˆæ—  ORM æ¨¡å‹ï¼‰...")
            for table_name in self.traditional_tables:
                if table_name in existing_tables:
                    count = await self._migrate_traditional_table(table_name)
                    total_migrated += count
                else:
                    logger.info(f"[è¿ç§»] {table_name} - ä¸å­˜åœ¨äºæ—§æ•°æ®åº“ï¼Œè·³è¿‡")

            # 5. éªŒè¯è¿ç§»
            await self._verify_migration()

            elapsed = time.time() - start_time
            logger.info("=" * 70)
            logger.info(f"âœ… æ•°æ®è¿ç§»å®Œæˆï¼")
            logger.info(f"ğŸ“Š å…±è¿ç§» {total_migrated} æ¡è®°å½•")
            logger.info(f"â±ï¸  è€—æ—¶: {elapsed:.2f} ç§’")
            logger.info("=" * 70)

        except Exception as e:
            logger.error(f"âŒ æ•°æ®è¿ç§»å¤±è´¥: {e}", exc_info=True)
            raise

    async def _create_tables(self):
        """åˆ›å»ºæ–°è¡¨ç»“æ„"""
        logger.info("ğŸ“ [æ­¥éª¤ 1/5] åˆ›å»º/æ›´æ–°è¡¨ç»“æ„...")

        async with self.target_engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)

        # ä¿®å¤æ—§è¡¨ç¼ºå¤±å­—æ®µ
        await self._fix_legacy_table_schema()

        logger.info("âœ… è¡¨ç»“æ„å‡†å¤‡å®Œæˆ")

    async def _fix_legacy_table_schema(self):
        """ä¿®å¤æ—§è¡¨ç¼ºå¤±çš„å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰"""
        logger.info("ğŸ”§ [ä¿®å¤] æ£€æŸ¥å¹¶ä¿®å¤æ—§è¡¨ç¼ºå¤±å­—æ®µ...")

        is_sqlite = 'sqlite' in self.target_db_url.lower()

        # éœ€è¦ä¿®å¤çš„è¡¨å’Œå­—æ®µå®šä¹‰
        fixes = {
            'style_learning_reviews': [
                ('reviewer_comment', 'TEXT' if is_sqlite else 'TEXT'),
                ('review_time', 'REAL' if is_sqlite else 'DOUBLE'),
            ],
            'persona_update_reviews': [
                ('reviewer_comment', 'TEXT' if is_sqlite else 'TEXT'),
                ('review_time', 'REAL' if is_sqlite else 'DOUBLE'),
            ],
        }

        async with self.target_session_factory() as session:
            for table_name, columns_to_add in fixes.items():
                try:
                    # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                    check_query = text(f"SELECT name FROM {'sqlite_master' if is_sqlite else 'information_schema.tables'} WHERE {'type' if is_sqlite else 'table_type'}='{'table' if is_sqlite else 'BASE TABLE'}' AND {'name' if is_sqlite else 'table_name'}=:table_name")
                    result = await session.execute(check_query, {'table_name': table_name})
                    if not result.fetchone():
                        logger.debug(f"  â”œâ”€ {table_name}: è¡¨ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¿®å¤")
                        continue

                    # è·å–ç°æœ‰åˆ—
                    if is_sqlite:
                        pragma_result = await session.execute(text(f"PRAGMA table_info({table_name})"))
                        existing_columns = {row[1] for row in pragma_result.fetchall()}
                    else:
                        # MySQL
                        col_result = await session.execute(
                            text(f"SELECT COLUMN_NAME FROM information_schema.COLUMNS WHERE TABLE_NAME=:table_name"),
                            {'table_name': table_name}
                        )
                        existing_columns = {row[0] for row in col_result.fetchall()}

                    # æ·»åŠ ç¼ºå¤±å­—æ®µ
                    for col_name, col_type in columns_to_add:
                        if col_name not in existing_columns:
                            try:
                                alter_sql = f"ALTER TABLE {table_name} ADD COLUMN {col_name} {col_type}"
                                await session.execute(text(alter_sql))
                                await session.commit()
                                logger.info(f"  â”œâ”€ {table_name}.{col_name}: å­—æ®µå·²æ·»åŠ  ({col_type})")
                            except Exception as e:
                                logger.warning(f"  â”œâ”€ {table_name}.{col_name}: æ·»åŠ å¤±è´¥ - {e}")
                        else:
                            logger.debug(f"  â”œâ”€ {table_name}.{col_name}: å­—æ®µå·²å­˜åœ¨")

                except Exception as e:
                    logger.warning(f"  â”œâ”€ {table_name}: ä¿®å¤å¤±è´¥ - {e}")

        logger.info("  â””â”€ å­—æ®µä¿®å¤å®Œæˆ")

    async def _detect_existing_tables(self) -> List[str]:
        """æ£€æµ‹æºæ•°æ®åº“ä¸­çš„ç°æœ‰è¡¨"""
        logger.info("ğŸ” [æ­¥éª¤ 2/5] æ£€æµ‹æºæ•°æ®åº“ä¸­çš„ç°æœ‰è¡¨...")

        async with self.source_session_factory() as session:
            if 'sqlite' in self.source_db_url:
                result = await session.execute(
                    text("SELECT name FROM sqlite_master WHERE type='table'")
                )
            else:
                result = await session.execute(text("SHOW TABLES"))

            tables = [row[0] for row in result.fetchall()]

        return tables

    async def _migrate_table(self, table_name: str, model_class) -> int:
        """
        è¿ç§»å•ä¸ª ORM è¡¨ï¼ˆä»æºæ•°æ®åº“åˆ°ç›®æ ‡æ•°æ®åº“ï¼‰

        Returns:
            æˆåŠŸè¿ç§»çš„è®°å½•æ•°
        """
        logger.info(f"ğŸ“¦ [è¿ç§»] {table_name}...")

        try:
            # ä»æºæ•°æ®åº“è¯»å–æ•°æ®
            async with self.source_session_factory() as source_session:
                result = await source_session.execute(text(f"SELECT * FROM {table_name}"))
                rows = result.fetchall()

                if not rows:
                    logger.info(f"  â””â”€ è¡¨ä¸ºç©ºï¼Œè·³è¿‡")
                    return 0

                columns = list(result.keys())
                logger.info(f"  â”œâ”€ æ‰¾åˆ° {len(rows)} æ¡è®°å½•")
                logger.info(f"  â”œâ”€ å­—æ®µ: {', '.join(columns)}")

            # è·å–æ¨¡å‹å­—æ®µ
            model_columns = [c.name for c in model_class.__table__.columns]
            logger.debug(f"  â”œâ”€ æ¨¡å‹å­—æ®µ: {', '.join(model_columns)}")

            # æ£€æŸ¥å­—æ®µåŒ¹é…åº¦
            missing_fields = set(model_columns) - set(columns) - {'id'}
            extra_fields = set(columns) - set(model_columns)

            if missing_fields:
                logger.warning(f"  â”œâ”€ âš ï¸ ç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}")
            if extra_fields:
                logger.debug(f"  â”œâ”€ é¢å¤–å­—æ®µ(å°†å¿½ç•¥): {', '.join(extra_fields)}")

            # å†™å…¥ç›®æ ‡æ•°æ®åº“
            async with self.target_session_factory() as target_session:
                success_count = 0
                error_count = 0

                for i, row in enumerate(rows):
                    try:
                        # è½¬æ¢ä¸ºå­—å…¸
                        row_dict = dict(zip(columns, row))

                        # æ™ºèƒ½ç±»å‹è½¬æ¢
                        converted_data = await self._smart_convert(
                            row_dict,
                            model_class,
                            model_columns
                        )

                        # åˆ›å»ºå¯¹è±¡
                        obj = model_class(**converted_data)
                        target_session.add(obj)

                        success_count += 1

                        # æ¯100æ¡æäº¤ä¸€æ¬¡
                        if (i + 1) % 100 == 0:
                            await target_session.commit()
                            logger.debug(f"  â”œâ”€ å·²å¤„ç† {i + 1}/{len(rows)} æ¡")

                    except Exception as row_error:
                        error_count += 1
                        logger.warning(f"  â”œâ”€ âš ï¸ ç¬¬ {i+1} è¡Œè¿ç§»å¤±è´¥: {row_error}")
                        logger.debug(f"  â”‚   æ•°æ®: {dict(zip(columns, row))}")

                # æœ€ç»ˆæäº¤
                await target_session.commit()

                # è¾“å‡ºç»“æœ
                if error_count > 0:
                    logger.warning(
                        f"  â””â”€ âš ï¸ å®Œæˆ: æˆåŠŸ {success_count} æ¡ï¼Œå¤±è´¥ {error_count} æ¡"
                    )
                else:
                    logger.info(f"  â””â”€ âœ… æˆåŠŸè¿ç§» {success_count} æ¡è®°å½•")

                return success_count

        except Exception as e:
            logger.error(f"  â””â”€ âŒ è¡¨è¿ç§»å¤±è´¥: {e}")
            logger.error(f"     é”™è¯¯ç±»å‹: {type(e).__name__}")
            return 0

    async def _smart_convert(
        self,
        row_dict: Dict[str, Any],
        model_class,
        model_columns: List[str]
    ) -> Dict[str, Any]:
        """
        æ™ºèƒ½ç±»å‹è½¬æ¢

        Args:
            row_dict: åŸå§‹è¡Œæ•°æ®
            model_class: ç›®æ ‡æ¨¡å‹ç±»
            model_columns: æ¨¡å‹å­—æ®µåˆ—è¡¨

        Returns:
            è½¬æ¢åçš„æ•°æ®å­—å…¸
        """
        result = {}

        for col_name in model_columns:
            if col_name not in row_dict:
                # å­—æ®µä¸å­˜åœ¨ï¼Œè·³è¿‡æˆ–ä½¿ç”¨é»˜è®¤å€¼
                continue

            value = row_dict[col_name]

            # è·å–å­—æ®µç±»å‹
            col_type = None
            for col in model_class.__table__.columns:
                if col.name == col_name:
                    col_type = col.type
                    break

            if value is None:
                result[col_name] = None
                continue

            # æ™ºèƒ½ç±»å‹è½¬æ¢
            try:
                # String ç±»å‹
                if hasattr(col_type, 'python_type') and col_type.python_type == str:
                    result[col_name] = str(value)

                # Integer ç±»å‹
                elif hasattr(col_type, 'python_type') and col_type.python_type == int:
                    if isinstance(value, float):
                        result[col_name] = int(value)
                    else:
                        result[col_name] = int(value) if value else 0

                # Float ç±»å‹
                elif hasattr(col_type, 'python_type') and col_type.python_type == float:
                    result[col_name] = float(value) if value else 0.0

                # BigInteger (æ—¶é—´æˆ³)
                elif 'BIGINT' in str(col_type) or 'timestamp' in col_name.lower():
                    if isinstance(value, float):
                        result[col_name] = int(value)
                    else:
                        result[col_name] = int(value) if value else int(time.time())

                # Text/JSON (ä¿æŒåŸæ ·)
                else:
                    result[col_name] = value

            except Exception as convert_error:
                logger.debug(
                    f"å­—æ®µ {col_name} è½¬æ¢å¤±è´¥: {convert_error}, "
                    f"åŸå€¼: {value} ({type(value)})"
                )
                result[col_name] = value

        return result

    async def _migrate_traditional_table(self, table_name: str) -> int:
        """
        è¿ç§»ä¼ ç»Ÿè¡¨ï¼ˆæ—  ORM æ¨¡å‹ï¼Œä»æºæ•°æ®åº“åˆ°ç›®æ ‡æ•°æ®åº“ï¼‰

        Args:
            table_name: è¡¨å

        Returns:
            æˆåŠŸè¿ç§»çš„è®°å½•æ•°
        """
        logger.info(f"ğŸ“¦ [è¿ç§»] {table_name} (ä¼ ç»Ÿè¡¨)...")

        try:
            # ä»æºæ•°æ®åº“è¯»å–æ•°æ®
            async with self.source_session_factory() as source_session:
                result = await source_session.execute(text(f"SELECT * FROM {table_name}"))
                rows = result.fetchall()

                if not rows:
                    logger.info(f"  â””â”€ è¡¨ä¸ºç©ºï¼Œè·³è¿‡")
                    return 0

                columns = list(result.keys())
                logger.info(f"  â”œâ”€ æ‰¾åˆ° {len(rows)} æ¡è®°å½•")
                logger.info(f"  â”œâ”€ å­—æ®µ: {', '.join(columns)}")

            # è·å–ç›®æ ‡è¡¨ç»“æ„
            target_columns = columns  # é»˜è®¤ä½¿ç”¨æºè¡¨å­—æ®µ
            try:
                async with self.target_session_factory() as target_session:
                    check_result = await target_session.execute(
                        text(f"SELECT * FROM {table_name} LIMIT 0")
                    )
                    target_columns = list(check_result.keys())
            except Exception as e:
                logger.warning(f"  â”œâ”€ âš ï¸ ç›®æ ‡è¡¨ä¸å­˜åœ¨æˆ–æŸ¥è¯¢å¤±è´¥ï¼Œå°†ä½¿ç”¨æºè¡¨ç»“æ„: {e}")

            # æ£€æŸ¥å­—æ®µåŒ¹é…åº¦
            missing_fields = set(target_columns) - set(columns) - {'id'}
            extra_fields = set(columns) - set(target_columns)

            if missing_fields:
                logger.warning(f"  â”œâ”€ âš ï¸ ç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}")
            if extra_fields:
                logger.debug(f"  â”œâ”€ é¢å¤–å­—æ®µ(å°†å¿½ç•¥): {', '.join(extra_fields)}")

            # ä½¿ç”¨ç›®æ ‡è¡¨å®é™…å­˜åœ¨çš„å­—æ®µ
            valid_columns = [col for col in columns if col in target_columns or col == 'id']

            # æ ¹æ®ç›®æ ‡æ•°æ®åº“ç±»å‹é€‰æ‹©å ä½ç¬¦
            is_mysql = 'mysql' in self.target_db_url.lower()
            placeholder = '%s' if is_mysql else '?'

            # æ„å»ºæ’å…¥è¯­å¥
            insert_columns = ', '.join(valid_columns)
            insert_placeholders = ', '.join([placeholder] * len(valid_columns))
            insert_sql = f"INSERT INTO {table_name} ({insert_columns}) VALUES ({insert_placeholders})"

            # å†™å…¥ç›®æ ‡æ•°æ®åº“
            async with self.target_session_factory() as target_session:
                success_count = 0
                error_count = 0

                for i, row in enumerate(rows):
                    try:
                        # è½¬æ¢ä¸ºå­—å…¸
                        row_dict = dict(zip(columns, row))

                        # åªé€‰æ‹©æœ‰æ•ˆå­—æ®µçš„å€¼
                        values = [row_dict[col] for col in valid_columns]

                        # æ‰§è¡Œæ’å…¥ - ä½¿ç”¨å­—å…¸å‚æ•°è€Œä¸æ˜¯åˆ—è¡¨
                        # ä¸ºæ¯ä¸ªå ä½ç¬¦åˆ›å»ºä¸€ä¸ªå‚æ•°å
                        param_names = [f'param_{j}' for j in range(len(valid_columns))]
                        param_dict = dict(zip(param_names, values))

                        # æ ¹æ®æ•°æ®åº“ç±»å‹æ„å»ºSQL
                        if is_mysql:
                            # MySQL: ä½¿ç”¨ REPLACE INTO é¿å…ä¸»é”®å†²çª
                            placeholders_str = ', '.join([f':{pname}' for pname in param_names])
                            insert_sql_parameterized = f"REPLACE INTO {table_name} ({insert_columns}) VALUES ({placeholders_str})"
                        else:
                            # SQLite: ä½¿ç”¨ REPLACE INTO é¿å…ä¸»é”®å†²çª
                            placeholders_str = ', '.join([f':{pname}' for pname in param_names])
                            insert_sql_parameterized = f"REPLACE INTO {table_name} ({insert_columns}) VALUES ({placeholders_str})"

                        await target_session.execute(text(insert_sql_parameterized), param_dict)
                        success_count += 1

                        # æ¯100æ¡æäº¤ä¸€æ¬¡
                        if (i + 1) % 100 == 0:
                            await target_session.commit()
                            logger.debug(f"  â”œâ”€ å·²å¤„ç† {i + 1}/{len(rows)} æ¡")

                    except Exception as row_error:
                        error_count += 1
                        logger.warning(f"  â”œâ”€ âš ï¸ ç¬¬ {i+1} è¡Œè¿ç§»å¤±è´¥: {row_error}")
                        logger.debug(f"  â”‚   æ•°æ®: {dict(zip(columns, row))}")

                # æœ€ç»ˆæäº¤
                await target_session.commit()

                # è¾“å‡ºç»“æœ
                if error_count > 0:
                    logger.warning(
                        f"  â””â”€ âš ï¸ å®Œæˆ: æˆåŠŸ {success_count} æ¡ï¼Œå¤±è´¥ {error_count} æ¡"
                    )
                else:
                    logger.info(f"  â””â”€ âœ… æˆåŠŸè¿ç§» {success_count} æ¡è®°å½•")

                return success_count

        except Exception as e:
            logger.error(f"  â””â”€ âŒ è¡¨è¿ç§»å¤±è´¥: {e}")
            logger.error(f"     é”™è¯¯ç±»å‹: {type(e).__name__}")
            return 0

    async def _verify_migration(self):
        """éªŒè¯ç›®æ ‡æ•°æ®åº“è¿ç§»æ•°æ®å®Œæ•´æ€§"""
        logger.info("âœ… [æ­¥éª¤ 5/5] éªŒè¯æ•°æ®å®Œæ•´æ€§...")

        async with self.target_session_factory() as session:
            # éªŒè¯ ORM è¡¨
            for table_name in self.table_models.keys():
                try:
                    result = await session.execute(
                        text(f"SELECT COUNT(*) FROM {table_name}")
                    )
                    count = result.scalar()

                    if count > 0:
                        logger.info(f"  â”œâ”€ {table_name}: {count} æ¡è®°å½•")
                    else:
                        logger.debug(f"  â”œâ”€ {table_name}: ç©ºè¡¨")

                except Exception as e:
                    logger.error(f"  â”œâ”€ {table_name}: éªŒè¯å¤±è´¥ - {e}")

            # éªŒè¯ä¼ ç»Ÿè¡¨
            for table_name in self.traditional_tables:
                try:
                    result = await session.execute(
                        text(f"SELECT COUNT(*) FROM {table_name}")
                    )
                    count = result.scalar()

                    if count > 0:
                        logger.info(f"  â”œâ”€ {table_name}: {count} æ¡è®°å½•")
                    else:
                        logger.debug(f"  â”œâ”€ {table_name}: ç©ºè¡¨")

                except Exception as e:
                    logger.debug(f"  â”œâ”€ {table_name}: è¡¨ä¸å­˜åœ¨æˆ–éªŒè¯å¤±è´¥")

        logger.info("  â””â”€ éªŒè¯å®Œæˆ")

    async def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.source_engine:
            await self.source_engine.dispose()
        if self.target_engine and self.target_engine != self.source_engine:
            await self.target_engine.dispose()
        logger.info("âœ… [æ•°æ®è¿ç§»] æ•°æ®åº“è¿æ¥å·²å…³é—­")


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================

async def auto_migrate(source_db_url: str, target_db_url: str = None):
    """
    è‡ªåŠ¨è¿ç§»æ•°æ®åº“

    Args:
        source_db_url: æºæ•°æ®åº“ URL
        target_db_url: ç›®æ ‡æ•°æ®åº“ URL (å¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨æºæ•°æ®åº“ï¼Œç”¨äºin-placeè¿ç§»)

    Examples:
        # In-place è¿ç§» (å•ä¸ªæ•°æ®åº“)
        await auto_migrate('./data/database.db')

        # è·¨æ•°æ®åº“è¿ç§» (SQLite â†’ MySQL)
        await auto_migrate(
            './data/database.db',
            'mysql+aiomysql://user:pass@localhost/dbname'
        )
    """
    migrator = SmartDatabaseMigrator(source_db_url, target_db_url)

    try:
        await migrator.migrate_all()
    finally:
        await migrator.close()


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("ç”¨æ³•: python migration_tool_v2.py <source_db_url> [target_db_url]")
        print("\nç¤ºä¾‹:")
        print("  # In-place è¿ç§»")
        print("  python migration_tool_v2.py ./data/database.db")
        print("\n  # è·¨æ•°æ®åº“è¿ç§» (SQLite â†’ MySQL)")
        print("  python migration_tool_v2.py ./data/database.db mysql+aiomysql://user:pass@localhost/dbname")
        sys.exit(1)

    source_url = sys.argv[1]
    target_url = sys.argv[2] if len(sys.argv) > 2 else None

    asyncio.run(auto_migrate(source_url, target_url))
