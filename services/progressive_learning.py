"""
æ¸è¿›å¼å­¦ä¹ æœåŠ¡ - åè°ƒå„ä¸ªç»„ä»¶å®ç°æ™ºèƒ½è‡ªé€‚åº”å­¦ä¹ 
"""
import asyncio
import json
import time
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass

from astrbot.api import logger
from astrbot.api.star import Context

from ..config import PluginConfig
from ..constants import UPDATE_TYPE_PROGRESSIVE_PERSONA_LEARNING
from ..exceptions import LearningError

from ..utils.json_utils import safe_parse_llm_json, clean_llm_json_response

from .database_manager import DatabaseManager


@dataclass
class LearningSession:
    """å­¦ä¹ ä¼šè¯"""
    session_id: str
    start_time: str
    end_time: Optional[str] = None
    messages_processed: int = 0
    filtered_messages: int = 0
    style_updates: int = 0
    quality_score: float = 0.0
    success: bool = False


class ProgressiveLearningService:
    """æ¸è¿›å¼å­¦ä¹ æœåŠ¡"""
    
    def __init__(self, config: PluginConfig, context: Context,
                 db_manager: DatabaseManager,
                 message_collector,
                 multidimensional_analyzer,
                 style_analyzer,
                 quality_monitor,
                 persona_manager, # æ·»åŠ  persona_manager å‚æ•°
                 ml_analyzer, # æ·»åŠ  ml_analyzer å‚æ•°
                 prompts: Any): # æ·»åŠ  prompts å‚æ•°
        self.config = config
        self.context = context
        self.db_manager = db_manager
        
        # æ³¨å…¥å„ä¸ªç»„ä»¶æœåŠ¡
        self.message_collector = message_collector
        self.multidimensional_analyzer = multidimensional_analyzer
        self.style_analyzer = style_analyzer
        self.quality_monitor = quality_monitor
        self.persona_manager = persona_manager # æ³¨å…¥ persona_manager
        self.ml_analyzer = ml_analyzer # æ³¨å…¥ ml_analyzer
        self.prompts = prompts  # ä¿å­˜ prompts å®ä¾‹
        
        # å­¦ä¹ çŠ¶æ€ - ä½¿ç”¨å­—å…¸ç®¡ç†æ¯ä¸ªç¾¤ç»„çš„å­¦ä¹ çŠ¶æ€
        self.learning_active = {}  # æ”¹ä¸ºå­—å…¸ï¼ŒæŒ‰ç¾¤ç»„IDç®¡ç†
        
        # å¢é‡æ›´æ–°å›è°ƒå‡½æ•°ï¼Œé™ä½è€¦åˆæ€§
        self.update_system_prompt_callback = None
        self.current_session: Optional[LearningSession] = None
        self.learning_sessions: List[LearningSession] = [] # å†å²å­¦ä¹ ä¼šè¯ï¼Œå¯ä»¥ä»æ•°æ®åº“åŠ è½½
        self.learning_lock = asyncio.Lock()  # æ·»åŠ å¼‚æ­¥é”é˜²æ­¢ç«æ€æ¡ä»¶
        
        # å­¦ä¹ æ§åˆ¶å‚æ•°
        self.batch_size = config.max_messages_per_batch
        self.learning_interval = config.learning_interval_hours * 3600  # è½¬æ¢ä¸ºç§’
        self.quality_threshold = config.style_update_threshold
        
        logger.info("æ¸è¿›å¼å­¦ä¹ æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def set_update_system_prompt_callback(self, callback):
        """
        è®¾ç½®å¢é‡æ›´æ–°å›è°ƒå‡½æ•°
        
        Args:
            callback: å¼‚æ­¥å›è°ƒå‡½æ•°ï¼Œæ¥å— group_id å‚æ•°
        """
        self.update_system_prompt_callback = callback
        logger.info("å¢é‡æ›´æ–°å›è°ƒå‡½æ•°å·²è®¾ç½®")

    async def start(self):
        """æœåŠ¡å¯åŠ¨æ—¶åŠ è½½å†å²å­¦ä¹ ä¼šè¯"""
        # å‡è®¾æ¯ä¸ªç¾¤ç»„æœ‰ç‹¬ç«‹çš„å­¦ä¹ ä¼šè¯ï¼Œè¿™é‡Œéœ€è¦ä¸€ä¸ª group_id
        # ä¸ºäº†ç®€åŒ–ï¼Œæš‚æ—¶å‡è®¾åŠ è½½ä¸€ä¸ªé»˜è®¤çš„æˆ–å…¨å±€çš„å­¦ä¹ ä¼šè¯
        # å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦æ ¹æ®å½“å‰å¤„ç†çš„ç¾¤ç»„IDæ¥åŠ è½½
        default_group_id = "global_learning" # æˆ–è€…ä»é…ç½®ä¸­è·å–
        # è¿™é‡Œå¯ä»¥åŠ è½½æ‰€æœ‰å†å²ä¼šè¯ï¼Œæˆ–è€…åªåŠ è½½æœ€è¿‘çš„Nä¸ª
        # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬æš‚æ—¶ä¸ä»æ•°æ®åº“åŠ è½½å†å²ä¼šè¯åˆ—è¡¨ï¼Œåªåœ¨æ¯æ¬¡ä¼šè¯ç»“æŸæ—¶ä¿å­˜
        # å¦‚æœéœ€è¦åŠ è½½å†å²ä¼šè¯ï¼Œéœ€è¦ DatabaseManager æä¾› load_all_learning_sessions æ–¹æ³•
        logger.info("æ¸è¿›å¼å­¦ä¹ æœåŠ¡å¯åŠ¨ï¼Œå‡†å¤‡å¼€å§‹å­¦ä¹ ã€‚")

    async def start_learning(self, group_id: str) -> bool:
        """å¯åŠ¨å­¦ä¹ æµç¨‹ - ä¼˜åŒ–ä¸ºåå°ä»»åŠ¡æ‰§è¡Œ"""
        async with self.learning_lock:  # ä½¿ç”¨é”é˜²æ­¢ç«æ€æ¡ä»¶
            try:
                # æ£€æŸ¥è¯¥ç¾¤ç»„æ˜¯å¦å·²ç»åœ¨å­¦ä¹ 
                if self.learning_active.get(group_id, False):
                    logger.info(f"ç¾¤ç»„ {group_id} å­¦ä¹ å·²åœ¨è¿›è¡Œä¸­ï¼Œè·³è¿‡å¯åŠ¨")
                    return True  # è¿”å›Trueè¡¨ç¤ºå­¦ä¹ çŠ¶æ€æ­£å¸¸
                
                # è®¾ç½®è¯¥ç¾¤ç»„ä¸ºå­¦ä¹ çŠ¶æ€
                self.learning_active[group_id] = True
                
                # åˆ›å»ºæ–°çš„å­¦ä¹ ä¼šè¯
                session_id = f"session_{group_id}_{int(time.time())}"
                self.current_session = LearningSession(
                    session_id=session_id,
                    start_time=datetime.now().isoformat()
                )
                # ä¿å­˜æ–°çš„å­¦ä¹ ä¼šè¯åˆ°æ•°æ®åº“
                await self.db_manager.save_learning_session_record(group_id, self.current_session.__dict__)
                
                logger.info(f"å¼€å§‹å­¦ä¹ ä¼šè¯: {session_id} for group {group_id}")
                
                # åˆ›å»ºåå°ä»»åŠ¡ï¼Œç¡®ä¿ä¸é˜»å¡ä¸»çº¿ç¨‹
                learning_task = asyncio.create_task(self._learning_loop_safe(group_id))
                
                # è®¾ç½®ä»»åŠ¡å®Œæˆå›è°ƒ
                def on_learning_complete(task):
                    if task.exception():
                        logger.error(f"ç¾¤ç»„ {group_id} å­¦ä¹ ä»»åŠ¡å¼‚å¸¸å®Œæˆ: {task.exception()}")
                    else:
                        logger.info(f"ç¾¤ç»„ {group_id} å­¦ä¹ ä»»åŠ¡æ­£å¸¸å®Œæˆ")
                    # æ¸…é™¤è¯¥ç¾¤ç»„çš„å­¦ä¹ çŠ¶æ€
                    self.learning_active[group_id] = False
                    
                learning_task.add_done_callback(on_learning_complete)
                
                return True
                
            except Exception as e:
                logger.error(f"å¯åŠ¨ç¾¤ç»„ {group_id} å­¦ä¹ å¤±è´¥: {e}")
                # ç¡®ä¿æ¸…é™¤å­¦ä¹ çŠ¶æ€
                self.learning_active[group_id] = False
                return False

    async def stop_learning(self, group_id: str = None):
        """åœæ­¢å­¦ä¹ æµç¨‹"""
        if group_id:
            # åœæ­¢ç‰¹å®šç¾¤ç»„çš„å­¦ä¹ 
            self.learning_active[group_id] = False
            logger.info(f"åœæ­¢ç¾¤ç»„ {group_id} çš„å­¦ä¹ ä»»åŠ¡")
        else:
            # åœæ­¢æ‰€æœ‰ç¾¤ç»„çš„å­¦ä¹ 
            for gid in list(self.learning_active.keys()):
                self.learning_active[gid] = False
            logger.info("åœæ­¢æ‰€æœ‰ç¾¤ç»„çš„å­¦ä¹ ä»»åŠ¡")
        
        if self.current_session:
            self.current_session.end_time = datetime.now().isoformat()
            self.current_session.success = True  # å‡è®¾æ­£å¸¸åœæ­¢å³æˆåŠŸ
            # ä¿å­˜æ›´æ–°åçš„å­¦ä¹ ä¼šè¯åˆ°æ•°æ®åº“
            target_group_id = group_id or "global_learning"  # ä½¿ç”¨æŒ‡å®šçš„ç¾¤ç»„IDæˆ–é»˜è®¤å€¼
            await self.db_manager.save_learning_session_record(target_group_id, self.current_session.__dict__)
            self.learning_sessions.append(self.current_session)  # ä»ç„¶æ·»åŠ åˆ°å†…å­˜åˆ—è¡¨
            logger.info(f"å­¦ä¹ ä¼šè¯ç»“æŸ: {self.current_session.session_id}")
            self.current_session = None

    async def _learning_loop_safe(self, group_id: str):
        """å®‰å…¨çš„å­¦ä¹ å¾ªç¯ - åœ¨åå°çº¿ç¨‹æ‰§è¡Œï¼ŒåŒ…å«å®Œæ•´é”™è¯¯å¤„ç†"""
        try:
            while self.learning_active.get(group_id, False):
                try:
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥æš‚åœå­¦ä¹ 
                    should_pause, reason = await self.quality_monitor.should_pause_learning()
                    if should_pause:
                        logger.warning(f"ç¾¤ç»„ {group_id} å­¦ä¹ è¢«æš‚åœ: {reason}")
                        await self.stop_learning(group_id)
                        break
                    
                    # æ‰§è¡Œä¸€ä¸ªå­¦ä¹ æ‰¹æ¬¡ - åœ¨åå°æ‰§è¡Œ
                    await self._execute_learning_batch_background(group_id)
                    
                    # ç­‰å¾…ä¸‹ä¸€ä¸ªå­¦ä¹ å‘¨æœŸ
                    await asyncio.sleep(self.learning_interval)
                    
                except asyncio.CancelledError:
                    logger.info(f"ç¾¤ç»„ {group_id} å­¦ä¹ ä»»åŠ¡è¢«å–æ¶ˆ")
                    break
                except Exception as e:
                    logger.error(f"ç¾¤ç»„ {group_id} å­¦ä¹ å¾ªç¯å¼‚å¸¸: {e}", exc_info=True)
                    await asyncio.sleep(60)  # å¼‚å¸¸æ—¶ç­‰å¾…1åˆ†é’Ÿ
        finally:
            # ç¡®ä¿æ¸…ç†èµ„æº
            if self.current_session:
                self.current_session.end_time = datetime.now().isoformat()
                await self.db_manager.save_learning_session_record(group_id, self.current_session.__dict__)
            logger.info(f"å­¦ä¹ å¾ªç¯ç»“æŸ for group {group_id}")

    async def _execute_learning_batch(self, group_id: str, relearn_mode: bool = False):
        """æ‰§è¡Œä¸€ä¸ªå­¦ä¹ æ‰¹æ¬¡ - é›†æˆå¼ºåŒ–å­¦ä¹ 

        Args:
            group_id: ç¾¤ç»„ID
            relearn_mode: é‡æ–°å­¦ä¹ æ¨¡å¼ï¼Œå¦‚æœä¸ºTrueåˆ™å¿½ç•¥"å·²å¤„ç†"æ ‡è®°ï¼Œè·å–æ‰€æœ‰å†å²æ¶ˆæ¯
        """
        try:
            batch_start_time = datetime.now()

            # 1. è·å–æ¶ˆæ¯ï¼ˆæ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦å¿½ç•¥"å·²å¤„ç†"æ ‡è®°ï¼‰
            if relearn_mode:
                # âœ… é‡æ–°å­¦ä¹ æ¨¡å¼ï¼šè·å–æ‰€æœ‰å†å²æ¶ˆæ¯ï¼Œå¿½ç•¥å·²å¤„ç†æ ‡è®°
                logger.info(f"ğŸ”„ é‡æ–°å­¦ä¹ æ¨¡å¼ï¼šè·å–ç¾¤ç»„ {group_id} çš„æ‰€æœ‰å†å²æ¶ˆæ¯ï¼ˆå¿½ç•¥å·²å¤„ç†æ ‡è®°ï¼‰")
                # ä½¿ç”¨ get_recent_raw_messages è·å–æ‰€æœ‰å†å²æ¶ˆæ¯ï¼ˆä¸è€ƒè™‘å·²å¤„ç†æ ‡è®°ï¼‰
                unprocessed_messages = await self.db_manager.get_recent_raw_messages(
                    group_id=group_id,
                    limit=self.batch_size * 10  # é‡æ–°å­¦ä¹ æ—¶è·å–æ›´å¤šæ¶ˆæ¯
                )
                logger.info(f"è·å–åˆ° {len(unprocessed_messages) if unprocessed_messages else 0} æ¡å†å²æ¶ˆæ¯ç”¨äºé‡æ–°å­¦ä¹ ")
            else:
                # æ­£å¸¸æ¨¡å¼ï¼šåªè·å–æœªå¤„ç†çš„æ¶ˆæ¯
                unprocessed_messages = await self.message_collector.get_unprocessed_messages(
                    limit=self.batch_size
                )

            if not unprocessed_messages:
                if relearn_mode:
                    logger.warning(f"ç¾¤ç»„ {group_id} æ²¡æœ‰æ‰¾åˆ°å†å²æ¶ˆæ¯")
                else:
                    logger.debug("æ²¡æœ‰æœªå¤„ç†çš„æ¶ˆæ¯ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                return

            logger.info(f"å¼€å§‹å¤„ç† {len(unprocessed_messages)} æ¡æ¶ˆæ¯ï¼ˆrelearn_mode={relearn_mode}ï¼‰")
            
            # 2. ä½¿ç”¨å¤šç»´åº¦åˆ†æå™¨ç­›é€‰æ¶ˆæ¯
            filtered_messages = await self._filter_messages_with_context(unprocessed_messages)
            
            if not filtered_messages:
                logger.debug("æ²¡æœ‰é€šè¿‡ç­›é€‰çš„æ¶ˆæ¯")
                await self._mark_messages_processed(unprocessed_messages)
                return
            
            # 3. è·å–å½“å‰äººæ ¼è®¾ç½® (é’ˆå¯¹ç‰¹å®šç¾¤ç»„)
            current_persona = await self._get_current_persona(group_id)
            
            # 4. ã€æ–°å¢ã€‘å¼ºåŒ–å­¦ä¹ è®°å¿†é‡æ”¾ - åœ¨force_learningä¸­å‡å°‘è°ƒç”¨é¢‘ç‡
            if self.config.enable_ml_analysis:
                try:
                    # æ£€æŸ¥æ˜¯å¦ä¸ºforce_learningè°ƒç”¨ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡è®°å¿†é‡æ”¾é¿å…æ— é™å¾ªç¯
                    import inspect
                    current_frame = inspect.currentframe()
                    call_stack = []
                    frame = current_frame
                    while frame:
                        call_stack.append(frame.f_code.co_name)
                        frame = frame.f_back
                    
                    if 'force_learning_command' in call_stack:
                        logger.debug("force_learningä¸­è·³è¿‡å¼ºåŒ–å­¦ä¹ è®°å¿†é‡æ”¾ï¼Œé¿å…æ— é™å¾ªç¯")
                    else:
                        reinforcement_result = await self.ml_analyzer.reinforcement_memory_replay(
                            group_id, filtered_messages, current_persona
                        )
                        
                        if reinforcement_result and reinforcement_result.get('optimization_strategy'):
                            # æ ¹æ®å¼ºåŒ–å­¦ä¹ ç»“æœè°ƒæ•´å­¦ä¹ å‚æ•°
                            learning_weight = reinforcement_result.get('optimization_strategy', {}).get('learning_weight', 1.0)
                            confidence_threshold = reinforcement_result.get('optimization_strategy', {}).get('confidence_threshold', self.config.confidence_threshold)
                            
                            # åŠ¨æ€è°ƒæ•´ç­›é€‰é˜ˆå€¼
                            if confidence_threshold != self.config.confidence_threshold:
                                logger.info(f"æ ¹æ®å¼ºåŒ–å­¦ä¹ è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼: {self.config.confidence_threshold} -> {confidence_threshold}")
                                # é‡æ–°ç­›é€‰æ¶ˆæ¯ï¼ˆå¦‚æœé˜ˆå€¼æé«˜äº†ï¼‰
                                if confidence_threshold > self.config.confidence_threshold:
                                    filtered_messages = [msg for msg in filtered_messages 
                                                       if msg.get('relevance_score', 0) >= confidence_threshold]
                                    
                except Exception as e:
                    logger.error(f"å¼ºåŒ–å­¦ä¹ è®°å¿†é‡æ”¾å¤±è´¥: {e}")
            
            # 5. ä½¿ç”¨é£æ ¼åˆ†æå™¨æ·±åº¦åˆ†æ
            style_analysis = await self.style_analyzer.analyze_conversation_style(group_id, filtered_messages)
            
            # 6. ã€å¢å¼ºã€‘ä½¿ç”¨æç‚¼æ¨¡å‹ç”Ÿæˆæ›´æ–°åçš„äººæ ¼
            updated_persona = await self._generate_updated_persona_with_refinement(group_id, current_persona, style_analysis)

            # 7. ã€æ–°å¢ã€‘å¼ºåŒ–å­¦ä¹ å¢é‡å¾®è°ƒ
            ml_tuning_info = None  # ç”¨äºè®°å½•å¼ºåŒ–å­¦ä¹ è°ƒä¼˜ä¿¡æ¯
            if self.config.enable_ml_analysis and updated_persona:
                try:
                    tuning_result = await self.ml_analyzer.reinforcement_incremental_tuning(
                        group_id, current_persona, updated_persona
                    )

                    if tuning_result and tuning_result.get('updated_persona'):
                        # ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–åçš„äººæ ¼
                        final_persona = tuning_result.get('updated_persona')

                        # æ£€æµ‹æ˜¯å¦ä½¿ç”¨äº†ä¿å®ˆèåˆç­–ç•¥
                        original_prompt_length = len(current_persona.get('prompt', ''))
                        new_prompt_length = len(final_persona.get('prompt', ''))
                        used_conservative_fusion = new_prompt_length < original_prompt_length * 0.8

                        updated_persona.update(final_persona)

                        # ä¿å­˜å¼ºåŒ–å­¦ä¹ è°ƒä¼˜ä¿¡æ¯ï¼Œä¾›å®¡æŸ¥è®°å½•ä½¿ç”¨
                        ml_tuning_info = {
                            'applied': True,
                            'expected_improvement': tuning_result.get('performance_prediction', {}).get('expected_improvement', 0),
                            'used_conservative_fusion': used_conservative_fusion,
                            'original_length': original_prompt_length,
                            'tuned_length': new_prompt_length
                        }

                        logger.info(f"åº”ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–åçš„äººæ ¼ï¼Œé¢„æœŸæ”¹è¿›: {ml_tuning_info['expected_improvement']}" +
                                  (f"ï¼Œä½¿ç”¨ä¿å®ˆèåˆç­–ç•¥" if used_conservative_fusion else ""))

                except Exception as e:
                    logger.error(f"å¼ºåŒ–å­¦ä¹ å¢é‡å¾®è°ƒå¤±è´¥: {e}")
            
            # 8. è´¨é‡ç›‘æ§è¯„ä¼°
            # ç¡®ä¿å‚æ•°ä¸ä¸ºNoneï¼Œæä¾›é»˜è®¤å€¼
            if current_persona is None:
                current_persona = {"prompt": "é»˜è®¤äººæ ¼"}
                logger.warning("current_personaä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤å€¼")
            
            if updated_persona is None:
                updated_persona = current_persona.copy()
                logger.warning("updated_personaä¸ºNoneï¼Œä½¿ç”¨current_personaçš„å‰¯æœ¬")
                
            quality_metrics = await self.quality_monitor.evaluate_learning_batch(
                current_persona,
                updated_persona,
                filtered_messages
            )

            # 9. åº”ç”¨å­¦ä¹ æ›´æ–°ï¼ˆå¯¹è¯é£æ ¼å­¦ä¹ ä¸åˆ¤æ–­è´¨é‡ç›´æ¥åº”ç”¨ï¼Œäººæ ¼å­¦ä¹ åŠ å…¥å®¡æŸ¥ï¼‰
            # æ³¨æ„ï¼šå¯¹è¯é£æ ¼ï¼ˆè¡¨è¾¾æ¨¡å¼ï¼‰å­¦ä¹ æ€»æ˜¯æˆåŠŸï¼Œäººæ ¼å­¦ä¹ åœ¨_apply_learning_updatesä¸­ä¼šåŠ å…¥å®¡æŸ¥
            # âœ… ä¼ é€’ relearn_mode å’Œ ml_tuning_info å‚æ•°
            await self._apply_learning_updates(group_id, style_analysis, filtered_messages, current_persona, updated_persona, quality_metrics, relearn_mode=relearn_mode, ml_tuning_info=ml_tuning_info)
            logger.info(f"å­¦ä¹ æ›´æ–°å·²åº”ç”¨ï¼ˆå¯¹è¯é£æ ¼å­¦ä¹ å·²å®Œæˆï¼Œäººæ ¼å­¦ä¹ å·²åŠ å…¥å®¡æŸ¥ï¼‰ï¼Œè´¨é‡å¾—åˆ†: {quality_metrics.consistency_score:.3f} for group {group_id}")
            success = True  # å¯¹è¯é£æ ¼å­¦ä¹ æ€»æ˜¯æˆåŠŸ
            
            # 10. ã€æ–°å¢ã€‘ä¿å­˜å­¦ä¹ æ€§èƒ½è®°å½•
            await self.db_manager.save_learning_performance_record(group_id, {
                'session_id': self.current_session.session_id if self.current_session else '',
                'timestamp': time.time(),
                'quality_score': quality_metrics.consistency_score,
                'learning_time': (datetime.now() - batch_start_time).total_seconds(),
                'success': success,
                'successful_pattern': json.dumps(style_analysis, default=self._json_serializer),
                'failed_pattern': ''  # å¯¹è¯é£æ ¼å­¦ä¹ æ€»æ˜¯æˆåŠŸï¼Œä¸è®°å½•å¤±è´¥
            })
            
            # 11. æ ‡è®°æ¶ˆæ¯ä¸ºå·²å¤„ç†
            await self._mark_messages_processed(unprocessed_messages)
            
            # 12. æ›´æ–°å­¦ä¹ ä¼šè¯ç»Ÿè®¡å¹¶æŒä¹…åŒ–
            if self.current_session:
                self.current_session.messages_processed += len(unprocessed_messages)
                self.current_session.filtered_messages += len(filtered_messages)
                self.current_session.quality_score = quality_metrics.consistency_score
                self.current_session.success = success
                # æ¯æ¬¡æ‰¹æ¬¡ç»“æŸéƒ½ä¿å­˜å½“å‰ä¼šè¯çŠ¶æ€
                await self.db_manager.save_learning_session_record(group_id, self.current_session.__dict__)
            
            # 13. ã€æ–°å¢ã€‘å­¦ä¹ æˆåŠŸåæ›´æ–°å¢é‡å†…å®¹åˆ°system_prompt
            if success:
                try:
                    # ä½¿ç”¨å›è°ƒå‡½æ•°è¿›è¡Œå¢é‡æ›´æ–°ï¼Œé™ä½è€¦åˆæ€§
                    if self.update_system_prompt_callback:
                        await self.update_system_prompt_callback(group_id)
                        logger.info(f"å®šæ—¶æ›´æ–°å¢é‡å†…å®¹å®Œæˆ: {group_id}")
                    else:
                        logger.debug("æœªè®¾ç½®å¢é‡æ›´æ–°å›è°ƒå‡½æ•°ï¼Œè·³è¿‡å¢é‡å†…å®¹æ›´æ–°")
                except Exception as e:
                    logger.error(f"å®šæ—¶å¢é‡å†…å®¹æ›´æ–°å¤±è´¥: {e}")
            
            # 14. ã€æ–°å¢ã€‘å®šæœŸæ‰§è¡Œç­–ç•¥ä¼˜åŒ–
            if success and self.current_session and self.current_session.messages_processed % 500 == 0:
                try:
                    await self.ml_analyzer.reinforcement_strategy_optimization(group_id)
                    logger.info("æ‰§è¡Œäº†ç­–ç•¥ä¼˜åŒ–æ£€æŸ¥")
                except Exception as e:
                    logger.error(f"ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {e}")
            
            # è®°å½•æ‰¹æ¬¡è€—æ—¶
            batch_duration = (datetime.now() - batch_start_time).total_seconds()
            logger.info(f"å­¦ä¹ æ‰¹æ¬¡å®Œæˆï¼Œè€—æ—¶: {batch_duration:.2f}ç§’")
            
        except Exception as e:
            logger.error(f"å­¦ä¹ æ‰¹æ¬¡æ‰§è¡Œå¤±è´¥: {e}")
            raise LearningError(f"å­¦ä¹ æ‰¹æ¬¡æ‰§è¡Œå¤±è´¥: {str(e)}")

    async def _execute_learning_batch_background(self, group_id: str):
        """åœ¨åå°æ‰§è¡Œå­¦ä¹ æ‰¹æ¬¡ - ä½¿ç”¨çº¿ç¨‹æ± é¿å…é˜»å¡ä¸»åç¨‹"""
        try:
            batch_start_time = datetime.now()
            
            # 1. å¼‚æ­¥è·å–æ•°æ®
            unprocessed_messages = await self.message_collector.get_unprocessed_messages(
                limit=self.batch_size
            )
            
            if not unprocessed_messages:
                logger.debug("æ²¡æœ‰æœªå¤„ç†çš„æ¶ˆæ¯ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                return
            
            logger.info(f"å¼€å§‹åå°å¤„ç† {len(unprocessed_messages)} æ¡æ¶ˆæ¯")
            
            # 2. å¹¶è¡Œæ‰§è¡Œç­›é€‰å’Œè·å–äººæ ¼
            filtered_messages, current_persona = await asyncio.gather(
                self._filter_messages_with_context(unprocessed_messages),
                self._get_current_persona(group_id),
                return_exceptions=True
            )
            
            # å¤„ç†å¼‚å¸¸ç»“æœ
            if isinstance(filtered_messages, Exception):
                logger.error(f"æ¶ˆæ¯ç­›é€‰å¼‚å¸¸: {filtered_messages}")
                filtered_messages = []
            
            if isinstance(current_persona, Exception):
                logger.error(f"è·å–äººæ ¼å¼‚å¸¸: {current_persona}")
                current_persona = {}
            
            if not filtered_messages:
                logger.debug("æ²¡æœ‰é€šè¿‡ç­›é€‰çš„æ¶ˆæ¯")
                await self._mark_messages_processed(unprocessed_messages)
                return
            
            # 3. å¹¶è¡Œæ‰§è¡Œå¼ºåŒ–å­¦ä¹ å’Œé£æ ¼åˆ†æ
            reinforcement_result, style_analysis = await asyncio.gather(
                self._execute_reinforcement_learning_background(group_id, filtered_messages, current_persona),
                self._execute_style_analysis_background(group_id, filtered_messages),
                return_exceptions=True
            )
            
            # å¤„ç†å¼‚å¸¸ç»“æœ
            if isinstance(reinforcement_result, Exception):
                logger.error(f"å¼ºåŒ–å­¦ä¹ å¼‚å¸¸: {reinforcement_result}")
                reinforcement_result = {}
            
            if isinstance(style_analysis, Exception):
                logger.error(f"é£æ ¼åˆ†æå¼‚å¸¸: {style_analysis}")
                style_analysis = {}
            
            # 4. åŠ¨æ€è°ƒæ•´å­¦ä¹ å‚æ•°ï¼ˆåŸºäºå¼ºåŒ–å­¦ä¹ ç»“æœï¼‰
            if reinforcement_result and reinforcement_result.get('optimization_strategy'):
                confidence_threshold = reinforcement_result.get('optimization_strategy', {}).get('confidence_threshold', self.config.confidence_threshold)
                if confidence_threshold > self.config.confidence_threshold:
                    filtered_messages = [msg for msg in filtered_messages 
                                       if msg.get('relevance_score', 0) >= confidence_threshold]
                    logger.info(f"æ ¹æ®å¼ºåŒ–å­¦ä¹ è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼: {self.config.confidence_threshold} -> {confidence_threshold}")
            
            # 5. ä½¿ç”¨æç‚¼æ¨¡å‹ç”Ÿæˆæ›´æ–°åçš„äººæ ¼
            updated_persona = await self._generate_updated_persona_with_refinement(
                group_id, current_persona, style_analysis
            )
            
            # 6. å¼ºåŒ–å­¦ä¹ å¢é‡å¾®è°ƒ
            if self.config.enable_ml_analysis and updated_persona:
                tuning_result = await self._execute_incremental_tuning_background(
                    group_id, current_persona, updated_persona
                )
                if tuning_result and tuning_result.get('updated_persona'):
                    updated_persona.update(tuning_result.get('updated_persona'))
                    logger.info(f"åº”ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ï¼Œé¢„æœŸæ”¹è¿›: {tuning_result.get('performance_prediction', {}).get('expected_improvement', 0)}")
            
            # 7. è´¨é‡è¯„ä¼°å’Œåº”ç”¨æ›´æ–°
            await self._finalize_learning_batch(
                group_id, current_persona, updated_persona, filtered_messages, 
                unprocessed_messages, batch_start_time
            )
            
        except Exception as e:
            logger.error(f"åå°å­¦ä¹ æ‰¹æ¬¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)

    async def _execute_reinforcement_learning_background(self, group_id: str, filtered_messages, current_persona):
        """åœ¨åå°æ‰§è¡Œå¼ºåŒ–å­¦ä¹ """
        if not self.config.enable_ml_analysis:
            return {}
        
        try:
            return await self.ml_analyzer.reinforcement_memory_replay(
                group_id, filtered_messages, current_persona
            )
        except Exception as e:
            logger.error(f"åå°å¼ºåŒ–å­¦ä¹ å¤±è´¥: {e}")
            return {}

    async def _execute_style_analysis_background(self, group_id: str, filtered_messages):
        """åœ¨åå°æ‰§è¡Œé£æ ¼åˆ†æ"""
        try:
            return await self.style_analyzer.analyze_conversation_style(group_id, filtered_messages)
        except Exception as e:
            logger.error(f"åå°é£æ ¼åˆ†æå¤±è´¥: {e}")
            return {}

    async def _execute_incremental_tuning_background(self, group_id: str, base_persona, incremental_updates):
        """åœ¨åå°æ‰§è¡Œå¢é‡å¾®è°ƒ"""
        try:
            return await self.ml_analyzer.reinforcement_incremental_tuning(
                group_id, base_persona, incremental_updates
            )
        except Exception as e:
            logger.error(f"åå°å¢é‡å¾®è°ƒå¤±è´¥: {e}")
            return {}

    async def _finalize_learning_batch(self, group_id: str, current_persona, updated_persona, 
                                     filtered_messages, unprocessed_messages, batch_start_time):
        """å®Œæˆå­¦ä¹ æ‰¹æ¬¡çš„æœ€ç»ˆå¤„ç†"""
        try:
            # è´¨é‡ç›‘æ§è¯„ä¼°
            # ç¡®ä¿å‚æ•°ä¸ä¸ºNoneï¼Œæä¾›é»˜è®¤å€¼
            if current_persona is None:
                current_persona = {"prompt": "é»˜è®¤äººæ ¼"}
                logger.warning("_finalize_learning_batch: current_personaä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤å€¼")
            
            if updated_persona is None:
                updated_persona = current_persona.copy()
                logger.warning("_finalize_learning_batch: updated_personaä¸ºNoneï¼Œä½¿ç”¨current_personaçš„å‰¯æœ¬")
                
            quality_metrics = await self.quality_monitor.evaluate_learning_batch(
                current_persona, updated_persona, filtered_messages
            )

            # åº”ç”¨å­¦ä¹ æ›´æ–°ï¼ˆå¯¹è¯é£æ ¼å­¦ä¹ ä¸åˆ¤æ–­è´¨é‡ç›´æ¥åº”ç”¨ï¼Œäººæ ¼å­¦ä¹ åŠ å…¥å®¡æŸ¥ï¼‰
            await self._apply_learning_updates(group_id, {}, filtered_messages, current_persona, updated_persona, quality_metrics, relearn_mode=False, ml_tuning_info=None)  # style_analysis may be empty, åå°å­¦ä¹ ä¸ä½¿ç”¨relearnæ¨¡å¼
            logger.info(f"å­¦ä¹ æ›´æ–°å·²åº”ç”¨ï¼ˆå¯¹è¯é£æ ¼å­¦ä¹ å·²å®Œæˆï¼Œäººæ ¼å­¦ä¹ å·²åŠ å…¥å®¡æŸ¥ï¼‰ï¼Œè´¨é‡å¾—åˆ†: {quality_metrics.consistency_score:.3f} for group {group_id}")
            success = True  # å¯¹è¯é£æ ¼å­¦ä¹ æ€»æ˜¯æˆåŠŸ
            
            # ã€æ–°å¢ã€‘è®°å½•å­¦ä¹ æ‰¹æ¬¡åˆ°æ•°æ®åº“ï¼Œä¾›webuiæŸ¥è¯¢ä½¿ç”¨
            batch_name = f"batch_{group_id}_{int(time.time())}"
            start_time = batch_start_time.timestamp()
            end_time = time.time()
            
            # è¿æ¥åˆ°å…¨å±€æ¶ˆæ¯æ•°æ®åº“è®°å½•å­¦ä¹ æ‰¹æ¬¡
            async with self.db_manager.get_db_connection() as conn:
                cursor = await conn.cursor()
                
                try:
                    await cursor.execute('''
                        INSERT INTO learning_batches
                        (group_id, batch_name, start_time, end_time, quality_score, processed_messages,
                         message_count, filtered_count, success, error_message)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        group_id,
                        batch_name,
                        start_time,
                        end_time,
                        quality_metrics.consistency_score,
                        len(unprocessed_messages),
                        len(unprocessed_messages),
                        len(filtered_messages),
                        success,
                        None  # å¯¹è¯é£æ ¼å­¦ä¹ æ€»æ˜¯æˆåŠŸï¼Œä¸è®°å½•é”™è¯¯
                    ))
                    await conn.commit()
                    logger.debug(f"å­¦ä¹ æ‰¹æ¬¡è®°å½•å·²ä¿å­˜: {batch_name}")
                except Exception as e:
                    logger.error(f"ä¿å­˜å­¦ä¹ æ‰¹æ¬¡è®°å½•å¤±è´¥: {e}")
                finally:
                    await cursor.close()
            
            # ä¿å­˜å­¦ä¹ æ€§èƒ½è®°å½•
            await self.db_manager.save_learning_performance_record(group_id, {
                'session_id': self.current_session.session_id if self.current_session else '',
                'timestamp': time.time(),
                'quality_score': quality_metrics.consistency_score,
                'learning_time': end_time - start_time,
                'success': success,
                'successful_pattern': json.dumps({}),
                'failed_pattern': ''  # å¯¹è¯é£æ ¼å­¦ä¹ æ€»æ˜¯æˆåŠŸï¼Œä¸è®°å½•å¤±è´¥
            })
            
            # æ ‡è®°æ¶ˆæ¯ä¸ºå·²å¤„ç†
            await self._mark_messages_processed(unprocessed_messages)
            
            # æ›´æ–°ä¼šè¯ç»Ÿè®¡
            if self.current_session:
                self.current_session.messages_processed += len(unprocessed_messages)
                self.current_session.filtered_messages += len(filtered_messages)
                self.current_session.quality_score = quality_metrics.consistency_score
                self.current_session.success = success
                await self.db_manager.save_learning_session_record(group_id, self.current_session.__dict__)
            
            # å®šæœŸæ‰§è¡Œç­–ç•¥ä¼˜åŒ– - ä¸é˜»å¡ä¸»æµç¨‹
            if success and self.current_session and self.current_session.messages_processed % 500 == 0:
                asyncio.create_task(self._execute_strategy_optimization_background(group_id))
            
            batch_duration = end_time - start_time
            logger.info(f"åå°å­¦ä¹ æ‰¹æ¬¡å®Œæˆï¼Œè€—æ—¶: {batch_duration:.2f}ç§’")
            
        except Exception as e:
            logger.error(f"å®Œæˆå­¦ä¹ æ‰¹æ¬¡å¤±è´¥: {e}")

    async def _execute_strategy_optimization_background(self, group_id: str):
        """åœ¨åå°æ‰§è¡Œç­–ç•¥ä¼˜åŒ–ï¼Œä¸é˜»å¡ä¸»æµç¨‹"""
        try:
            await self.ml_analyzer.reinforcement_strategy_optimization(group_id)
            logger.info("åå°ç­–ç•¥ä¼˜åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"åå°ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {e}")

    async def _generate_updated_persona_with_refinement(self, group_id: str, current_persona: Dict[str, Any], style_analysis: Any) -> Dict[str, Any]:
        """ä½¿ç”¨æç‚¼æ¨¡å‹ç”Ÿæˆæ›´æ–°åçš„äººæ ¼"""
        try:
            # æ­£ç¡®å¤„ç†AnalysisResultå¯¹è±¡å’Œå­—å…¸ç±»å‹
            from ..core.interfaces import AnalysisResult
            
            if isinstance(style_analysis, AnalysisResult):
                # å¦‚æœæ˜¯AnalysisResultå¯¹è±¡ï¼Œæå–dataå±æ€§
                analysis_data = style_analysis.data if style_analysis.data else {}
                logger.debug(f"ä»AnalysisResultæå–data: success={style_analysis.success}, confidence={style_analysis.confidence}")
            elif isinstance(style_analysis, dict):
                analysis_data = style_analysis
                logger.debug("ä½¿ç”¨å­—å…¸å½¢å¼çš„style_analysis")
            elif hasattr(style_analysis, 'data'):
                # å…¼å®¹å…¶ä»–å…·æœ‰dataå±æ€§çš„å¯¹è±¡
                analysis_data = style_analysis.data if style_analysis.data else {}
                logger.debug(f"ä»å¯¹è±¡æå–dataå±æ€§: {type(style_analysis)}")
            else:
                analysis_data = {}
                logger.warning(f"style_analysisç±»å‹ä¸æ­£ç¡®: {type(style_analysis)}, ä½¿ç”¨ç©ºå­—å…¸")
            
            # ä½¿ç”¨å¤šç»´åº¦åˆ†æå™¨çš„æ¡†æ¶é€‚é…å™¨ç”Ÿæˆäººæ ¼æ›´æ–°
            if hasattr(self.multidimensional_analyzer, 'llm_adapter') and self.multidimensional_analyzer.llm_adapter:
                llm_adapter = self.multidimensional_analyzer.llm_adapter
                
                if llm_adapter.has_refine_provider() and llm_adapter.providers_configured >= 2:
                    # å‡†å¤‡è¾“å…¥æ•°æ®
                    current_persona_json = json.dumps(current_persona, ensure_ascii=False, indent=2, default=self._json_serializer)
                    style_analysis_json = json.dumps(analysis_data, ensure_ascii=False, indent=2, default=self._json_serializer)
                    
                    # è°ƒç”¨æ¡†æ¶é€‚é…å™¨
                    response = await llm_adapter.refine_chat_completion(
                        prompt=self.prompts.PROGRESSIVE_LEARNING_GENERATE_UPDATED_PERSONA_PROMPT.format(
                            current_persona_json=current_persona_json,
                            style_analysis_json=style_analysis_json
                        ),
                        temperature=0.6
                    )
                    
                    if response:
                        # æ¸…ç†å“åº”æ–‡æœ¬ï¼Œç§»é™¤markdownæ ‡è¯†ç¬¦ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„json_utilså·¥å…·ï¼‰
                        clean_response = clean_llm_json_response(response)

                        try:
                            updated_persona = safe_parse_llm_json(clean_response)
                            logger.info("ä½¿ç”¨æç‚¼æ¨¡å‹æˆåŠŸç”Ÿæˆæ›´æ–°åçš„äººæ ¼")
                            return updated_persona
                        except json.JSONDecodeError as e:
                            logger.error(f"æç‚¼æ¨¡å‹è¿”å›çš„JSONæ ¼å¼ä¸æ­£ç¡®: {e}, å“åº”: {clean_response}")
                            return await self._generate_updated_persona(group_id, current_persona, style_analysis)
                else:
                    logger.warning("æç‚¼æ¨¡å‹Provideræœªé…ç½®ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•ç”Ÿæˆäººæ ¼")
                    return await self._generate_updated_persona(group_id, current_persona, style_analysis)
            else:
                logger.warning("æ¡†æ¶é€‚é…å™¨æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•ç”Ÿæˆäººæ ¼")
                return await self._generate_updated_persona(group_id, current_persona, style_analysis)
            
        except Exception as e:
            logger.error(f"ä½¿ç”¨æç‚¼æ¨¡å‹ç”Ÿæˆäººæ ¼å¤±è´¥: {e}")
            return await self._generate_updated_persona(group_id, current_persona, style_analysis)

    def _json_serializer(self, obj):
        """è‡ªå®šä¹‰JSONåºåˆ—åŒ–å™¨ï¼Œå¤„ç†ä¸èƒ½ç›´æ¥åºåˆ—åŒ–çš„å¯¹è±¡"""
        try:
            # æ£€æŸ¥å¯¹è±¡çš„ç±»å‹åç§°ï¼Œé¿å…å¾ªç¯å¯¼å…¥
            class_name = obj.__class__.__name__
            
            if class_name == 'StyleProfile':
                # å°†StyleProfileå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
                if hasattr(obj, 'to_dict') and callable(getattr(obj, 'to_dict')):
                    return obj.to_dict()
                elif hasattr(obj, '__dict__'):
                    return obj.__dict__
            elif hasattr(obj, 'to_dict') and callable(getattr(obj, 'to_dict')):
                # å¯¹äºæœ‰to_dictæ–¹æ³•çš„å¯¹è±¡
                return obj.to_dict()
            elif hasattr(obj, '__dict__'):
                # å¯¹äºå…¶ä»–dataclassæˆ–å¯¹è±¡ï¼Œå°è¯•ä½¿ç”¨__dict__
                return obj.__dict__
            else:
                # å¦‚æœéƒ½ä¸è¡Œï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                return str(obj)
        except Exception as e:
            logger.warning(f"JSONåºåˆ—åŒ–å¯¹è±¡æ—¶å‡ºç°é”™è¯¯: {e}, å¯¹è±¡ç±»å‹: {type(obj)}, è½¬æ¢ä¸ºå­—ç¬¦ä¸²")
            return str(obj)

    # async def _execute_learning_batch(self):
    #     """æ‰§è¡Œä¸€ä¸ªå­¦ä¹ æ‰¹æ¬¡"""
    #     try:
    #         batch_start_time = datetime.now()
            
    #         # 1. è·å–æœªå¤„ç†çš„æ¶ˆæ¯
    #         unprocessed_messages = await self.message_collector.get_unprocessed_messages(
    #             limit=self.batch_size
    #         )
            
    #         if not unprocessed_messages:
    #             logger.debug("æ²¡æœ‰æœªå¤„ç†çš„æ¶ˆæ¯ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
    #             return
            
    #         logger.info(f"å¼€å§‹å¤„ç† {len(unprocessed_messages)} æ¡æ¶ˆæ¯")
            
    #         # 2. ä½¿ç”¨å¤šç»´åº¦åˆ†æå™¨ç­›é€‰æ¶ˆæ¯
    #         filtered_messages = await self._filter_messages_with_context(unprocessed_messages)
            
    #         if not filtered_messages:
    #             logger.debug("æ²¡æœ‰é€šè¿‡ç­›é€‰çš„æ¶ˆæ¯")
    #             await self._mark_messages_processed(unprocessed_messages)
    #             return
            
    #         # 3. ä½¿ç”¨é£æ ¼åˆ†æå™¨æ·±åº¦åˆ†æ
    #         style_analysis = await self.style_analyzer.analyze_conversation_style(filtered_messages)
            
    #         # 4. è·å–å½“å‰äººæ ¼è®¾ç½®
    #         current_persona = await self._get_current_persona()
            
    #         # 5. è´¨é‡ç›‘æ§è¯„ä¼°
    #         quality_metrics = await self.quality_monitor.evaluate_learning_batch(
    #             current_persona, 
    #             await self._generate_updated_persona(current_persona, style_analysis),
    #             filtered_messages
    #         )
            
    #         # 6. æ ¹æ®è´¨é‡è¯„ä¼°å†³å®šæ˜¯å¦åº”ç”¨æ›´æ–°
    #         if quality_metrics.consistency_score >= self.quality_threshold:
    #             await self._apply_learning_updates(style_analysis, filtered_messages)
    #             logger.info(f"å­¦ä¹ æ›´æ–°å·²åº”ç”¨ï¼Œè´¨é‡å¾—åˆ†: {quality_metrics.consistency_score:.3f}")
    #         else:
    #             logger.warning(f"å­¦ä¹ è´¨é‡ä¸è¾¾æ ‡ï¼Œè·³è¿‡æ›´æ–°ï¼Œå¾—åˆ†: {quality_metrics.consistency_score:.3f}")
            
    #         # 7. æ ‡è®°æ¶ˆæ¯ä¸ºå·²å¤„ç†
    #         await self._mark_messages_processed(unprocessed_messages)
            
    #         # 8. æ›´æ–°å­¦ä¹ ä¼šè¯ç»Ÿè®¡
    #         if self.current_session:
    #             self.current_session.messages_processed += len(unprocessed_messages)
    #             self.current_session.filtered_messages += len(filtered_messages)
    #             self.current_session.quality_score = quality_metrics.consistency_score
            
    #         # è®°å½•æ‰¹æ¬¡è€—æ—¶
    #         batch_duration = (datetime.now() - batch_start_time).total_seconds()
    #         logger.info(f"å­¦ä¹ æ‰¹æ¬¡å®Œæˆï¼Œè€—æ—¶: {batch_duration:.2f}ç§’")
            
    #     except Exception as e:
    #         logger.error(f"å­¦ä¹ æ‰¹æ¬¡æ‰§è¡Œå¤±è´¥: {e}")
    #         raise LearningError(f"å­¦ä¹ æ‰¹æ¬¡æ‰§è¡Œå¤±è´¥: {str(e)}")

    async def _filter_messages_with_context(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ä½¿ç”¨å¤šç»´åº¦åˆ†æè¿›è¡Œæ™ºèƒ½ç­›é€‰"""
        filtered = []
        
        # æ·»åŠ æ‰¹é‡å¤„ç†é™åˆ¶ï¼Œé˜²æ­¢è¿‡åº¦çš„LLMè°ƒç”¨
        max_messages_to_analyze = min(len(messages), 10)  # å‡å°‘åˆ°æ¯æ‰¹æœ€å¤šåˆ†æ10æ¡æ¶ˆæ¯
        messages_to_process = messages[:max_messages_to_analyze]
        
        logger.info(f"å¼€å§‹ç­›é€‰ {len(messages_to_process)} æ¡æ¶ˆæ¯ (åŸå§‹: {len(messages)} æ¡ï¼Œé™åˆ¶æ‰¹é‡å¤§å°ä»¥å‡å°‘LLMè°ƒç”¨)")
        
        for i, message in enumerate(messages_to_process):
            try:
                # æ·»åŠ å¤„ç†è¿›åº¦æ—¥å¿—
                if i % 3 == 0:  # å‡å°‘æ—¥å¿—é¢‘ç‡
                    logger.debug(f"ç­›é€‰è¿›åº¦: {i+1}/{len(messages_to_process)}")
                
                # ä½¿ç”¨ä¸“é—¨çš„æ‰¹é‡åˆ†ææ–¹æ³•ï¼Œä¸éœ€è¦äº‹ä»¶å¯¹è±¡
                context_analysis = await self.multidimensional_analyzer.analyze_message_batch(
                    message['message'],
                    sender_id=message.get('sender_id', ''),
                    sender_name=message.get('sender_name', ''),
                    group_id=message.get('group_id', ''),
                    timestamp=message.get('timestamp', time.time())
                )
                
                # æ ¹æ®ä¸Šä¸‹æ–‡ç›¸å…³æ€§ç­›é€‰
                relevance = context_analysis.get('contextual_relevance', 0.0)
                if relevance >= self.config.relevance_threshold:
                    # æ·»åŠ ç­›é€‰ä¿¡æ¯åˆ°æ¶ˆæ¯
                    message['context_analysis'] = context_analysis
                    message['relevance_score'] = relevance
                    filtered.append(message)
                    
                    # ä¿å­˜åˆ°ç­›é€‰æ¶ˆæ¯è¡¨
                    await self.message_collector.add_filtered_message({
                        'raw_message_id': message.get('id'),
                        'message': message['message'],
                        'sender_id': message.get('sender_id', ''),
                        'confidence': relevance,
                        'filter_reason': 'context_relevance',
                        'timestamp': message.get('timestamp', time.time())
                    })
                    
            except Exception as e:
                logger.warning(f"æ¶ˆæ¯ç­›é€‰å¤±è´¥: {e}")
                continue
        
        # å¦‚æœè¿˜æœ‰æœªå¤„ç†çš„æ¶ˆæ¯ï¼Œè®°å½•æ—¥å¿—
        if len(messages) > max_messages_to_analyze:
            logger.info(f"ç”±äºæ‰¹é‡å¤„ç†é™åˆ¶ï¼Œè·³è¿‡äº† {len(messages) - max_messages_to_analyze} æ¡æ¶ˆæ¯ï¼Œå‡å°‘LLMè°ƒç”¨é¢‘ç‡")
        
        logger.info(f"ç­›é€‰å®Œæˆ: {len(filtered)} æ¡æ¶ˆæ¯é€šè¿‡ç­›é€‰")
        return filtered

    async def _get_current_persona(self, group_id: str) -> Dict[str, Any]:
        """è·å–å½“å‰äººæ ¼è®¾ç½® (é’ˆå¯¹ç‰¹å®šç¾¤ç»„)"""
        try:
            # é€šè¿‡ PersonaManagerService è·å–å½“å‰äººæ ¼
            persona = await self.persona_manager.get_current_persona(group_id)
            if persona:
                return persona

            # å¦‚æœæ²¡æœ‰ç‰¹å®šç¾¤ç»„çš„äººæ ¼ï¼Œå°è¯•ä»æ¡†æ¶è·å–é»˜è®¤äººæ ¼
            if hasattr(self.context, 'persona_manager') and self.context.persona_manager:
                try:
                    default_persona = await self.context.persona_manager.get_default_persona_v3(group_id)
                    if default_persona:
                        return {
                            'prompt': default_persona.get('prompt', 'é»˜è®¤äººæ ¼'),
                            'name': default_persona.get('name', 'default'),
                            'style_parameters': {},
                            'last_updated': datetime.now().isoformat()
                        }
                except Exception as e:
                    logger.warning(f"ä»æ¡†æ¶è·å–é»˜è®¤äººæ ¼å¤±è´¥: {e}")

            # å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æ„
            return {
                'prompt': "é»˜è®¤äººæ ¼",
                'name': 'default',
                'style_parameters': {},
                'last_updated': datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"è·å–å½“å‰äººæ ¼å¤±è´¥ for group {group_id}: {e}")
            return {'prompt': 'é»˜è®¤äººæ ¼', 'name': 'default', 'style_parameters': {}}

    async def _generate_updated_persona(self, group_id: str, current_persona: Dict[str, Any], style_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ›´æ–°åçš„äººæ ¼ - ç›´æ¥åœ¨åŸæœ‰æ–‡æœ¬åé¢è¿½åŠ å¢é‡å­¦ä¹ å†…å®¹"""
        try:
            # ä½¿ç”¨æ–°ç‰ˆæ¡†æ¶APIè·å–å½“å‰äººæ ¼
            if not hasattr(self.context, 'persona_manager') or not self.context.persona_manager:
                logger.warning(f"æ— æ³•è·å–PersonaManager for group {group_id}")
                return current_persona

            default_persona = await self.context.persona_manager.get_default_persona_v3(group_id)
            if not default_persona:
                logger.warning(f"æ— æ³•è·å–å½“å‰äººæ ¼ for group {group_id}")
                return current_persona

            # è·å–åŸæœ‰äººæ ¼æ–‡æœ¬
            original_prompt = default_persona.get('prompt', '')

            # æ„å»ºå¢é‡å­¦ä¹ å†…å®¹
            learning_content = []

            # æ­£ç¡®å¤„ç†AnalysisResultå¯¹è±¡å’Œå­—å…¸ç±»å‹
            from ..core.interfaces import AnalysisResult

            if isinstance(style_analysis, AnalysisResult):
                # å¦‚æœæ˜¯AnalysisResultå¯¹è±¡ï¼Œæå–dataå±æ€§
                analysis_data = style_analysis.data if style_analysis.data else {}
                logger.debug(f"ä»AnalysisResultæå–data: success={style_analysis.success}, confidence={style_analysis.confidence}")
            elif isinstance(style_analysis, dict):
                analysis_data = style_analysis
                logger.debug("ä½¿ç”¨å­—å…¸å½¢å¼çš„style_analysis")
            elif hasattr(style_analysis, 'data'):
                # å…¼å®¹å…¶ä»–å…·æœ‰dataå±æ€§çš„å¯¹è±¡
                analysis_data = style_analysis.data if style_analysis.data else {}
                logger.debug(f"ä»å¯¹è±¡æå–dataå±æ€§: {type(style_analysis)}")
            else:
                analysis_data = {}
                logger.warning(f"style_analysisç±»å‹ä¸æ­£ç¡®: {type(style_analysis)}, ä½¿ç”¨ç©ºå­—å…¸")

            # âœ… ä¿®å¤ï¼šä»å®é™…çš„ style_analysis ç»“æ„ä¸­æå–å†…å®¹
            # ä¼˜å…ˆæå– enhanced_prompt å’Œ learning_insightsï¼ˆå¦‚æœæœ‰ï¼‰
            if 'enhanced_prompt' in analysis_data:
                learning_content.append(analysis_data['enhanced_prompt'])
                logger.debug("æ‰¾åˆ° enhanced_prompt å­—æ®µ")

            if 'learning_insights' in analysis_data:
                insights = analysis_data['learning_insights']
                if insights:
                    learning_content.append(insights)
                    logger.debug("æ‰¾åˆ° learning_insights å­—æ®µ")

            # âœ… æ–°å¢ï¼šä» style_analysis å­—æ®µæå–å†…å®¹ï¼ˆStyleAnalyzerè¿”å›çš„ç»“æ„ï¼‰
            if not learning_content and 'style_analysis' in analysis_data:
                style_report = analysis_data['style_analysis']
                if isinstance(style_report, dict):
                    # æå–å…³é”®çš„é£æ ¼åˆ†æå†…å®¹
                    extracted_parts = []

                    # æå–æ–‡æœ¬é£æ ¼æè¿°
                    if 'text_style' in style_report:
                        extracted_parts.append(f"æ–‡æœ¬é£æ ¼: {style_report['text_style']}")

                    # æå–è¡¨è¾¾ç‰¹ç‚¹
                    if 'expression_features' in style_report:
                        features = style_report['expression_features']
                        if isinstance(features, list):
                            extracted_parts.append(f"è¡¨è¾¾ç‰¹ç‚¹: {', '.join(features)}")
                        elif isinstance(features, str):
                            extracted_parts.append(f"è¡¨è¾¾ç‰¹ç‚¹: {features}")

                    # æå–è¯­æ°”å€¾å‘
                    if 'tone' in style_report:
                        extracted_parts.append(f"è¯­æ°”å€¾å‘: {style_report['tone']}")

                    # æå–è¯é¢˜åå¥½
                    if 'topics' in style_report:
                        topics = style_report['topics']
                        if isinstance(topics, list):
                            extracted_parts.append(f"è¯é¢˜åå¥½: {', '.join(topics)}")
                        elif isinstance(topics, str):
                            extracted_parts.append(f"è¯é¢˜åå¥½: {topics}")

                    if extracted_parts:
                        learning_content.append("ã€å¯¹è¯é£æ ¼å­¦ä¹ ç»“æœã€‘\n" + "\n".join(extracted_parts))
                        logger.debug(f"ä» style_analysis æå–äº† {len(extracted_parts)} ä¸ªé£æ ¼ç‰¹å¾")

            # âœ… æ–°å¢ï¼šå¦‚æœè¿˜æ˜¯æ²¡æœ‰å†…å®¹ï¼Œä» style_profile æå–
            if not learning_content and 'style_profile' in analysis_data:
                style_profile = analysis_data['style_profile']
                if isinstance(style_profile, dict):
                    profile_parts = []

                    # æå–è¯­æ°”å¼ºåº¦
                    if 'tone_intensity' in style_profile:
                        profile_parts.append(f"è¯­æ°”å¼ºåº¦: {style_profile['tone_intensity']:.2f}")

                    # æå–æƒ…æ„Ÿå€¾å‘
                    if 'sentiment' in style_profile:
                        profile_parts.append(f"æƒ…æ„Ÿå€¾å‘: {style_profile['sentiment']:.2f}")

                    # æå–è¯æ±‡ä¸°å¯Œåº¦
                    if 'vocabulary_richness' in style_profile:
                        profile_parts.append(f"è¯æ±‡ä¸°å¯Œåº¦: {style_profile['vocabulary_richness']:.2f}")

                    if profile_parts:
                        learning_content.append("ã€é£æ ¼é‡åŒ–æŒ‡æ ‡ã€‘\n" + "\n".join(profile_parts))
                        logger.debug(f"ä» style_profile æå–äº† {len(profile_parts)} ä¸ªé‡åŒ–æŒ‡æ ‡")

            # âœ… æ–°å¢ï¼šå¦‚æœè¿˜æ˜¯æ²¡æœ‰å†…å®¹ï¼Œå°è¯•æå–ä»»ä½•æœ‰ç”¨çš„ä¿¡æ¯
            if not learning_content:
                # å°è¯•ä»é¡¶å±‚æå–ä»»ä½•çœ‹èµ·æ¥æœ‰ç”¨çš„å­—æ®µ
                useful_fields = ['summary', 'description', 'analysis', 'insights', 'findings']
                for field in useful_fields:
                    if field in analysis_data and analysis_data[field]:
                        learning_content.append(f"ã€{field}ã€‘\n{analysis_data[field]}")
                        logger.debug(f"ä»é¡¶å±‚å­—æ®µ {field} æå–äº†å†…å®¹")
                        break

            # ç›´æ¥åœ¨åŸæœ‰æ–‡æœ¬åé¢è¿½åŠ æ–°å†…å®¹
            if learning_content:
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')
                new_content = f"\n\nã€å­¦ä¹ æ›´æ–° - {timestamp}ã€‘\n" + "\n".join(learning_content)

                # åˆ›å»ºæ›´æ–°åçš„äººæ ¼ (Personalityæ˜¯TypedDict)
                updated_persona = dict(default_persona)
                updated_persona['prompt'] = original_prompt + new_content
                updated_persona['last_updated'] = timestamp

                logger.info(f"âœ… æˆåŠŸè¿½åŠ  {len(learning_content)} é¡¹å­¦ä¹ å†…å®¹åˆ°äººæ ¼ for group {group_id}")
                return updated_persona
            else:
                logger.warning(f"âš ï¸ style_analysisä¸­æ²¡æœ‰å¯æå–çš„å­¦ä¹ å†…å®¹ for group {group_id}, æ•°æ®ç»“æ„: {list(analysis_data.keys())}")
                # å³ä½¿æ²¡æœ‰å­¦ä¹ å†…å®¹ï¼Œä¹Ÿè¿”å›ä¸€ä¸ªå‰¯æœ¬ä»¥ç¡®ä¿æœ‰updated_personaç”¨äºå¯¹æ¯”
                return dict(default_persona)

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ›´æ–°äººæ ¼å¤±è´¥ for group {group_id}: {e}", exc_info=True)
            return current_persona

    async def _apply_learning_updates(self, group_id: str, style_analysis: Dict[str, Any], messages: List[Dict[str, Any]],
                                     current_persona: Dict[str, Any] = None, updated_persona: Dict[str, Any] = None,
                                     quality_metrics = None, relearn_mode: bool = False, ml_tuning_info: Dict[str, Any] = None):
        """åº”ç”¨å­¦ä¹ æ›´æ–°ï¼Œå¹¶åˆ›å»ºäººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•

        Args:
            group_id: ç¾¤ç»„ID
            style_analysis: é£æ ¼åˆ†æç»“æœ
            messages: å¤„ç†çš„æ¶ˆæ¯åˆ—è¡¨
            current_persona: å½“å‰äººæ ¼
            updated_persona: æ›´æ–°åçš„äººæ ¼
            quality_metrics: è´¨é‡æŒ‡æ ‡
            relearn_mode: é‡æ–°å­¦ä¹ æ¨¡å¼ï¼Œä¸ºTrueæ—¶å³ä½¿å†…å®¹ç›¸åŒä¹Ÿåˆ›å»ºå®¡æŸ¥è®°å½•
            ml_tuning_info: å¼ºåŒ–å­¦ä¹ è°ƒä¼˜ä¿¡æ¯ï¼ˆåŒ…å«æ˜¯å¦ä½¿ç”¨ä¿å®ˆèåˆç­–ç•¥ç­‰ï¼‰
        """
        try:
            # 1. æ›´æ–°äººæ ¼promptï¼ˆé€šè¿‡ PersonaManagerServiceï¼‰
            logger.info(f"åº”ç”¨äººæ ¼æ›´æ–° for group {group_id}")
            update_success = await self.persona_manager.update_persona(group_id, style_analysis, messages)
            if not update_success:
                logger.error(f"é€šè¿‡ PersonaManagerService æ›´æ–°äººæ ¼å¤±è´¥ for group {group_id}")

            # 2. åˆ›å»ºäººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•ï¼ˆæ–°å¢ï¼‰
            # âœ… é‡æ–°å­¦ä¹ æ¨¡å¼ï¼šå³ä½¿å†…å®¹ç›¸åŒä¹Ÿåˆ›å»ºå®¡æŸ¥è®°å½•ï¼ˆä½œä¸ºé‡æ–°ç¡®è®¤ï¼‰
            # æ­£å¸¸æ¨¡å¼ï¼šåªåœ¨å†…å®¹ä¸åŒæ—¶åˆ›å»ºå®¡æŸ¥è®°å½•
            should_create_review = False
            if relearn_mode:
                # é‡æ–°å­¦ä¹ æ¨¡å¼ï¼šæ€»æ˜¯åˆ›å»ºå®¡æŸ¥è®°å½•
                should_create_review = bool(updated_persona and current_persona)
                if should_create_review:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å®è´¨æ€§å˜åŒ–
                    has_changes = updated_persona.get('prompt', '') != current_persona.get('prompt', '')
                    if has_changes:
                        logger.info(f"ğŸ”„ é‡æ–°å­¦ä¹ æ¨¡å¼ï¼šæ£€æµ‹åˆ°äººæ ¼å˜åŒ–ï¼Œåˆ›å»ºå®¡æŸ¥è®°å½•ï¼ˆgroup: {group_id}ï¼‰")
                    else:
                        logger.info(f"ğŸ”„ é‡æ–°å­¦ä¹ æ¨¡å¼ï¼šæœªæ£€æµ‹åˆ°äººæ ¼å˜åŒ–ï¼Œä½†ä»åˆ›å»ºå®¡æŸ¥è®°å½•ä¾›å®¡æ ¸ï¼ˆgroup: {group_id}ï¼‰")
                else:
                    logger.warning(f"âš ï¸ é‡æ–°å­¦ä¹ æ¨¡å¼ï¼šæ— æ³•åˆ›å»ºå®¡æŸ¥è®°å½• - updated_persona={bool(updated_persona)}, current_persona={bool(current_persona)}")
            elif updated_persona and current_persona and updated_persona.get('prompt') != current_persona.get('prompt'):
                # æ­£å¸¸æ¨¡å¼ï¼šåªåœ¨å†…å®¹ä¸åŒæ—¶åˆ›å»º
                should_create_review = True
                logger.info(f"âœ… æ­£å¸¸æ¨¡å¼ï¼šæ£€æµ‹åˆ°äººæ ¼å˜åŒ–ï¼Œåˆ›å»ºå®¡æŸ¥è®°å½•ï¼ˆgroup: {group_id}ï¼‰")
            else:
                logger.debug(f"ğŸ”¹ æ­£å¸¸æ¨¡å¼ï¼šäººæ ¼æœªå˜åŒ–ï¼Œè·³è¿‡å®¡æŸ¥è®°å½• - updated={bool(updated_persona)}, current={bool(current_persona)}, same_prompt={updated_persona.get('prompt') == current_persona.get('prompt') if updated_persona and current_persona else 'N/A'}")

            if should_create_review:
                try:
                    # æå–åŸäººæ ¼å’Œæ–°äººæ ¼çš„å®Œæ•´æ–‡æœ¬
                    original_prompt = current_persona.get('prompt', '')
                    new_prompt = updated_persona.get('prompt', '')

                    # âœ… è®¡ç®—æ–°å¢å†…å®¹ï¼ˆç”¨äºå•ç‹¬æ ‡è®°ï¼‰
                    if len(new_prompt) > len(original_prompt):
                        incremental_content = new_prompt[len(original_prompt):].strip()
                    else:
                        incremental_content = new_prompt

                    # âœ… å‡†å¤‡å…ƒæ•°æ®ï¼ˆåŒ…å«é«˜äº®ä¿¡æ¯ï¼‰
                    metadata = {
                        "progressive_learning": True,
                        "message_count": len(messages),
                        "style_analysis_fields": list(style_analysis.keys()) if style_analysis else [],
                        "original_prompt_length": len(original_prompt),
                        "new_prompt_length": len(new_prompt),
                        "incremental_content": incremental_content,  # âœ… å•ç‹¬è®°å½•å¢é‡å†…å®¹ï¼Œç”¨äºé«˜äº®
                        "incremental_start_pos": len(original_prompt),  # âœ… æ ‡è®°æ–°å¢å†…å®¹çš„èµ·å§‹ä½ç½®
                        "relearn_mode": relearn_mode  # âœ… æ ‡è®°æ˜¯å¦ä¸ºé‡æ–°å­¦ä¹ æ¨¡å¼
                    }

                    # âœ… æ·»åŠ å¼ºåŒ–å­¦ä¹ è°ƒä¼˜ä¿¡æ¯åˆ°å…ƒæ•°æ®
                    if ml_tuning_info:
                        metadata['ml_tuning'] = ml_tuning_info

                    # è·å–è´¨é‡å¾—åˆ†
                    confidence_score = quality_metrics.consistency_score if quality_metrics and hasattr(quality_metrics, 'consistency_score') else 0.5

                    # âœ… æ„å»º raw_analysis è¯´æ˜ï¼ˆåŒ…å«å¼ºåŒ–å­¦ä¹ ä¿¡æ¯ï¼‰
                    raw_analysis_parts = [f"åŸºäº{len(messages)}æ¡æ¶ˆæ¯çš„é£æ ¼åˆ†æ"]
                    if relearn_mode:
                        raw_analysis_parts.append("ï¼ˆé‡æ–°å­¦ä¹ ï¼‰")
                    if ml_tuning_info and ml_tuning_info.get('applied'):
                        if ml_tuning_info.get('used_conservative_fusion'):
                            raw_analysis_parts.append(f"å¼ºåŒ–å­¦ä¹ ç”Ÿæˆçš„promptè¿‡çŸ­({ml_tuning_info['tuned_length']} vs {ml_tuning_info['original_length']})ï¼Œé‡‡ç”¨ä¿å®ˆèåˆç­–ç•¥")
                        else:
                            raw_analysis_parts.append(f"å·²åº”ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ï¼Œé¢„æœŸæ”¹è¿›: {ml_tuning_info['expected_improvement']:.2%}")
                    raw_analysis = "ï¼›".join(raw_analysis_parts)

                    # âœ… åˆ›å»ºå®¡æŸ¥è®°å½• - proposed_content æ˜¯å®Œæ•´çš„æ–°äººæ ¼ï¼ˆåŸäººæ ¼ + æ›´æ–°å†…å®¹ï¼‰
                    review_id = await self.db_manager.add_persona_learning_review(
                        group_id=group_id,
                        proposed_content=new_prompt,  # âœ… ä¿®æ”¹ï¼šproposed_content æ˜¯å®Œæ•´æ–°äººæ ¼
                        learning_source=UPDATE_TYPE_PROGRESSIVE_PERSONA_LEARNING,
                        confidence_score=confidence_score,
                        raw_analysis=raw_analysis,
                        metadata=metadata,
                        original_content=original_prompt,  # âœ… åŸäººæ ¼å®Œæ•´æ–‡æœ¬
                        new_content=new_prompt  # âœ… æ–°äººæ ¼å®Œæ•´æ–‡æœ¬ï¼ˆä¸proposed_contentç›¸åŒï¼Œä¿æŒä¸€è‡´æ€§ï¼‰
                    )

                    logger.info(f"âœ… å·²åˆ›å»ºäººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½• (ID: {review_id})ï¼Œç½®ä¿¡åº¦: {confidence_score:.3f}")

                except Exception as review_error:
                    logger.error(f"åˆ›å»ºäººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•å¤±è´¥: {review_error}", exc_info=True)
            else:
                logger.debug(f"äººæ ¼æœªå˜åŒ–æˆ–ç¼ºå°‘å¿…è¦å‚æ•°ï¼Œè·³è¿‡å®¡æŸ¥è®°å½•åˆ›å»º")

            # 3. è®°å½•å­¦ä¹ æ›´æ–°
            if self.current_session:
                self.current_session.style_updates += 1

        except Exception as e:
            logger.error(f"åº”ç”¨å­¦ä¹ æ›´æ–°å¤±è´¥ for group {group_id}: {e}")

    async def _mark_messages_processed(self, messages: List[Dict[str, Any]]):
        """æ ‡è®°æ¶ˆæ¯ä¸ºå·²å¤„ç†"""
        message_ids = [msg['id'] for msg in messages if 'id' in msg]
        if message_ids:
            await self.message_collector.mark_messages_processed(message_ids)

    async def get_learning_status(self, group_id: str = None) -> Dict[str, Any]:
        """è·å–å­¦ä¹ çŠ¶æ€"""
        if group_id:
            # è·å–ç‰¹å®šç¾¤ç»„çš„çŠ¶æ€
            return {
                'learning_active': self.learning_active.get(group_id, False),
                'group_id': group_id,
                'current_session': self.current_session.__dict__ if self.current_session else None,
                'total_sessions': len(self.learning_sessions),
                'statistics': await self.message_collector.get_statistics(),
                'quality_report': await self.quality_monitor.get_quality_report(),
                'last_update': datetime.now().isoformat()
            }
        else:
            # è·å–æ‰€æœ‰ç¾¤ç»„çš„çŠ¶æ€
            return {
                'learning_active_groups': {gid: active for gid, active in self.learning_active.items()},
                'active_groups_count': sum(1 for active in self.learning_active.values() if active),
                'current_session': self.current_session.__dict__ if self.current_session else None,
                'total_sessions': len(self.learning_sessions),
                'statistics': await self.message_collector.get_statistics(),
                'quality_report': await self.quality_monitor.get_quality_report(),
                'last_update': datetime.now().isoformat()
            }

    async def get_learning_insights(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ æ´å¯Ÿ"""
        try:
            # è·å–é£æ ¼è¶‹åŠ¿
            style_trends = await self.style_analyzer.get_style_trends()
            
            # è·å–ç”¨æˆ·åˆ†æï¼ˆç¤ºä¾‹ç”¨æˆ·ï¼‰
            user_insights = {}
            if self.multidimensional_analyzer.user_profiles:
                sample_user_id = list(self.multidimensional_analyzer.user_profiles.keys())
                user_insights = await self.multidimensional_analyzer.get_user_insights(sample_user_id)
            
            # è·å–ç¤¾äº¤å›¾è°±
            social_graph = await self.multidimensional_analyzer.export_social_graph()
            
            return {
                'style_trends': style_trends,
                'user_insights_sample': user_insights,
                'social_graph_summary': {
                    'total_nodes': len(social_graph.get('nodes', [])),
                    'total_edges': len(social_graph.get('edges', [])),
                    'statistics': social_graph.get('statistics', {})
                },
                'learning_performance': {
                    'successful_sessions': len([s for s in self.learning_sessions if s.success]),
                    'average_quality_score': sum(s.quality_score for s in self.learning_sessions) / 
                                           max(len(self.learning_sessions), 1),
                    'total_messages_processed': sum(s.messages_processed for s in self.learning_sessions)
                }
            }
            
        except Exception as e:
            logger.error(f"è·å–å­¦ä¹ æ´å¯Ÿå¤±è´¥: {e}")
            return {"error": str(e)}

    async def stop(self):
        """åœæ­¢æœåŠ¡"""
        try:
            await self.stop_learning()  # åœæ­¢æ‰€æœ‰ç¾¤ç»„çš„å­¦ä¹ 
            logger.info("æ¸è¿›å¼å­¦ä¹ æœåŠ¡å·²åœæ­¢")
            return True
        except Exception as e:
            logger.error(f"åœæ­¢æ¸è¿›å¼å­¦ä¹ æœåŠ¡å¤±è´¥: {e}")
            return False

    async def _create_persona_review_for_low_quality(self, group_id: str, current_persona: str, 
                                                   updated_persona: str, quality_metrics, filtered_messages):
        """ä¸ºè´¨é‡ä¸è¾¾æ ‡çš„å­¦ä¹ ç»“æœåˆ›å»ºå®¡æŸ¥è®°å½•"""
        try:
            from ..core.interfaces import PersonaUpdateRecord
            import time
            
            # å°†å­—å…¸ç±»å‹çš„äººæ ¼æ•°æ®è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            if isinstance(current_persona, dict):
                current_persona_str = json.dumps(current_persona, ensure_ascii=False, indent=2)
            else:
                current_persona_str = str(current_persona) if current_persona else ""
                
            if isinstance(updated_persona, dict):
                updated_persona_str = json.dumps(updated_persona, ensure_ascii=False, indent=2)
            else:
                updated_persona_str = str(updated_persona) if updated_persona else ""
            
            # è®¡ç®—å˜åŒ–å†…å®¹æ‘˜è¦
            current_length = len(current_persona_str)
            updated_length = len(updated_persona_str)
            
            # æ„å»ºè¯¦ç»†çš„å®¡æŸ¥è¯´æ˜
            reason = f"""å­¦ä¹ è´¨é‡è¯„ä¼°ç»“æœ (å¾—åˆ†: {quality_metrics.consistency_score:.3f} < é˜ˆå€¼: {self.quality_threshold})

è´¨é‡åˆ†æè¯¦æƒ…:
- ä¸€è‡´æ€§å¾—åˆ†: {quality_metrics.consistency_score:.3f}
- å¤„ç†æ¶ˆæ¯æ•°: {len(filtered_messages)}
- åŸäººæ ¼é•¿åº¦: {current_length} å­—ç¬¦
- æ–°äººæ ¼é•¿åº¦: {updated_length} å­—ç¬¦

ç³»ç»Ÿå»ºè®®: ç”±äºå­¦ä¹ è´¨é‡ä¸è¾¾æ ‡ï¼Œå»ºè®®æ‰‹åŠ¨å®¡æŸ¥å†…å®¹è´¨é‡åå†³å®šæ˜¯å¦åº”ç”¨ã€‚
å¯èƒ½çš„é—®é¢˜åŒ…æ‹¬ï¼šå†…å®¹å†—ä½™ã€é€»è¾‘ä¸è¿è´¯ã€ä¸ç°æœ‰äººæ ¼é£æ ¼å·®å¼‚è¿‡å¤§ç­‰ã€‚

è¯·ä»”ç»†æ£€æŸ¥æ–°äººæ ¼å†…å®¹æ˜¯å¦åˆç†ï¼Œå†³å®šæ˜¯å¦åº”ç”¨æ­¤æ¬¡å­¦ä¹ ç»“æœã€‚"""

            # ä¿å­˜å®Œæ•´å†…å®¹ï¼Œä¸è¿›è¡Œæˆªæ–­ï¼ˆç§»é™¤ä¹‹å‰çš„500å­—ç¬¦é™åˆ¶ï¼‰
            original_content_full = current_persona_str
            new_content_full = updated_persona_str

            # åˆ›å»ºå®¡æŸ¥è®°å½•
            review_record = PersonaUpdateRecord(
                timestamp=time.time(),
                group_id=group_id,
                update_type="persona_learning_review", 
                original_content=original_content_full,
                new_content=new_content_full,
                reason=reason,
                confidence_score=quality_metrics.consistency_score,  # ä½¿ç”¨å®é™…çš„è´¨é‡å¾—åˆ†
                status='pending'
            )
            
            # ç›´æ¥ä¿å­˜åˆ°æ•°æ®åº“ - ä¸ä¾èµ–persona_updater
            try:
                async with self.db_manager.get_db_connection() as conn:
                    cursor = await conn.cursor()
                    
                    # ç¡®ä¿å®¡æŸ¥è¡¨å­˜åœ¨
                    await cursor.execute('''
                        CREATE TABLE IF NOT EXISTS persona_update_reviews (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            timestamp REAL NOT NULL,
                            group_id TEXT NOT NULL,
                            update_type TEXT NOT NULL,
                            original_content TEXT,
                            new_content TEXT,
                            proposed_content TEXT,
                            confidence_score REAL,
                            reason TEXT,
                            status TEXT NOT NULL DEFAULT 'pending',
                            reviewer_comment TEXT,
                            review_time REAL
                        )
                    ''')
                    
                    # ä¸ºæ—§è¡¨æ·»åŠ ç¼ºå¤±çš„åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                    try:
                        await cursor.execute('ALTER TABLE persona_update_reviews ADD COLUMN proposed_content TEXT')
                    except:
                        pass  # åˆ—å·²å­˜åœ¨
                    try:
                        await cursor.execute('ALTER TABLE persona_update_reviews ADD COLUMN confidence_score REAL')
                    except:
                        pass  # åˆ—å·²å­˜åœ¨
                    
                    # æ’å…¥å®¡æŸ¥è®°å½•
                    await cursor.execute('''
                        INSERT INTO persona_update_reviews 
                        (timestamp, group_id, update_type, original_content, new_content, proposed_content, confidence_score, reason, status)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        review_record.timestamp,
                        review_record.group_id,
                        review_record.update_type,
                        review_record.original_content,
                        review_record.new_content,
                        review_record.new_content,  # proposed_contentä½¿ç”¨ç›¸åŒå†…å®¹
                        review_record.confidence_score,
                        review_record.reason,
                        review_record.status
                    ))
                    
                    await conn.commit()
                    record_id = cursor.lastrowid
                    await cursor.close()
                    logger.info(f"è´¨é‡ä¸è¾¾æ ‡çš„äººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•å·²åˆ›å»ºï¼ŒID: {record_id}")
                    return True
                    
            except Exception as db_error:
                logger.error(f"ä¿å­˜å®¡æŸ¥è®°å½•åˆ°æ•°æ®åº“å¤±è´¥: {db_error}")
                return False
            
        except Exception as e:
            logger.error(f"åˆ›å»ºè´¨é‡ä¸è¾¾æ ‡å®¡æŸ¥è®°å½•å¤±è´¥: {e}")
            return False
