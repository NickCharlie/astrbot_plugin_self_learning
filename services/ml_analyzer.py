"""
è½»é‡çº§æœºå™¨å­¦ä¹ åˆ†æå™¨ - ä½¿ç”¨ç®€å•çš„MLç®—æ³•è¿›è¡Œæ•°æ®åˆ†æ
"""
import numpy as np
import json
import time
import pandas as pd # å¯¼å…¥ pandas
import asyncio # å¯¼å…¥ asyncio
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from collections import Counter, defaultdict

try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.cluster import KMeans
    from sklearn.metrics.pairwise import cosine_similarity
    from sklearn.linear_model import LogisticRegression # å¯¼å…¥ LogisticRegression
    from sklearn.tree import DecisionTreeClassifier # å¯¼å…¥ DecisionTreeClassifier
    SKLEARN_AVAILABLE = True
except ImportError: 
    SKLEARN_AVAILABLE = False

from astrbot.api import logger

from ..config import PluginConfig

from ..exceptions import StyleAnalysisError

from ..core.framework_llm_adapter import FrameworkLLMAdapter # å¯¼å…¥æ¡†æ¶é€‚é…å™¨

from .database_manager import DatabaseManager # ç¡®ä¿ DatabaseManager è¢«æ­£ç¡®å¯¼å…¥

from ..utils.json_utils import safe_parse_llm_json, clean_llm_json_response


class LightweightMLAnalyzer:
    """è½»é‡çº§æœºå™¨å­¦ä¹ åˆ†æå™¨ - ä½¿ç”¨ç®€å•çš„MLç®—æ³•è¿›è¡Œæ•°æ®åˆ†æ"""
    
    def __init__(self, config: PluginConfig, db_manager: DatabaseManager, 
                 llm_adapter: Optional[FrameworkLLMAdapter] = None,
                 prompts: Any = None, temporary_persona_updater = None): # ä½¿ç”¨æ¡†æ¶é€‚é…å™¨æ›¿ä»£LLMClient
        self.config = config
        self.db_manager = db_manager
        self.llm_adapter = llm_adapter  # ä½¿ç”¨æ¡†æ¶é€‚é…å™¨
        self.prompts = prompts # ä¿å­˜ prompts
        self.temporary_persona_updater = temporary_persona_updater # ä¿å­˜ä¸´æ—¶äººæ ¼æ›´æ–°å™¨å¼•ç”¨
        
        # è®¾ç½®åˆ†æé™åˆ¶ä»¥èŠ‚çœèµ„æº
        self.max_sample_size = 100  # æœ€å¤§æ ·æœ¬æ•°é‡
        self.max_features = 50      # æœ€å¤§ç‰¹å¾æ•°é‡
        self.analysis_cache = {}    # åˆ†æç»“æœç¼“å­˜
        self.cache_timeout = 3600   # ç¼“å­˜1å°æ—¶
        
        if not SKLEARN_AVAILABLE:
            logger.warning("scikit-learnæœªå®‰è£…ï¼Œå°†ä½¿ç”¨åŸºç¡€ç»Ÿè®¡åˆ†æ")
            self.strategy_model = None
        else:
            # åˆå§‹åŒ–ç­–ç•¥æ¨¡å‹
            self.strategy_model: Optional[LogisticRegression | DecisionTreeClassifier] = None
            # å¯ä»¥åœ¨è¿™é‡Œé€‰æ‹©ä½¿ç”¨ LogisticRegression æˆ– DecisionTreeClassifier
            # self.strategy_model = LogisticRegression(max_iter=1000) 
            # self.strategy_model = DecisionTreeClassifier(max_depth=5)
        
        logger.info("è½»é‡çº§MLåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    async def reinforcement_memory_replay(self, group_id: str, new_messages: List[Dict[str, Any]], current_persona: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¼ºåŒ–å­¦ä¹ è®°å¿†é‡æ”¾ï¼šé€šè¿‡å¼ºåŒ–æ¨¡å‹åˆ†æå†å²æ•°æ®å’Œæ–°æ•°æ®çš„å…³è”æ€§ï¼Œä¼˜åŒ–å­¦ä¹ ç­–ç•¥
        """
        if not self.llm_adapter or not self.llm_adapter.has_reinforce_provider() and self.llm_adapter.providers_configured < 3:
            logger.warning("å¼ºåŒ–æ¨¡å‹æœªé…ç½®ï¼Œè·³è¿‡å¼ºåŒ–å­¦ä¹ è®°å¿†é‡æ”¾åŠŸèƒ½")
            return {}

        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨å­¦ä¹ æµç¨‹ä¸­ï¼Œé¿å…åœ¨force_learningè¿‡ç¨‹ä¸­é‡å¤è°ƒç”¨
            import inspect
            current_frame = inspect.currentframe()
            call_stack = []
            frame = current_frame
            while frame:
                call_stack.append(frame.f_code.co_name)
                frame = frame.f_back
            
            learning_methods = ['_execute_learning_batch', 'force_learning_command']
            if any(method in call_stack for method in learning_methods):
                logger.debug(f"æ£€æµ‹åˆ°æ­£åœ¨å¼ºåˆ¶å­¦ä¹ æµç¨‹ä¸­ï¼Œé€‚åº¦é™ä½å¼ºåŒ–å­¦ä¹ è®°å¿†é‡æ”¾çš„è°ƒç”¨é¢‘ç‡")
                # åœ¨å­¦ä¹ æµç¨‹ä¸­ä»ç„¶æ‰§è¡Œï¼Œä½†å‡å°‘å¤æ‚åº¦
                pass

            # è·å–å†å²å­¦ä¹ æ•°æ®
            historical_data = await self.db_manager.get_learning_history_for_reinforcement(group_id, limit=50)
            
            # è¿‡æ»¤æ‰Noneå€¼ï¼Œå‡†å¤‡æ•°æ®æ ¼å¼
            filtered_historical_data = [h for h in historical_data if h is not None]
            filtered_new_messages = [msg for msg in new_messages if msg is not None]
            
            historical_summary = {
                "successful_patterns": [h.get('successful_pattern', '') for h in filtered_historical_data if h.get('success')],
                "failed_patterns": [h.get('failed_pattern', '') for h in filtered_historical_data if not h.get('success')],
                "average_quality_score": sum([h.get('quality_score', 0) for h in filtered_historical_data]) / max(len(filtered_historical_data), 1),
                "learning_trends": self._analyze_learning_trends(filtered_historical_data)
            }
            
            new_data_summary = {
                "message_count": len(filtered_new_messages),
                "avg_message_length": sum([len(msg.get('message', '')) for msg in filtered_new_messages]) / max(len(filtered_new_messages), 1),
                "dominant_topics": self._extract_dominant_topics(filtered_new_messages),
                "emotional_distribution": await self._analyze_emotional_distribution(filtered_new_messages)
            }

            # è°ƒç”¨å¼ºåŒ–æ¨¡å‹è¿›è¡Œè®°å¿†é‡æ”¾åˆ†æ
            response = await self.llm_adapter.reinforce_chat_completion(
                prompt=self.prompts.JSON_ONLY_SYSTEM_PROMPT + "\n\n" + self.prompts.REINFORCEMENT_LEARNING_MEMORY_REPLAY_PROMPT.format(
                    historical_learning_data=json.dumps(historical_summary, ensure_ascii=False, indent=2),
                    new_learning_data=json.dumps(new_data_summary, ensure_ascii=False, indent=2),
                    current_persona=json.dumps(current_persona, ensure_ascii=False, indent=2)
                ),
                temperature=0.7
            )

            if response:
                # response æ˜¯å­—ç¬¦ä¸²ï¼Œæ¸…ç†å“åº”æ–‡æœ¬ï¼Œç§»é™¤markdownæ ‡è¯†ç¬¦
                clean_response = clean_llm_json_response(response)
                
                try:
                    reinforcement_result = safe_parse_llm_json(clean_response)
                    
                    # ä¿å­˜å¼ºåŒ–å­¦ä¹ ç»“æœåˆ°æ•°æ®åº“
                    await self.db_manager.save_reinforcement_learning_result(group_id, {
                        'timestamp': time.time(),
                        'replay_analysis': reinforcement_result.get('replay_analysis', {}),
                        'optimization_strategy': reinforcement_result.get('optimization_strategy', {}),
                        'reinforcement_feedback': reinforcement_result.get('reinforcement_feedback', {}),
                        'next_action': reinforcement_result.get('next_action', '')
                    })
                    
                    logger.info(f"å¼ºåŒ–å­¦ä¹ è®°å¿†é‡æ”¾å®Œæˆï¼Œå¥–åŠ±åˆ†æ•°: {reinforcement_result.get('reinforcement_feedback', {}).get('reward_score', 0)}")
                    return reinforcement_result
                    
                except json.JSONDecodeError:
                    logger.error(f"å¼ºåŒ–æ¨¡å‹è¿”å›çš„JSONæ ¼å¼ä¸æ­£ç¡®: {clean_response}")
                    return {}
            return {}
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œå¼ºåŒ–å­¦ä¹ è®°å¿†é‡æ”¾å¤±è´¥: {e}")
            return {}

    async def reinforcement_incremental_tuning(self, group_id: str, base_persona: Dict[str, Any], 
                                               incremental_updates: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¼ºåŒ–å­¦ä¹ å¢é‡å¾®è°ƒï¼šé€šè¿‡å¼ºåŒ–æ¨¡å‹æ™ºèƒ½èåˆåŸºç¡€äººæ ¼å’Œå¢é‡æ›´æ–°
        """
        if (not self.llm_adapter or not self.llm_adapter.has_reinforce_provider()) and self.llm_adapter.providers_configured < 3:
            logger.warning("å¼ºåŒ–æ¨¡å‹æœªé…ç½®ï¼Œè·³è¿‡å¢é‡å¾®è°ƒåŠŸèƒ½")
            return {}

        try:
            # è·å–èåˆå†å²æ•°æ®
            fusion_history = await self.db_manager.get_persona_fusion_history(group_id, limit=10)
            
            # ä¿æŠ¤åŸå§‹promptå†…å®¹ï¼Œé¿å…è¢«è¿‡åº¦ç²¾ç®€
            original_prompt = base_persona.get('prompt', '')
            original_prompt_length = len(original_prompt)
            
            # å¦‚æœåŸå§‹promptå¤ªçŸ­ï¼Œç›´æ¥è·³è¿‡å¼ºåŒ–å­¦ä¹ å¾®è°ƒ
            if original_prompt_length < 100:
                logger.info(f"åŸå§‹promptè¿‡çŸ­({original_prompt_length}å­—ç¬¦)ï¼Œè·³è¿‡å¼ºåŒ–å­¦ä¹ å¾®è°ƒä»¥é¿å…è¿‡åº¦ç²¾ç®€")
                return {}
            
            # è°ƒç”¨å¼ºåŒ–æ¨¡å‹è¿›è¡Œå¢é‡å¾®è°ƒåˆ†æ
            response = await self.llm_adapter.reinforce_chat_completion(
                prompt=self.prompts.JSON_ONLY_SYSTEM_PROMPT + "\n\n" + self.prompts.REINFORCEMENT_LEARNING_INCREMENTAL_TUNING_PROMPT.format(
                    base_persona=json.dumps(base_persona, ensure_ascii=False, indent=2),
                    incremental_updates=json.dumps(incremental_updates, ensure_ascii=False, indent=2),
                    fusion_history=json.dumps(fusion_history, ensure_ascii=False, indent=2)
                ),
                temperature=0.6
            )

            if response:
                # response æ˜¯å­—ç¬¦ä¸²ï¼Œæ¸…ç†å“åº”æ–‡æœ¬ï¼Œç§»é™¤markdownæ ‡è¯†ç¬¦
                clean_response = clean_llm_json_response(response)
                
                try:
                    tuning_result = safe_parse_llm_json(clean_response, fallback_result={})
                    
                    # ç¡®ä¿tuning_resultä¸ä¸ºNoneä¸”æ˜¯å­—å…¸ç±»å‹
                    if not tuning_result or not isinstance(tuning_result, dict):
                        logger.warning("å¼ºåŒ–å­¦ä¹ å¢é‡å¾®è°ƒ: è§£æç»“æœä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®ï¼Œä½¿ç”¨é»˜è®¤ç»“æœ")
                        tuning_result = {}
                    
                    # é‡è¦ä¿æŠ¤ï¼šé˜²æ­¢promptè¢«è¿‡åº¦ç²¾ç®€
                    if 'updated_persona' in tuning_result and 'prompt' in tuning_result['updated_persona']:
                        new_prompt = tuning_result['updated_persona']['prompt']
                        new_prompt_length = len(new_prompt)
                        
                        # å¦‚æœæ–°promptæ¯”åŸpromptçŸ­å¤ªå¤šï¼Œåˆ™è¿›è¡Œä¿æŠ¤æ€§å¤„ç†
                        if new_prompt_length < original_prompt_length * 0.8:
                            logger.warning(f"å¼ºåŒ–å­¦ä¹ ç”Ÿæˆçš„promptè¿‡çŸ­({new_prompt_length} vs {original_prompt_length})ï¼Œé‡‡ç”¨ä¿å®ˆèåˆç­–ç•¥")
                            
                            # é‡‡ç”¨ä¿å®ˆçš„å¢é‡èåˆï¼Œè€Œä¸æ˜¯å®Œå…¨æ›¿æ¢
                            enhanced_prompt = self._conservative_prompt_fusion(original_prompt, new_prompt, tuning_result)
                            tuning_result['updated_persona']['prompt'] = enhanced_prompt
                            
                            # é™ä½æœŸæœ›æ”¹è¿›å€¼ï¼Œå› ä¸ºæˆ‘ä»¬é‡‡ç”¨äº†ä¿å®ˆç­–ç•¥
                            if 'performance_prediction' in tuning_result:
                                original_improvement = tuning_result['performance_prediction'].get('expected_improvement', 0)
                                tuning_result['performance_prediction']['expected_improvement'] = min(original_improvement * 0.7, 0.6)
                        
                        logger.info(f"å¼ºåŒ–å­¦ä¹ prompté•¿åº¦å˜åŒ–: {original_prompt_length} -> {len(tuning_result['updated_persona']['prompt'])}")
                    
                    # ä¿å­˜èåˆç»“æœåˆ°å†å²è®°å½•
                    await self.db_manager.save_persona_fusion_result(group_id, {
                        'timestamp': time.time(),
                        'base_persona_hash': hash(str(base_persona)),
                        'incremental_hash': hash(str(incremental_updates)),
                        'fusion_result': tuning_result,
                        'compatibility_score': tuning_result.get('compatibility_analysis', {}).get('feature_compatibility', 0)
                    })
                    
                    logger.info(f"å¼ºåŒ–å­¦ä¹ å¢é‡å¾®è°ƒå®Œæˆï¼Œé¢„æœŸæ”¹è¿›: {tuning_result.get('performance_prediction', {}).get('expected_improvement', 0)}")
                    return tuning_result
                    
                except json.JSONDecodeError:
                    logger.error(f"å¼ºåŒ–æ¨¡å‹è¿”å›çš„JSONæ ¼å¼ä¸æ­£ç¡®: {clean_response}")
                    return {}
            return {}
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œå¼ºåŒ–å­¦ä¹ å¢é‡å¾®è°ƒå¤±è´¥: {e}")
            return {}

    async def reinforcement_strategy_optimization(self, group_id: str) -> Dict[str, Any]:
        """
        å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä¼˜åŒ–ï¼šåŸºäºå†å²è¡¨ç°æ•°æ®åŠ¨æ€è°ƒæ•´å­¦ä¹ ç­–ç•¥
        """
        if (not self.llm_adapter or not self.llm_adapter.has_reinforce_provider())  and self.llm_adapter.providers_configured < 3:
            logger.warning("å¼ºåŒ–æ¨¡å‹æœªé…ç½®ï¼Œè·³è¿‡ç­–ç•¥ä¼˜åŒ–åŠŸèƒ½")
            return {}

        try:
            # è·å–å­¦ä¹ å†å²æ•°æ®å’Œæ€§èƒ½æŒ‡æ ‡
            learning_history = await self.db_manager.get_learning_performance_history(group_id, limit=30)
            current_strategy = {
                "learning_rate": self.config.learning_interval_hours / 24.0,
                "batch_size": self.config.max_messages_per_batch,
                "confidence_threshold": self.config.confidence_threshold,
                "quality_threshold": self.config.style_update_threshold
            }
            
            performance_metrics = self._calculate_performance_metrics(learning_history)
            
            # è°ƒç”¨å¼ºåŒ–æ¨¡å‹è¿›è¡Œç­–ç•¥ä¼˜åŒ–
            response = await self.llm_adapter.reinforce_chat_completion(
                prompt=self.prompts.JSON_ONLY_SYSTEM_PROMPT + "\n\n" + self.prompts.REINFORCEMENT_LEARNING_STRATEGY_OPTIMIZATION_PROMPT.format(
                    learning_history=json.dumps(learning_history, ensure_ascii=False, indent=2),
                    current_strategy=json.dumps(current_strategy, ensure_ascii=False, indent=2),
                    performance_metrics=json.dumps(performance_metrics, ensure_ascii=False, indent=2)
                ),
                temperature=0.5
            )

            if response:
                # response æ˜¯å­—ç¬¦ä¸²ï¼Œæ¸…ç†å“åº”æ–‡æœ¬ï¼Œç§»é™¤markdownæ ‡è¯†ç¬¦
                clean_response = clean_llm_json_response(response)
                
                try:
                    optimization_result = safe_parse_llm_json(clean_response)
                    
                    # ä¿å­˜ç­–ç•¥ä¼˜åŒ–ç»“æœ
                    await self.db_manager.save_strategy_optimization_result(group_id, {
                        'timestamp': time.time(),
                        'original_strategy': current_strategy,
                        'optimization_result': optimization_result,
                        'expected_improvement': optimization_result.get('expected_improvements', {})
                    })
                    
                    logger.info(f"å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä¼˜åŒ–å®Œæˆï¼Œé¢„æœŸå­¦ä¹ é€Ÿåº¦æå‡: {optimization_result.get('expected_improvements', {}).get('learning_speed', 0)}")
                    return optimization_result
                    
                except json.JSONDecodeError:
                    logger.error(f"å¼ºåŒ–æ¨¡å‹è¿”å›çš„JSONæ ¼å¼ä¸æ­£ç¡®: {clean_response}")
                    return {}
            return {}
        except Exception as e:
            logger.error(f"ç­–ç•¥ä¼˜åŒ–æ‰§è¡Œå¤±è´¥: {e}")
            return {}

    def _conservative_prompt_fusion(self, original_prompt: str, new_prompt: str, tuning_result: Dict[str, Any]) -> str:
        """
        ä¿å®ˆçš„promptèåˆç­–ç•¥ï¼Œé¿å…è¿‡åº¦ç²¾ç®€åŸå§‹prompt
        """
        try:
            # å¦‚æœæ–°promptæ˜æ˜¾å¤ªçŸ­ï¼Œåªæå–å…¶ä¸­çš„å¢é‡ä¿¡æ¯
            if len(new_prompt) < len(original_prompt) * 0.5:
                # å°è¯•ä»tuning_resultä¸­æå–å…³é”®å˜åŒ–ä¿¡æ¯
                key_changes = tuning_result.get('updated_persona', {}).get('key_changes', [])
                
                if key_changes:
                    # å°†å…³é”®å˜åŒ–ä»¥å¢é‡æ–¹å¼æ·»åŠ åˆ°åŸå§‹promptæœ«å°¾
                    enhancement_text = f"\n\n## å­¦ä¹ å¢å¼ºç‰¹å¾:\n" + "\n".join([f"- {change}" for change in key_changes[:3]])
                    return original_prompt + enhancement_text
                else:
                    # å¦‚æœæ²¡æœ‰å…³é”®å˜åŒ–ï¼Œè¿”å›åŸå§‹prompt
                    logger.info("æœªå‘ç°æ˜æ˜¾çš„å…³é”®å˜åŒ–ï¼Œä¿æŒåŸå§‹promptä¸å˜")
                    return original_prompt
            
            # å¦‚æœæ–°prompté•¿åº¦åˆç†ï¼Œä½†ä»ç„¶æ¯”åŸæ¥çŸ­ï¼Œè¿›è¡Œæ™ºèƒ½èåˆ
            elif len(new_prompt) < len(original_prompt) * 0.8:
                # å°è¯•ä¿ç•™åŸå§‹promptçš„ä¸»è¦ç»“æ„ï¼Œæ·»åŠ æ–°çš„ç‰¹å¾
                lines = original_prompt.split('\n')
                new_lines = new_prompt.split('\n')
                
                # æ‰¾åˆ°å¯èƒ½çš„å¢é‡å†…å®¹ï¼ˆå‡ºç°åœ¨æ–°promptä½†ä¸åœ¨åŸpromptä¸­çš„å†…å®¹ï¼‰
                new_content = []
                for line in new_lines:
                    if line.strip() and line.strip() not in original_prompt:
                        new_content.append(line.strip())
                
                if new_content:
                    # å°†æ–°å†…å®¹ä½œä¸ºå¢é‡æ·»åŠ 
                    enhancement = f"\n\n## æœ€æ–°å­¦ä¹ ç‰¹å¾:\n" + "\n".join([f"- {content}" for content in new_content[:5]])
                    return original_prompt + enhancement
                else:
                    return original_prompt
            
            else:
                # é•¿åº¦å·®å¼‚ä¸å¤§ï¼Œä½¿ç”¨æ–°prompt
                return new_prompt
                
        except Exception as e:
            logger.error(f"ä¿å®ˆèåˆå¤±è´¥: {e}")
            return original_prompt

    async def replay_memory(self, group_id: str, new_messages: List[Dict[str, Any]], current_persona: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        è®°å¿†é‡æ”¾ï¼šå°†å†å²æ•°æ®ä¸æ–°æ•°æ®æ··åˆï¼Œå¹¶äº¤ç»™æç‚¼æ¨¡å‹è¿›è¡Œå¤„ç†ã€‚
        è¿™æ¨¡æ‹Ÿäº†LLMçš„"å¢é‡å¾®è°ƒ"è¿‡ç¨‹ï¼Œé€šè¿‡é‡æ–°æš´éœ²å†å²æ•°æ®æ¥å·©å›ºå­¦ä¹ ã€‚
        """
        if (not self.llm_adapter or not self.llm_adapter.has_refine_provider())  and self.llm_adapter.providers_configured < 2:
            logger.warning("æç‚¼æ¨¡å‹æœªé…ç½®ï¼Œè·³è¿‡è®°å¿†é‡æ”¾åŠŸèƒ½")
            return []

        try:
            # è·å–æœ€è¿‘ä¸€æ®µæ—¶é—´çš„å†å²æ¶ˆæ¯
            # å‡è®¾æˆ‘ä»¬è·å–è¿‡å»30å¤©çš„æ¶ˆæ¯ä½œä¸ºå†å²æ•°æ®
            history_messages = await self.db_manager.get_messages_for_replay(group_id, days=30, limit=self.config.max_messages_per_batch * 2)
            
            # å°†æ–°æ¶ˆæ¯ä¸å†å²æ¶ˆæ¯æ··åˆ
            # å¯ä»¥æ ¹æ®æ—¶é—´æˆ³è¿›è¡Œæ’åºï¼Œæˆ–è€…ç®€å•åœ°æ‹¼æ¥
            # è¿‡æ»¤æ‰Noneå€¼
            filtered_history_messages = [msg for msg in history_messages if msg is not None]
            filtered_new_messages = [msg for msg in new_messages if msg is not None]
            
            all_messages = filtered_history_messages + filtered_new_messages
            # ç¡®ä¿æ¶ˆæ¯ä¸é‡å¤ï¼Œå¹¶æŒ‰æ—¶é—´æ’åº
            unique_messages = {msg.get('message_id', id(msg)): msg for msg in all_messages if msg.get('message_id') or id(msg)}
            sorted_messages = sorted(unique_messages.values(), key=lambda x: x.get('timestamp', 0))
            
            # é™åˆ¶æ€»æ¶ˆæ¯æ•°é‡ï¼Œé¿å…è¿‡å¤§çš„ä¸Šä¸‹æ–‡
            if len(sorted_messages) > self.config.max_messages_per_batch * 2:
                sorted_messages = sorted_messages[-self.config.max_messages_per_batch * 2:]

            logger.info(f"æ‰§è¡Œè®°å¿†é‡æ”¾ï¼Œæ··åˆæ¶ˆæ¯æ•°é‡: {len(sorted_messages)}")

            # å°†æ··åˆåçš„æ¶ˆæ¯äº¤ç»™æç‚¼æ¨¡å‹è¿›è¡Œå¤„ç†
            # è¿™é‡Œå¯ä»¥è®¾è®¡ä¸€ä¸ªæ›´å¤æ‚çš„promptï¼Œè®©LLMä»è¿™äº›æ¶ˆæ¯ä¸­æç‚¼æ–°çš„çŸ¥è¯†æˆ–é£æ ¼
            # ç¤ºä¾‹ï¼šè®©LLMæ€»ç»“è¿™äº›æ¶ˆæ¯çš„ç‰¹ç‚¹ï¼Œå¹¶ä¸å½“å‰äººæ ¼è¿›è¡Œå¯¹æ¯”
            messages_text = "\n".join([msg.get('message', '') for msg in sorted_messages if msg.get('message')])
            
            prompt = f"""{self.prompts.JSON_ONLY_SYSTEM_PROMPT}

{self.prompts.ML_ANALYZER_REPLAY_MEMORY_SYSTEM_PROMPT.format(
                current_persona_description=current_persona['description']
            )}

{self.prompts.ML_ANALYZER_REPLAY_MEMORY_PROMPT.format(
                messages_text=messages_text
            )}"""

            response = await self.llm_adapter.refine_chat_completion(
                prompt=prompt,
                temperature=0.3
            )

            if response:
                # response æ˜¯å­—ç¬¦ä¸²ï¼Œæ¸…ç†å“åº”æ–‡æœ¬ï¼Œç§»é™¤markdownæ ‡è¯†ç¬¦
                clean_response = clean_llm_json_response(response)
                
                try:
                    refined_data = safe_parse_llm_json(clean_response)
                    logger.info(f"è®°å¿†é‡æ”¾æç‚¼ç»“æœ: {refined_data}")
                    
                    # å°†å¼ºåŒ–å­¦ä¹ ç»“æœé›†æˆåˆ°system_prompt
                    if self.temporary_persona_updater:
                        try:
                            # æ£€æŸ¥æ˜¯å¦åœ¨å¼ºåˆ¶å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œé¿å…æ— é™å¾ªç¯
                            # é€šè¿‡æ£€æŸ¥è°ƒç”¨æ ˆæ¥åˆ¤æ–­æ˜¯å¦å·²ç»åœ¨å­¦ä¹ æµç¨‹ä¸­
                            import inspect
                            current_frame = inspect.currentframe()
                            call_stack = []
                            frame = current_frame
                            while frame:
                                call_stack.append(frame.f_code.co_name)
                                frame = frame.f_back
                            
                            # å¦‚æœè°ƒç”¨æ ˆä¸­åŒ…å«å­¦ä¹ ç›¸å…³çš„æ–¹æ³•ï¼Œè¯´æ˜æ­£åœ¨å­¦ä¹ æµç¨‹ä¸­ï¼Œè·³è¿‡system_promptæ›´æ–°
                            learning_methods = ['_execute_learning_batch', 'force_learning_command', '_apply_learning_updates']
                            if any(method in call_stack for method in learning_methods):
                                logger.debug(f"æ£€æµ‹åˆ°æ­£åœ¨å­¦ä¹ æµç¨‹ä¸­ï¼Œè·³è¿‡è®°å¿†é‡æ”¾çš„system_prompté›†æˆä»¥é¿å…å¾ªç¯")
                            else:
                                # å‡†å¤‡å­¦ä¹ æ´å¯Ÿæ›´æ–°æ•°æ®
                                insights_data = {
                                    'learning_insights': {
                                        'interaction_patterns': refined_data.get('interaction_patterns', 'é€šè¿‡è®°å¿†é‡æ”¾å‘ç°çš„äº¤äº’æ¨¡å¼'),
                                        'improvement_suggestions': refined_data.get('suggested_improvements', 'åŸºäºå†å²æ¶ˆæ¯çš„æ”¹è¿›å»ºè®®'),
                                        'effective_strategies': refined_data.get('effective_responses', 'æœ‰æ•ˆçš„å›å¤ç­–ç•¥'),
                                        'learning_focus': f"è®°å¿†é‡æ”¾å­¦ä¹  - å¤„ç†äº†{len(new_messages)}æ¡å†å²æ¶ˆæ¯"
                                    }
                                }
                                
                                await self.temporary_persona_updater.apply_comprehensive_update_to_system_prompt(
                                    group_id, insights_data
                                )
                                logger.info(f"æˆåŠŸå°†å¼ºåŒ–å­¦ä¹ ç»“æœé›†æˆåˆ°system_prompt: {group_id}")
                            
                        except Exception as e:
                            logger.error(f"é›†æˆå¼ºåŒ–å­¦ä¹ ç»“æœåˆ°system_promptå¤±è´¥: {e}")
                    
                    
                    # è¿™é‡Œå¯ä»¥å°† refined_data ä¼ é€’ç»™ PersonaUpdater è¿›è¡Œäººæ ¼æ›´æ–°
                    # æˆ–è€…åœ¨ ProgressiveLearning æ¨¡å—ä¸­å¤„ç†
                    return refined_data
                except json.JSONDecodeError:
                    logger.error(f"æç‚¼æ¨¡å‹è¿”å›çš„JSONæ ¼å¼ä¸æ­£ç¡®: {clean_response}")
                    return {}
            return {}
        except Exception as e:
            logger.error(f"æ‰§è¡Œè®°å¿†é‡æ”¾å¤±è´¥: {e}")
            return {}

    def _analyze_learning_trends(self, historical_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æå­¦ä¹ è¶‹åŠ¿"""
        # è¿‡æ»¤æ‰Noneå€¼
        filtered_data = [h for h in historical_data if h is not None]
        
        if not filtered_data:
            return {}
        
        quality_scores = [h.get('quality_score', 0) for h in filtered_data]
        success_rate = sum([1 for h in filtered_data if h.get('success', False)]) / len(filtered_data)
        
        # è®¡ç®—è¶‹åŠ¿
        if len(quality_scores) >= 3:
            recent_avg = sum(quality_scores[-3:]) / 3
            early_avg = sum(quality_scores[:3]) / 3
            trend = (recent_avg - early_avg) / max(early_avg, 0.1)
        else:
            trend = 0.0
        
        return {
            "average_quality": sum(quality_scores) / len(quality_scores),
            "success_rate": success_rate,
            "quality_trend": trend,
            "total_sessions": len(filtered_data)
        }

    def _extract_dominant_topics(self, messages: List[Dict[str, Any]]) -> List[str]:
        """æå–ä¸»è¦è¯é¢˜"""
        # è¿‡æ»¤æ‰Noneå€¼
        filtered_messages = [msg for msg in messages if msg is not None]
        
        if not SKLEARN_AVAILABLE or len(filtered_messages) < 5:
            return []
        
        try:
            texts = [msg.get('message', '') for msg in filtered_messages if len(msg.get('message', '')) > 10]
            if len(texts) < 3:
                return []
            
            # ä½¿ç”¨TF-IDFæå–å…³é”®è¯
            vectorizer = TfidfVectorizer(max_features=10, ngram_range=(1, 2))
            tfidf_matrix = vectorizer.fit_transform(texts)
            feature_names = vectorizer.get_feature_names_out()
            
            # è·å–å¹³å‡TF-IDFåˆ†æ•°
            mean_scores = tfidf_matrix.mean(axis=0).A1
            top_indices = mean_scores.argsort()[-5:][::-1]
            
            return [feature_names[i] for i in top_indices]
            
        except Exception as e:
            logger.error(f"æå–ä¸»è¦è¯é¢˜å¤±è´¥: {e}")
            return []

    async def _analyze_emotional_distribution(self, messages: List[Dict[str, Any]]) -> Dict[str, float]:
        """åˆ†ææƒ…æ„Ÿåˆ†å¸ƒ"""
        try:
            # è¿‡æ»¤æ‰Noneå€¼
            filtered_messages = [msg for msg in messages if msg is not None]
            # ä½¿ç”¨ç°æœ‰çš„æƒ…æ„Ÿåˆ†ææ–¹æ³•
            return await self._analyze_sentiment_with_llm(filtered_messages)
        except Exception as e:
            logger.error(f"åˆ†ææƒ…æ„Ÿåˆ†å¸ƒå¤±è´¥: {e}")
            # è¿‡æ»¤æ‰Noneå€¼å†ä¼ ç»™ç®€å•æƒ…æ„Ÿåˆ†æ
            filtered_messages = [msg for msg in messages if msg is not None]
            return self._simple_sentiment_analysis(filtered_messages)

    def _calculate_performance_metrics(self, learning_history: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        # è¿‡æ»¤æ‰Noneå€¼
        filtered_history = [h for h in learning_history if h is not None]
        
        if not filtered_history:
            return {}
        
        quality_scores = [h.get('quality_score', 0) for h in filtered_history]
        learning_times = [h.get('learning_time', 0) for h in filtered_history]
        success_count = sum([1 for h in filtered_history if h.get('success', False)])
        
        return {
            "average_quality": sum(quality_scores) / len(quality_scores),
            "quality_variance": np.var(quality_scores),
            "success_rate": success_count / len(filtered_history),
            "average_learning_time": sum(learning_times) / max(len(learning_times), 1),
            "total_sessions": len(filtered_history),
            "improvement_rate": self._calculate_improvement_rate(quality_scores)
        }

    def _calculate_improvement_rate(self, quality_scores: List[float]) -> float:
        """è®¡ç®—æ”¹è¿›ç‡"""
        if len(quality_scores) < 4:
            return 0.0
        
        # æ¯”è¾ƒå‰åŠéƒ¨åˆ†å’ŒååŠéƒ¨åˆ†çš„å¹³å‡åˆ†
        mid = len(quality_scores) // 2
        first_half_avg = sum(quality_scores[:mid]) / mid
        second_half_avg = sum(quality_scores[mid:]) / (len(quality_scores) - mid)
        
        if first_half_avg == 0:
            return 0.0
        
        return (second_half_avg - first_half_avg) / first_half_avg

    async def train_strategy_model(self, X: np.ndarray, y: np.ndarray, model_type: str = "logistic_regression"):
        """
        è®­ç»ƒç­–ç•¥æ¨¡å‹ï¼ˆé€»è¾‘å›å½’æˆ–å†³ç­–æ ‘ï¼‰ã€‚
        X: ç‰¹å¾çŸ©é˜µ (e.g., æ¶ˆæ¯é•¿åº¦, æƒ…æ„Ÿåˆ†æ•°, ç›¸å…³æ€§åˆ†æ•°)
        y: ç›®æ ‡å˜é‡ (e.g., æ¶ˆæ¯æ˜¯å¦è¢«é‡‡çº³/å­¦ä¹ ä»·å€¼é«˜ä½)
        """
        if not SKLEARN_AVAILABLE:
            logger.warning("scikit-learnæœªå®‰è£…ï¼Œæ— æ³•è®­ç»ƒç­–ç•¥æ¨¡å‹ã€‚")
            return

        if model_type == "logistic_regression":
            self.strategy_model = LogisticRegression(max_iter=1000, random_state=42)
        elif model_type == "decision_tree":
            self.strategy_model = DecisionTreeClassifier(max_depth=5, random_state=42)
        else:
            logger.error(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
            self.strategy_model = None
            return

        try:
            # å°†é˜»å¡çš„fitæ“ä½œæ”¾åˆ°å•ç‹¬çš„çº¿ç¨‹ä¸­æ‰§è¡Œ
            await asyncio.to_thread(self.strategy_model.fit, X, y)
            logger.info(f"ç­–ç•¥æ¨¡å‹ ({model_type}) è®­ç»ƒå®Œæˆã€‚")
        except Exception as e:
            logger.error(f"è®­ç»ƒç­–ç•¥æ¨¡å‹å¤±è´¥: {e}")
            self.strategy_model = None

    def predict_learning_value(self, features: np.ndarray) -> float:
        """
        ä½¿ç”¨è®­ç»ƒå¥½çš„ç­–ç•¥æ¨¡å‹é¢„æµ‹æ¶ˆæ¯çš„å­¦ä¹ ä»·å€¼ã€‚
        features: å•ä¸ªæ¶ˆæ¯çš„ç‰¹å¾å‘é‡ã€‚
        è¿”å›é¢„æµ‹çš„å­¦ä¹ ä»·å€¼ï¼ˆ0-1ä¹‹é—´ï¼‰ã€‚
        """
        if not self.strategy_model:
            logger.warning("ç­–ç•¥æ¨¡å‹æœªè®­ç»ƒï¼Œè¿”å›é»˜è®¤å­¦ä¹ ä»·å€¼0.5ã€‚")
            return 0.5
        
        try:
            # ç¡®ä¿ç‰¹å¾ç»´åº¦åŒ¹é…è®­ç»ƒæ—¶çš„ç»´åº¦
            if features.ndim == 1:
                features = features.reshape(1, -1)

            if hasattr(self.strategy_model, 'predict_proba'):
                # å¯¹äºåˆ†ç±»æ¨¡å‹ï¼Œé€šå¸¸é¢„æµ‹ä¸ºæ­£ç±»çš„æ¦‚ç‡
                proba = self.strategy_model.predict_proba(features)
                # å‡è®¾æ­£ç±»æ˜¯ç´¢å¼•1
                return float(proba[0][1])
            elif hasattr(self.strategy_model, 'predict'):
                # å¯¹äºå›å½’æ¨¡å‹ï¼Œç›´æ¥é¢„æµ‹å€¼
                return float(self.strategy_model.predict(features)[0])
            else:
                logger.warning("ç­–ç•¥æ¨¡å‹ä¸æ”¯æŒé¢„æµ‹æ¦‚ç‡æˆ–ç›´æ¥é¢„æµ‹ï¼Œè¿”å›é»˜è®¤å­¦ä¹ ä»·å€¼0.5ã€‚")
                return 0.5
        except Exception as e:
            logger.error(f"é¢„æµ‹å­¦ä¹ ä»·å€¼å¤±è´¥: {e}")
            return 0.5

    async def analyze_user_behavior_pattern(self, group_id: str, user_id: str) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"behavior_{group_id}_{user_id}"
            if self._check_cache(cache_key):
                return self.analysis_cache[cache_key]['data']
            
            # è·å–ç”¨æˆ·æœ€è¿‘æ¶ˆæ¯ï¼ˆé™åˆ¶æ•°é‡ï¼‰
            messages = await self._get_user_messages(group_id, user_id, limit=self.max_sample_size)
            
            if not messages:
                return {}
            
            # åŸºç¡€ç»Ÿè®¡åˆ†æ
            pattern = {
                'message_count': len(messages),
                'avg_message_length': np.mean([len(msg['message']) for msg in messages]),
                'activity_hours': self._analyze_activity_hours(messages),
                'message_frequency': self._analyze_message_frequency(messages),
                'interaction_patterns': await self._analyze_interaction_patterns(group_id, user_id, messages)
            }
            
            # å¦‚æœæœ‰sklearnï¼Œè¿›è¡Œæ–‡æœ¬èšç±»
            if SKLEARN_AVAILABLE and len(messages) >= 5:
                pattern['topic_clusters'] = self._analyze_topic_clusters(messages)
            
            # ç¼“å­˜ç»“æœ
            self._cache_result(cache_key, pattern)
            
            return pattern
            
        except Exception as e:
            logger.error(f"åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼å¤±è´¥: {e}")
            raise StyleAnalysisError(f"åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼å¤±è´¥: {str(e)}")

    async def _get_user_messages(self, group_id: str, user_id: str, limit: int) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·æ¶ˆæ¯ï¼ˆé™åˆ¶æ•°é‡ï¼‰"""
        try:
            # ä»å…¨å±€æ¶ˆæ¯æ•°æ®åº“è·å–è¿æ¥
            async with self.db_manager.get_db_connection() as conn:
                cursor = await conn.cursor()
                
                await cursor.execute('''
                    SELECT message, timestamp, sender_name, sender_id, group_id
                    FROM raw_messages 
                    WHERE sender_id = ? AND group_id = ? AND timestamp > ?
                    ORDER BY timestamp DESC 
                    LIMIT ?
                ''', (user_id, group_id, time.time() - 86400 * 7, limit))  # æœ€è¿‘7å¤©
                
                messages = []
                for row in await cursor.fetchall():
                    messages.append({
                        'message': row[0],
                        'timestamp': row[1],
                        'sender_name': row[2],
                        'sender_id': row[3],
                        'group_id': row[4]
                    })
                
                return messages
            
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·æ¶ˆæ¯å¤±è´¥: {e}")
            return []

    def _analyze_activity_hours(self, messages: List[Dict[str, Any]]) -> Dict[str, float]:
        """åˆ†ææ´»åŠ¨æ—¶é—´æ¨¡å¼"""
        if not messages:
            return {}
        
        hour_counts = defaultdict(int)
        for msg in messages:
            hour = datetime.fromtimestamp(msg['timestamp']).hour
            hour_counts[hour] += 1
        
        total_messages = len(messages)
        hour_distribution = {
            str(hour): count / total_messages 
            for hour, count in hour_counts.items()
        }
        
        # ç¡®å®šæœ€æ´»è·ƒæ—¶æ®µ
        most_active_hour = max(hour_counts.items(), key=lambda x: x)[1]
        
        return {
            'distribution': hour_distribution,
            'most_active_hour': most_active_hour,
            'activity_variance': np.var(list(hour_counts.values()))
        }

    def _analyze_message_frequency(self, messages: List[Dict[str, Any]]) -> Dict[str, float]:
        """åˆ†ææ¶ˆæ¯é¢‘ç‡æ¨¡å¼"""
        if len(messages) < 2:
            return {}
        
        # è®¡ç®—æ¶ˆæ¯é—´éš”
        intervals = []
        sorted_messages = sorted(messages, key=lambda x: x['timestamp'])
        
        for i in range(1, len(sorted_messages)):
            interval = sorted_messages[i]['timestamp'] - sorted_messages[i-1]['timestamp']
            intervals.append(interval / 60)  # è½¬æ¢ä¸ºåˆ†é’Ÿ
        
        if not intervals:
            return {}
        
        return {
            'avg_interval_minutes': np.mean(intervals),
            'interval_std': np.std(intervals),
            'burst_tendency': len([x for x in intervals if x < 5]) / len(intervals)  # 5åˆ†é’Ÿå†…è¿ç»­æ¶ˆæ¯æ¯”ä¾‹
        }

    async def _analyze_interaction_patterns(self, group_id: str, user_id: str, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æäº’åŠ¨æ¨¡å¼"""
        try:
            # åˆ†æ@æ¶ˆæ¯å’Œå›å¤
            mention_count = len([msg for msg in messages if '@' in msg['message']])
            question_count = len([msg for msg in messages if '?' in msg['message'] or 'ï¼Ÿ' in msg['message']])
            
            # è·å–ç¤¾äº¤å…³ç³»å¼ºåº¦
            social_relations = await self.db_manager.load_social_graph(group_id)
            user_relations = [rel for rel in social_relations if rel['from_user'] == user_id or rel['to_user'] == user_id]
            
            return {
                'mention_ratio': mention_count / max(len(messages), 1),
                'question_ratio': question_count / max(len(messages), 1),
                'social_connections': len(user_relations),
                'avg_relation_strength': np.mean([rel['strength'] for rel in user_relations]) if user_relations else 0.0
            }
            
        except Exception as e:
            logger.error(f"åˆ†æäº’åŠ¨æ¨¡å¼å¤±è´¥: {e}")
            return {}

    def _analyze_topic_clusters(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ä½¿ç”¨TF-IDFå’ŒK-meansè¿›è¡Œè¯é¢˜èšç±»"""
        if not SKLEARN_AVAILABLE or len(messages) < 3:
            return {}
        
        try:
            # æå–æ¶ˆæ¯æ–‡æœ¬
            texts = [msg['message'] for msg in messages if len(msg['message']) > 5]
            
            if len(texts) < 3:
                return {}
            
            # TF-IDFå‘é‡åŒ–ï¼ˆé™åˆ¶ç‰¹å¾æ•°é‡ï¼‰
            vectorizer = TfidfVectorizer(
                max_features=min(self.max_features, len(texts) * 2),
                stop_words=None,  # ä¸ä½¿ç”¨åœç”¨è¯ä»¥èŠ‚çœå†…å­˜
                ngram_range=(1, 1)  # åªä½¿ç”¨å•è¯
            )
            
            tfidf_matrix = vectorizer.fit_transform(texts)
            
            # K-meansèšç±»ï¼ˆé™åˆ¶ç°‡æ•°é‡ï¼‰
            n_clusters = min(3, len(texts) // 2)
            if n_clusters < 2:
                return {}
            
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            cluster_labels = kmeans.fit_predict(tfidf_matrix)
            
            # åˆ†æèšç±»ç»“æœ
            clusters = defaultdict(list)
            for i, label in enumerate(cluster_labels):
                clusters[int(label)].append(texts[i][:50])  # é™åˆ¶æ–‡æœ¬é•¿åº¦
            
            # æå–å…³é”®è¯
            feature_names = vectorizer.get_feature_names_out()
            cluster_keywords = {}
            
            for i in range(n_clusters):
                center = kmeans.cluster_centers_[i]
                top_indices = center.argsort()[-5:][::-1]  # å‰5ä¸ªå…³é”®è¯
                cluster_keywords[i] = [feature_names[idx] for idx in top_indices]
            
            return {
                'n_clusters': n_clusters,
                'cluster_keywords': cluster_keywords,
                'cluster_sizes': {str(k): len(v) for k, v in clusters.items()}
            }
            
        except Exception as e:
            logger.error(f"è¯é¢˜èšç±»åˆ†æå¤±è´¥: {e}")
            return {}

    async def analyze_group_sentiment_trend(self, group_id: str) -> Dict[str, Any]:
        """åˆ†æç¾¤èŠæƒ…æ„Ÿè¶‹åŠ¿"""
        try:
            cache_key = f"sentiment_{group_id}"
            if self._check_cache(cache_key):
                return self.analysis_cache[cache_key]['data']
            
            # è·å–æœ€è¿‘æ¶ˆæ¯ï¼ˆé™åˆ¶æ•°é‡ï¼‰
            recent_messages = await self._get_recent_group_messages(group_id, limit=self.max_sample_size)
            
            if not recent_messages:
                return {}
            
            # ç®€å•æƒ…æ„Ÿåˆ†æï¼ˆåŸºäºå…³é”®è¯ï¼‰
            sentiment_trend = self._analyze_sentiment_keywords(recent_messages)
            
            # æ´»è·ƒåº¦åˆ†æ
            activity_trend = self._analyze_activity_trend(recent_messages)
            
            result = {
                'sentiment_trend': sentiment_trend,
                'activity_trend': activity_trend,
                'analysis_time': datetime.now().isoformat(),
                'sample_size': len(recent_messages)
            }
            
            self._cache_result(cache_key, result)
            return result
            
        except Exception as e:
            logger.error(f"åˆ†æç¾¤èŠæƒ…æ„Ÿè¶‹åŠ¿å¤±è´¥: {e}")
            return {}

    async def _get_recent_group_messages(self, group_id: str, limit: int) -> List[Dict[str, Any]]:
        """è·å–ç¾¤èŠæœ€è¿‘æ¶ˆæ¯"""
        try:
            # ä»å…¨å±€æ¶ˆæ¯æ•°æ®åº“è·å–è¿æ¥
            async with self.db_manager.get_db_connection() as conn:
                cursor = await conn.cursor()
                
                await cursor.execute('''
                    SELECT message, timestamp, sender_id, group_id
                    FROM raw_messages 
                    WHERE group_id = ? AND timestamp > ?
                    ORDER BY timestamp DESC 
                    LIMIT ?
                ''', (group_id, time.time() - 3600 * 6, limit))  # æœ€è¿‘6å°æ—¶
                
                messages = []
                for row in await cursor.fetchall():
                    messages.append({
                        'message': row[0],
                        'timestamp': row[1],
                        'sender_id': row[2],
                        'group_id': row[3]
                    })
                
                return messages
            
        except Exception as e:
            logger.error(f"è·å–ç¾¤èŠæœ€è¿‘æ¶ˆæ¯å¤±è´¥: {e}")
            return []

    async def _analyze_sentiment_with_llm(self, messages: List[Dict[str, Any]]) -> Dict[str, float]:
        """ä½¿ç”¨LLMå¯¹æ¶ˆæ¯åˆ—è¡¨è¿›è¡Œæƒ…æ„Ÿåˆ†æ"""
        # ç¡®ä¿æ¶ˆæ¯åˆ—è¡¨å·²ç»è¿‡æ»¤æ‰Noneå€¼
        filtered_messages = [msg for msg in messages if msg is not None]
        
        if (not self.llm_adapter or not self.llm_adapter.has_refine_provider()) and self.llm_adapter.providers_configured < 2:
            logger.warning("æç‚¼æ¨¡å‹æœªé…ç½®ï¼Œæ— æ³•è¿›è¡ŒLLMæƒ…æ„Ÿåˆ†æï¼Œä½¿ç”¨ç®€åŒ–ç®—æ³•")
            return self._simple_sentiment_analysis(filtered_messages)

        messages_text = "\n".join([msg.get('message', '') for msg in filtered_messages])
        
        prompt = self.prompts.JSON_ONLY_SYSTEM_PROMPT + "\n\n" + self.prompts.ML_ANALYZER_SENTIMENT_ANALYSIS_PROMPT.format(
            messages_text=messages_text
        )
        try:
            response = await self.llm_adapter.refine_chat_completion(
                prompt=prompt,
                temperature=0.3
            )
            
            if response:
                try:
                    sentiment_scores = safe_parse_llm_json(response)
                    # ç¡®ä¿æ‰€æœ‰åˆ†æ•°éƒ½åœ¨0-1ä¹‹é—´
                    for key, value in sentiment_scores.items():
                        sentiment_scores[key] = max(0.0, min(float(value), 1.0))
                    return sentiment_scores
                except json.JSONDecodeError:
                    logger.warning(f"LLMå“åº”JSONè§£æå¤±è´¥ï¼Œè¿”å›ç®€åŒ–æƒ…æ„Ÿåˆ†æã€‚å“åº”å†…å®¹: {response}")
                    return self._simple_sentiment_analysis(filtered_messages)
            return self._simple_sentiment_analysis(filtered_messages)
        except Exception as e:
            logger.warning(f"LLMæƒ…æ„Ÿåˆ†æå¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç®—æ³•: {e}")
            return self._simple_sentiment_analysis(filtered_messages)

    def _simple_sentiment_analysis(self, messages: List[Dict[str, Any]]) -> Dict[str, float]:
        """åŸºäºå…³é”®è¯çš„ç®€å•æƒ…æ„Ÿåˆ†æï¼ˆå¤‡ç”¨ï¼‰"""
        # ç¡®ä¿æ¶ˆæ¯åˆ—è¡¨å·²ç»è¿‡æ»¤æ‰Noneå€¼
        filtered_messages = [msg for msg in messages if msg is not None]
        
        positive_keywords = ['å“ˆå“ˆ', 'å¥½çš„', 'è°¢è°¢', 'èµ', 'æ£’', 'å¼€å¿ƒ', 'é«˜å…´', 'ğŸ˜Š', 'ğŸ‘', 'â¤ï¸']
        negative_keywords = ['ä¸è¡Œ', 'å·®', 'çƒ¦', 'æ— èŠ', 'ç”Ÿæ°”', 'ğŸ˜¢', 'ğŸ˜¡', 'ğŸ’”']
        
        positive_count = 0
        negative_count = 0
        total_messages = len(filtered_messages)
        
        for msg in filtered_messages:
            text = msg.get('message', '').lower()
            for keyword in positive_keywords:
                if keyword in text:
                    positive_count += 1
                    break
            for keyword in negative_keywords:
                if keyword in text:
                    negative_count += 1
                    break
        
        return {
            'positive_ratio': positive_count / max(total_messages, 1),
            'negative_ratio': negative_count / max(total_messages, 1),
            'neutral_ratio': (total_messages - positive_count - negative_count) / max(total_messages, 1)
        }

    def _analyze_activity_trend(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†ææ´»è·ƒåº¦è¶‹åŠ¿"""
        if not messages:
            return {}
        
        # æŒ‰å°æ—¶åˆ†ç»„ç»Ÿè®¡
        hourly_counts = defaultdict(int)
        for msg in messages:
            hour = datetime.fromtimestamp(msg['timestamp']).hour
            hourly_counts[hour] += 1
        
        # è®¡ç®—è¶‹åŠ¿
        hours = sorted(hourly_counts.keys())
        counts = [hourly_counts[hour] for hour in hours]
        
        if len(counts) >= 3:
            # ç®€å•çº¿æ€§è¶‹åŠ¿è®¡ç®—
            x = np.array(range(len(counts)))
            y = np.array(counts)
            trend_slope = np.polyfit(x, y, 1)[0] # å–ç¬¬ä¸€ä¸ªå…ƒç´ 
        else:
            trend_slope = 0.0 # ç¡®ä¿ä¸ºæµ®ç‚¹æ•°
        
        peak_hour = None
        if hourly_counts:
            peak_hour = max(hourly_counts.items(), key=lambda x: x[1])[0] # è·å–å°æ—¶è€Œä¸æ˜¯è®¡æ•°
        
        return {
            'hourly_activity': dict(hourly_counts),
            'trend_slope': float(trend_slope),
            'peak_hour': peak_hour,
            'total_activity': sum(counts)
        }

    def _check_cache(self, cache_key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if cache_key not in self.analysis_cache:
            return False
        
        cache_time = self.analysis_cache[cache_key]['timestamp']
        return time.time() - cache_time < self.cache_timeout

    def _cache_result(self, cache_key: str, data: Dict[str, Any]):
        """ç¼“å­˜åˆ†æç»“æœ"""
        self.analysis_cache[cache_key] = {
            'data': data,
            'timestamp': time.time()
        }
        
        # æ¸…ç†è¿‡æœŸç¼“å­˜
        current_time = time.time()
        expired_keys = [
            key for key, value in self.analysis_cache.items()
            if current_time - value['timestamp'] > self.cache_timeout
        ]
        
        for key in expired_keys:
            del self.analysis_cache[key]

    async def get_analysis_summary(self, group_id: str) -> Dict[str, Any]:
        """è·å–åˆ†ææ‘˜è¦"""
        try:
            # è·å–ç¾¤ç»Ÿè®¡
            group_stats = await self.db_manager.get_group_statistics(group_id)
            
            # è·å–æƒ…æ„Ÿè¶‹åŠ¿
            sentiment_trend = await self.analyze_group_sentiment_trend(group_id)
            
            # è·å–æœ€æ´»è·ƒç”¨æˆ·
            active_users = await self._get_most_active_users(group_id, limit=5)
            
            return {
                'group_statistics': group_stats,
                'sentiment_analysis': sentiment_trend,
                'active_users': active_users,
                'analysis_capabilities': {
                    'sklearn_available': SKLEARN_AVAILABLE,
                    'max_sample_size': self.max_sample_size,
                    'cache_status': len(self.analysis_cache)
                }
            }
            
        except Exception as e:
            logger.error(f"è·å–åˆ†ææ‘˜è¦å¤±è´¥: {e}")
            return {}

    async def _get_most_active_users(self, group_id: str, limit: int) -> List[Dict[str, Any]]:
        """è·å–æœ€æ´»è·ƒç”¨æˆ·"""
        try:
            # ä»å…¨å±€æ¶ˆæ¯æ•°æ®åº“è·å–è¿æ¥
            async with self.db_manager.get_db_connection() as conn:
                cursor = await conn.cursor()
                
                await cursor.execute('''
                    SELECT sender_id, sender_name, COUNT(*) as message_count
                    FROM raw_messages 
                    WHERE group_id = ? AND timestamp > ?
                    GROUP BY sender_id, sender_name
                    ORDER BY message_count DESC
                    LIMIT ?
                ''', (group_id, time.time() - 86400, limit))  # æœ€è¿‘24å°æ—¶
                
                users = []
                for row in await cursor.fetchall():
                    users.append({
                        'user_id': row[0],
                        'user_name': row[1],
                        'message_count': row[2]
                    })
                
                return users
            
        except Exception as e:
            logger.error(f"è·å–æœ€æ´»è·ƒç”¨æˆ·å¤±è´¥: {e}")
            return []
