"""
æ•°æ®åº“ç®¡ç†å™¨ - ç®¡ç†åˆ†ç¾¤æ•°æ®åº“å’Œæ•°æ®æŒä¹…åŒ–
"""
import os
import json
import aiosqlite
import time
import asyncio
from typing import Dict, List, Optional, Any, Callable
from datetime import datetime

from astrbot.api import logger

from ..config import PluginConfig

from ..exceptions import DataStorageError

from ..core.patterns import AsyncServiceBase


class DatabaseConnectionPool:
    """æ•°æ®åº“è¿æ¥æ± """
    
    def __init__(self, db_path: str, max_connections: int = 10, min_connections: int = 2):
        self.db_path = db_path
        self.max_connections = max_connections
        self.min_connections = min_connections
        self.pool: asyncio.Queue = asyncio.Queue(maxsize=max_connections)
        self.active_connections = 0
        self.total_connections = 0
        self._lock = asyncio.Lock()
        self._logger = logger

    async def initialize(self):
        """åˆå§‹åŒ–è¿æ¥æ± """
        async with self._lock:
            # åˆ›å»ºæœ€å°æ•°é‡çš„è¿æ¥
            for _ in range(self.min_connections):
                conn = await self._create_connection()
                await self.pool.put(conn)

    async def _create_connection(self) -> aiosqlite.Connection:
        """åˆ›å»ºæ–°çš„æ•°æ®åº“è¿æ¥"""
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        db_dir = os.path.dirname(self.db_path)
        os.makedirs(db_dir, exist_ok=True)
        
        # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æƒé™
        if os.path.exists(self.db_path):
            try:
                import stat
                os.chmod(self.db_path, stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IWGRP)
            except OSError as e:
                self._logger.warning(f"æ— æ³•ä¿®æ”¹æ•°æ®åº“æ–‡ä»¶æƒé™: {e}")
        
        conn = await aiosqlite.connect(self.db_path)
        
        # è®¾ç½®è¿æ¥å‚æ•°
        await conn.execute('PRAGMA foreign_keys = ON')
        await conn.execute('PRAGMA journal_mode = WAL')
        await conn.execute('PRAGMA synchronous = NORMAL')
        await conn.execute('PRAGMA cache_size = 10000')
        await conn.execute('PRAGMA temp_store = memory')
        await conn.commit()
        
        self.total_connections += 1
        self._logger.debug(f"åˆ›å»ºæ–°æ•°æ®åº“è¿æ¥ï¼Œæ€»è¿æ¥æ•°: {self.total_connections}")
        return conn

    async def get_connection(self) -> aiosqlite.Connection:
        """è·å–æ•°æ®åº“è¿æ¥"""
        try:
            # å°è¯•ä»æ± ä¸­è·å–è¿æ¥ï¼ˆéé˜»å¡ï¼‰
            conn = self.pool.get_nowait()
            self.active_connections += 1
            return conn
        except asyncio.QueueEmpty:
            # æ± ä¸­æ— å¯ç”¨è¿æ¥
            async with self._lock:
                if self.total_connections < self.max_connections:
                    # å¯ä»¥åˆ›å»ºæ–°è¿æ¥
                    conn = await self._create_connection()
                    self.active_connections += 1
                    return conn
                else:
                    # è¾¾åˆ°æœ€å¤§è¿æ¥æ•°ï¼Œç­‰å¾…è¿æ¥å½’è¿˜
                    self._logger.debug("è¿æ¥æ± å·²æ»¡ï¼Œç­‰å¾…è¿æ¥å½’è¿˜...")
                    conn = await self.pool.get()
                    self.active_connections += 1
                    return conn

    async def return_connection(self, conn: aiosqlite.Connection):
        """å½’è¿˜æ•°æ®åº“è¿æ¥"""
        if conn:
            try:
                # æ£€æŸ¥è¿æ¥æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
                await conn.execute('SELECT 1')
                await self.pool.put(conn)
                self.active_connections -= 1
            except Exception as e:
                # è¿æ¥å·²æŸåï¼Œå…³é—­å¹¶å‡å°‘è®¡æ•°
                self._logger.warning(f"è¿æ¥å·²æŸåï¼Œå…³é—­è¿æ¥: {e}")
                try:
                    await conn.close()
                except:
                    pass
                self.total_connections -= 1
                self.active_connections -= 1

    async def close_all(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        self._logger.info("å¼€å§‹å…³é—­æ•°æ®åº“è¿æ¥æ± ...")
        
        # å…³é—­æ± ä¸­çš„æ‰€æœ‰è¿æ¥
        while not self.pool.empty():
            try:
                conn = self.pool.get_nowait()
                await conn.close()
                self.total_connections -= 1
            except asyncio.QueueEmpty:
                break
            except Exception as e:
                self._logger.error(f"å…³é—­è¿æ¥æ—¶å‡ºé”™: {e}")
        
        self._logger.info(f"æ•°æ®åº“è¿æ¥æ± å·²å…³é—­ï¼Œå‰©ä½™è¿æ¥æ•°: {self.total_connections}")

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return await self.get_connection()

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½ç›´æ¥å½’è¿˜è¿æ¥ï¼Œå› ä¸ºæˆ‘ä»¬ä¸çŸ¥é“è¿æ¥å¯¹è±¡
        # å®é™…ä½¿ç”¨æ—¶éœ€è¦åœ¨è°ƒç”¨æ–¹æ‰‹åŠ¨å½’è¿˜
        pass


class DatabaseManager(AsyncServiceBase):
    """æ•°æ®åº“ç®¡ç†å™¨ - ä½¿ç”¨è¿æ¥æ± ç®¡ç†æ•°æ®åº“è¿æ¥"""
    
    def __init__(self, config: PluginConfig, context=None):
        super().__init__("database_manager")
        self.config = config
        self.context = context
        self.group_db_connections: Dict[str, aiosqlite.Connection] = {}
        
        # å®‰å…¨åœ°æ„å»ºè·¯å¾„
        if not config.data_dir:
            raise ValueError("config.data_dir ä¸èƒ½ä¸ºç©º")
        
        self.group_data_dir = os.path.join(config.data_dir, "group_databases")
        self.messages_db_path = config.messages_db_path
        
        # åˆå§‹åŒ–è¿æ¥æ± 
        self.connection_pool = DatabaseConnectionPool(
            db_path=self.messages_db_path,
            max_connections=15,  # å¢åŠ æœ€å¤§è¿æ¥æ•°
            min_connections=3    # å¢åŠ æœ€å°è¿æ¥æ•°
        )
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(self.group_data_dir, exist_ok=True)
        
        self._logger.info("æ•°æ®åº“ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼ˆä½¿ç”¨è¿æ¥æ± ï¼‰")

    async def _do_start(self) -> bool:
        """å¯åŠ¨æœåŠ¡æ—¶åˆå§‹åŒ–è¿æ¥æ± å’Œæ•°æ®åº“"""
        try:
            # åˆå§‹åŒ–è¿æ¥æ± 
            await self.connection_pool.initialize()
            self._logger.info("æ•°æ®åº“è¿æ¥æ± åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„
            await self._init_messages_database()
            self._logger.info("å…¨å±€æ¶ˆæ¯æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
            
            return True
        except Exception as e:
            self._logger.error(f"å¯åŠ¨æ•°æ®åº“ç®¡ç†å™¨å¤±è´¥: {e}", exc_info=True)
            return False

    async def _do_stop(self) -> bool:
        """åœæ­¢æœåŠ¡æ—¶å…³é—­æ‰€æœ‰æ•°æ®åº“è¿æ¥"""
        try:
            await self.close_all_connections()
            await self.connection_pool.close_all()
            self._logger.info("æ‰€æœ‰æ•°æ®åº“è¿æ¥å·²å…³é—­")
            return True
        except Exception as e:
            self._logger.error(f"å…³é—­æ•°æ®åº“ç®¡ç†å™¨å¤±è´¥: {e}", exc_info=True)
            return False

    def get_db_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        class ConnectionManager:
            def __init__(self, pool: DatabaseConnectionPool):
                self.pool = pool
                self.connection = None

            async def __aenter__(self):
                self.connection = await self.pool.get_connection()
                return self.connection

            async def __aexit__(self, exc_type, exc_val, exc_tb):
                if self.connection:
                    await self.pool.return_connection(self.connection)

        return ConnectionManager(self.connection_pool)
    
    def get_connection(self):
        """
        è·å–æ•°æ®åº“è¿æ¥çš„åŒæ­¥æ¥å£ï¼Œç”¨äºå…¼å®¹æ—§ä»£ç 
        æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªåŒæ­¥æ–¹æ³•ï¼Œç”¨äºå…¼å®¹ä½¿ç”¨ 'with' è¯­å¥çš„ä»£ç 
        """
        class SyncConnectionWrapper:
            def __init__(self, db_manager):
                self.db_manager = db_manager
                self.connection = None
                
            def __enter__(self):
                # åŒæ­¥è·å–è¿æ¥ï¼Œè¿™éœ€è¦åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨
                import sqlite3
                # ç›´æ¥åˆ›å»ºåŒæ­¥è¿æ¥åˆ°åŒä¸€ä¸ªæ•°æ®åº“æ–‡ä»¶
                self.connection = sqlite3.connect(self.db_manager.messages_db_path)
                return self.connection
                
            def __exit__(self, exc_type, exc_val, exc_tb):
                if self.connection:
                    self.connection.close()
        
        return SyncConnectionWrapper(self)

    async def close_all_connections(self):
        """å…³é—­æ‰€æœ‰æ•°æ®åº“è¿æ¥"""
        try:
            # å…³é—­æ‰€æœ‰ç¾¤ç»„æ•°æ®åº“è¿æ¥
            for group_id, conn in list(self.group_db_connections.items()):
                try:
                    await conn.close()
                    self._logger.info(f"ç¾¤ç»„ {group_id} æ•°æ®åº“è¿æ¥å·²å…³é—­")
                except Exception as e:
                    self._logger.error(f"å…³é—­ç¾¤ç»„ {group_id} æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            
            self.group_db_connections.clear()
            self._logger.info("æ‰€æœ‰ç¾¤ç»„æ•°æ®åº“è¿æ¥å·²å…³é—­")
            
        except Exception as e:
            self._logger.error(f"å…³é—­æ•°æ®åº“è¿æ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise

    async def _retry_on_connection_error(self, func, *args, **kwargs):
        """åœ¨è¿æ¥é”™è¯¯æ—¶é‡è¯•çš„é€šç”¨æ–¹æ³•ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            if "no active connection" in str(e).lower():
                self._logger.warning(f"æ£€æµ‹åˆ°è¿æ¥é—®é¢˜: {e}ï¼Œå°è¯•é‡æ–°æ‰§è¡Œ...")
                try:
                    # è¿æ¥æ± ä¼šè‡ªåŠ¨å¤„ç†è¿æ¥é—®é¢˜ï¼Œç›´æ¥é‡è¯•
                    return await func(*args, **kwargs)
                except Exception as retry_error:
                    self._logger.error(f"é‡è¯•ä¹Ÿå¤±è´¥: {retry_error}")
                    raise retry_error
            else:
                raise e

    async def _init_messages_database(self):
        """
        åˆå§‹åŒ–å…¨å±€æ¶ˆæ¯æ•°æ®åº“ï¼ˆä½¿ç”¨è¿æ¥æ± ï¼‰
        """
        async with self.get_db_connection() as conn:
            await self._init_messages_database_tables(conn)
            self._logger.info("å…¨å±€æ¶ˆæ¯æ•°æ®åº“è¿æ¥æ± åˆå§‹åŒ–å®Œæˆå¹¶è¡¨å·²åˆå§‹åŒ–ã€‚")

    async def _init_messages_database_tables(self, conn: aiosqlite.Connection):
        """åˆå§‹åŒ–å…¨å±€æ¶ˆæ¯SQLiteæ•°æ®åº“çš„è¡¨ç»“æ„"""
        cursor = await conn.cursor()
        
        try:
            # è®¾ç½®æ•°æ®åº“ä¸ºWALæ¨¡å¼ï¼Œæé«˜å¹¶å‘æ€§èƒ½å¹¶é¿å…é”å®šé—®é¢˜
            await cursor.execute('PRAGMA journal_mode=WAL')
            await cursor.execute('PRAGMA synchronous=NORMAL')
            await cursor.execute('PRAGMA cache_size=10000')
            await cursor.execute('PRAGMA temp_store=memory')
            
            # åˆ›å»ºåŸå§‹æ¶ˆæ¯è¡¨
            self._logger.info("å°è¯•åˆ›å»º raw_messages è¡¨...")
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS raw_messages (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    sender_id TEXT NOT NULL,
                    sender_name TEXT,
                    message TEXT NOT NULL,
                    group_id TEXT,
                    platform TEXT,
                    timestamp REAL NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    processed BOOLEAN DEFAULT FALSE
                )
            ''')
            self._logger.info("raw_messages è¡¨åˆ›å»º/æ£€æŸ¥å®Œæˆã€‚")
            await conn.commit() # å¼ºåˆ¶æäº¤ï¼Œç¡®ä¿è¡¨ç»“æ„å†™å…¥ç£ç›˜

            # åˆ›å»ºBotæ¶ˆæ¯è¡¨ (ç”¨äºå­˜å‚¨Botå‘é€çš„æ¶ˆæ¯ï¼Œä¾›å¤šæ ·æ€§ç®¡ç†å™¨ä½¿ç”¨)
            self._logger.info("å°è¯•åˆ›å»º bot_messages è¡¨...")
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS bot_messages (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    group_id TEXT NOT NULL,
                    user_id TEXT,
                    message TEXT NOT NULL,
                    response_to_message_id INTEGER,
                    context_type TEXT,
                    temperature REAL,
                    language_style TEXT,
                    response_pattern TEXT,
                    timestamp REAL NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (response_to_message_id) REFERENCES raw_messages (id)
                )
            ''')
            self._logger.info("bot_messages è¡¨åˆ›å»º/æ£€æŸ¥å®Œæˆã€‚")
            await conn.commit()

            # åˆ›å»ºç­›é€‰åæ¶ˆæ¯è¡¨
            self._logger.info("å°è¯•åˆ›å»º filtered_messages è¡¨...")
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS filtered_messages (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    raw_message_id INTEGER,
                    message TEXT NOT NULL,
                    sender_id TEXT,
                    group_id TEXT,
                    confidence REAL,
                    filter_reason TEXT,
                    timestamp REAL NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    used_for_learning BOOLEAN DEFAULT FALSE,
                    quality_scores TEXT, -- æ–°å¢å­—æ®µï¼Œå­˜å‚¨JSONå­—ç¬¦ä¸²
                    FOREIGN KEY (raw_message_id) REFERENCES raw_messages (id)
                )
            ''')
            self._logger.info("filtered_messages è¡¨åˆ›å»º/æ£€æŸ¥å®Œæˆã€‚")
            
            # æ£€æŸ¥å¹¶æ·»åŠ  quality_scores åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            await cursor.execute("PRAGMA table_info(filtered_messages)")
            columns = [col[1] for col in await cursor.fetchall()]
            if 'quality_scores' not in columns:
                await cursor.execute("ALTER TABLE filtered_messages ADD COLUMN quality_scores TEXT")
                logger.info("å·²ä¸º filtered_messages è¡¨æ·»åŠ  quality_scores åˆ—ã€‚")

            # æ£€æŸ¥å¹¶æ·»åŠ  group_id åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if 'group_id' not in columns:
                await cursor.execute("ALTER TABLE filtered_messages ADD COLUMN group_id TEXT")
                logger.info("å·²ä¸º filtered_messages è¡¨æ·»åŠ  group_id åˆ—ã€‚")

            # æ£€æŸ¥å¹¶æ·»åŠ  refined åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if 'refined' not in columns:
                await cursor.execute("ALTER TABLE filtered_messages ADD COLUMN refined BOOLEAN DEFAULT 0")
                logger.info("å·²ä¸º filtered_messages è¡¨æ·»åŠ  refined åˆ—ã€‚")

            # åˆ›å»ºå­¦ä¹ æ‰¹æ¬¡è¡¨
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS learning_batches (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    group_id TEXT NOT NULL,
                    start_time REAL NOT NULL,
                    end_time REAL,
                    quality_score REAL DEFAULT 0.5,
                    processed_messages INTEGER DEFAULT 0,
                    batch_name TEXT UNIQUE,
                    message_count INTEGER,
                    filtered_count INTEGER,
                    success BOOLEAN,
                    error_message TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')

            # åˆ›å»ºäººæ ¼æ›´æ–°è®°å½•è¡¨
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS persona_update_records (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL NOT NULL,
                    group_id TEXT NOT NULL,
                    update_type TEXT NOT NULL,
                    original_content TEXT,
                    new_content TEXT NOT NULL,
                    reason TEXT,
                    status TEXT DEFAULT 'pending',
                    reviewer_comment TEXT,
                    review_time REAL
                )
            ''')
            
            # åˆ›å»ºç´¢å¼•
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_raw_messages_timestamp ON raw_messages(timestamp)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_raw_messages_sender ON raw_messages(sender_id)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_raw_messages_processed ON raw_messages(processed)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_filtered_messages_confidence ON filtered_messages(confidence)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_filtered_messages_used ON filtered_messages(used_for_learning)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_persona_update_records_status ON persona_update_records(status)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_persona_update_records_group_id ON persona_update_records(group_id)')
            
            # æ–°å¢å¼ºåŒ–å­¦ä¹ ç›¸å…³è¡¨
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS reinforcement_learning_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    group_id TEXT NOT NULL,
                    timestamp REAL NOT NULL,
                    replay_analysis TEXT,
                    optimization_strategy TEXT,
                    reinforcement_feedback TEXT,
                    next_action TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS persona_fusion_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    group_id TEXT NOT NULL,
                    timestamp REAL NOT NULL,
                    base_persona_hash INTEGER,
                    incremental_hash INTEGER,
                    fusion_result TEXT,
                    compatibility_score REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS strategy_optimization_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    group_id TEXT NOT NULL,
                    timestamp REAL NOT NULL,
                    original_strategy TEXT,
                    optimization_result TEXT,
                    expected_improvement TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS learning_performance_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    group_id TEXT NOT NULL,
                    session_id TEXT,
                    timestamp REAL NOT NULL,
                    quality_score REAL,
                    learning_time REAL,
                    success BOOLEAN,
                    successful_pattern TEXT,
                    failed_pattern TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ä¸ºå¼ºåŒ–å­¦ä¹ è¡¨åˆ›å»ºç´¢å¼•
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_reinforcement_learning_group ON reinforcement_learning_results(group_id)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_persona_fusion_group ON persona_fusion_history(group_id)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_strategy_optimization_group ON strategy_optimization_results(group_id)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_learning_performance_group ON learning_performance_history(group_id)')
            
            # åˆ›å»ºLLMè°ƒç”¨ç»Ÿè®¡è¡¨
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS llm_call_statistics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    provider_type TEXT NOT NULL, -- filter, refine, reinforce
                    model_name TEXT,
                    total_calls INTEGER DEFAULT 0,
                    success_calls INTEGER DEFAULT 0,
                    failed_calls INTEGER DEFAULT 0,
                    total_response_time_ms INTEGER DEFAULT 0,
                    avg_response_time_ms REAL DEFAULT 0,
                    success_rate REAL DEFAULT 0,
                    last_call_time REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(provider_type, model_name)
                )
            ''')
            
            # é£æ ¼å­¦ä¹ è®°å½•è¡¨ (ä»ç¾¤ç»„æ•°æ®åº“ç§»è‡³æ¶ˆæ¯æ•°æ®åº“)
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS style_learning_records (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    group_id TEXT NOT NULL,
                    style_type TEXT NOT NULL,
                    learned_patterns TEXT, -- JSONæ ¼å¼å­˜å‚¨å­¦ä¹ åˆ°çš„æ¨¡å¼
                    confidence_score REAL,
                    sample_count INTEGER,
                    learning_time REAL NOT NULL,
                    last_updated REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # è¯­è¨€é£æ ¼æ¨¡å¼è¡¨ (ä»ç¾¤ç»„æ•°æ®åº“ç§»è‡³æ¶ˆæ¯æ•°æ®åº“)
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS language_style_patterns (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    group_id TEXT NOT NULL,
                    language_style TEXT NOT NULL,
                    example_phrases TEXT, -- JSONæ ¼å¼å­˜å‚¨ç¤ºä¾‹çŸ­è¯­
                    usage_frequency INTEGER DEFAULT 0,
                    context_type TEXT DEFAULT 'general',
                    confidence_score REAL,
                    last_updated REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ä¸ºæ–°è¡¨åˆ›å»ºç´¢å¼•
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_style_learning_group ON style_learning_records(group_id)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_style_learning_time ON style_learning_records(learning_time)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_language_style_group ON language_style_patterns(group_id)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_language_style_frequency ON language_style_patterns(usage_frequency)')

            # åˆ›å»ºè¯é¢˜æ€»ç»“è¡¨
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS topic_summaries (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    group_id TEXT NOT NULL,
                    topic TEXT NOT NULL,
                    summary TEXT,
                    participants TEXT,  -- JSONæ ¼å¼å­˜å‚¨å‚ä¸è€…åˆ—è¡¨
                    message_count INTEGER DEFAULT 0,
                    start_timestamp REAL,
                    end_timestamp REAL,
                    generated_at REAL NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')

            # ä¸ºè¯é¢˜æ€»ç»“è¡¨åˆ›å»ºç´¢å¼•
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_topic_summaries_group ON topic_summaries(group_id)')
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_topic_summaries_time ON topic_summaries(generated_at)')

            await conn.commit()
            logger.info("å…¨å±€æ¶ˆæ¯æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
            
        except aiosqlite.Error as e:
            logger.error(f"å…¨å±€æ¶ˆæ¯æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            # å°è¯•åˆ é™¤å¯èƒ½æŸåçš„æ•°æ®åº“æ–‡ä»¶ï¼Œä»¥ä¾¿ä¸‹æ¬¡å¯åŠ¨æ—¶é‡æ–°åˆ›å»º
            if os.path.exists(self.messages_db_path):
                self._logger.warning(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼Œå°è¯•åˆ é™¤æŸåçš„æ•°æ®åº“æ–‡ä»¶: {self.messages_db_path}")
                try:
                    os.remove(self.messages_db_path)
                except OSError as ose:
                    self._logger.error(f"åˆ é™¤æ•°æ®åº“æ–‡ä»¶å¤±è´¥: {ose}")
            raise DataStorageError(f"å…¨å±€æ¶ˆæ¯æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}")

    def get_group_db_path(self, group_id: str) -> str:
        """è·å–ç¾¤æ•°æ®åº“æ–‡ä»¶è·¯å¾„"""
        if not group_id:
            raise ValueError("group_id ä¸èƒ½ä¸ºç©º")
        if not self.group_data_dir:
            raise ValueError("group_data_dir æœªåˆå§‹åŒ–")
        return os.path.join(self.group_data_dir, f"{group_id}_ID.db")

    async def get_group_connection(self, group_id: str) -> aiosqlite.Connection:
        """è·å–ç¾¤æ•°æ®åº“è¿æ¥"""
        if group_id not in self.group_db_connections:
            db_path = self.get_group_db_path(group_id)
            
            # ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
            db_dir = os.path.dirname(db_path)
            os.makedirs(db_dir, exist_ok=True)
            
            # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æƒé™
            if os.path.exists(db_path):
                try:
                    # å°è¯•ä¿®æ”¹æ–‡ä»¶æƒé™ä¸ºå¯å†™
                    import stat
                    os.chmod(db_path, stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IWGRP)
                except OSError as e:
                    logger.warning(f"æ— æ³•ä¿®æ”¹ç¾¤æ•°æ®åº“æ–‡ä»¶æƒé™: {e}")
            
            conn = await aiosqlite.connect(db_path)
            
            # è®¾ç½®è¿æ¥å‚æ•°ï¼Œç¡®ä¿æ•°æ®åº“å¯å†™
            await conn.execute('PRAGMA foreign_keys = ON')
            await conn.execute('PRAGMA journal_mode = WAL')  
            await conn.execute('PRAGMA synchronous = NORMAL')
            await conn.commit()
            
            await self._init_group_database(conn)
            self.group_db_connections[group_id] = conn
            logger.info(f"å·²åˆ›å»ºç¾¤ {group_id} çš„æ•°æ®åº“è¿æ¥")
        
        return self.group_db_connections[group_id]

    async def _init_group_database(self, conn: aiosqlite.Connection):
        """åˆå§‹åŒ–ç¾¤æ•°æ®åº“è¡¨ç»“æ„"""
        cursor = await conn.cursor()
        
        try:
            # è®¾ç½®æ•°æ®åº“ä¸ºWALæ¨¡å¼ï¼Œæé«˜å¹¶å‘æ€§èƒ½å¹¶é¿å…é”å®šé—®é¢˜
            await cursor.execute('PRAGMA journal_mode=WAL')
            await cursor.execute('PRAGMA synchronous=NORMAL')
            await cursor.execute('PRAGMA cache_size=10000')
            await cursor.execute('PRAGMA temp_store=memory')
            
            # åŸå§‹æ¶ˆæ¯è¡¨ (ç¾¤æ•°æ®åº“ä¸­ä¸å†å­˜å‚¨åŸå§‹æ¶ˆæ¯ï¼Œç”±å…¨å±€æ¶ˆæ¯æ•°æ®åº“ç»Ÿä¸€ç®¡ç†)
            # ç­›é€‰æ¶ˆæ¯è¡¨ (ç¾¤æ•°æ®åº“ä¸­ä¸å†å­˜å‚¨ç­›é€‰æ¶ˆæ¯ï¼Œç”±å…¨å±€æ¶ˆæ¯æ•°æ®åº“ç»Ÿä¸€ç®¡ç†)
            
            # ç”¨æˆ·ç”»åƒè¡¨
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS user_profiles (
                    qq_id TEXT PRIMARY KEY,
                    qq_name TEXT,
                    nicknames TEXT, -- JSONæ ¼å¼å­˜å‚¨
                    activity_pattern TEXT, -- JSONæ ¼å¼å­˜å‚¨æ´»åŠ¨æ¨¡å¼
                    communication_style TEXT, -- JSONæ ¼å¼å­˜å‚¨æ²Ÿé€šé£æ ¼
                    topic_preferences TEXT, -- JSONæ ¼å¼å­˜å‚¨è¯é¢˜åå¥½
                    emotional_tendency TEXT, -- JSONæ ¼å¼å­˜å‚¨æƒ…æ„Ÿå€¾å‘
                    last_active REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ç¤¾äº¤å…³ç³»è¡¨
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS social_relations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    from_user TEXT NOT NULL,
                    to_user TEXT NOT NULL,
                    relation_type TEXT NOT NULL, -- mention, reply, frequent_interaction
                    strength REAL NOT NULL,
                    frequency INTEGER NOT NULL,
                    last_interaction REAL NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(from_user, to_user, relation_type)
                )
            ''')
            
            # é£æ ¼æ¡£æ¡ˆè¡¨
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS style_profiles (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    profile_name TEXT NOT NULL,
                    vocabulary_richness REAL,
                    sentence_complexity REAL,
                    emotional_expression REAL,
                    interaction_tendency REAL,
                    topic_diversity REAL,
                    formality_level REAL,
                    creativity_score REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # äººæ ¼å¤‡ä»½è¡¨
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS persona_backups (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    backup_name TEXT NOT NULL,
                    timestamp REAL NOT NULL,
                    reason TEXT,
                    persona_config TEXT, -- JSONæ ¼å¼å­˜å‚¨äººæ ¼é…ç½®
                    original_persona TEXT, -- JSONæ ¼å¼å­˜å‚¨
                    imitation_dialogues TEXT, -- JSONæ ¼å¼å­˜å‚¨æ¨¡ä»¿å¯¹è¯
                    backup_reason TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # é£æ ¼å­¦ä¹ è®°å½•è¡¨
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS style_learning_records (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    style_type TEXT NOT NULL,
                    learned_patterns TEXT, -- JSONæ ¼å¼å­˜å‚¨å­¦ä¹ åˆ°çš„æ¨¡å¼
                    confidence_score REAL,
                    sample_count INTEGER,
                    last_updated REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # æƒ…æ„Ÿè¡¨è¾¾æ¨¡å¼è¡¨
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS emotion_patterns (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    emotional_pattern TEXT NOT NULL,
                    confidence_score REAL,
                    frequency INTEGER DEFAULT 0,
                    context_type TEXT,
                    last_updated REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # è¯­è¨€é£æ ¼æ¨¡å¼è¡¨
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS language_style_patterns (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    language_style TEXT NOT NULL,
                    example_phrases TEXT, -- JSONæ ¼å¼å­˜å‚¨ç¤ºä¾‹çŸ­è¯­
                    usage_frequency INTEGER DEFAULT 0,
                    context_type TEXT DEFAULT 'general',
                    confidence_score REAL,
                    last_updated REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ä¸»é¢˜åå¥½è¡¨
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS topic_preferences (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    topic_category TEXT NOT NULL,
                    interest_level REAL,
                    response_style TEXT,
                    sample_count INTEGER DEFAULT 0,
                    confidence_score REAL,
                    last_updated REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # äººæ ¼æ›´æ–°å®¡æŸ¥è¡¨
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS persona_update_reviews (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    update_type TEXT NOT NULL, -- style_update, persona_update, learning_update
                    original_content TEXT, -- åŸå§‹äººæ ¼å†…å®¹
                    proposed_content TEXT, -- å»ºè®®çš„æ–°å†…å®¹
                    confidence_score REAL,
                    reason TEXT, -- æ›´æ–°åŸå› 
                    sample_messages TEXT, -- JSONæ ¼å¼å­˜å‚¨è§¦å‘æ›´æ–°çš„ç¤ºä¾‹æ¶ˆæ¯
                    review_status TEXT DEFAULT 'pending', -- pending, approved, rejected
                    reviewer_comment TEXT,
                    created_at REAL,
                    reviewed_at REAL,
                    auto_score REAL, -- è‡ªåŠ¨è¯„åˆ†
                    manual_override BOOLEAN DEFAULT FALSE
                )
            ''')
            
            # å­¦ä¹ æ‰¹æ¬¡è¡¨ (å¦‚æœä¸å­˜åœ¨)
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS learning_batches (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    batch_name TEXT,
                    start_time REAL,
                    end_time REAL,
                    processed_messages INTEGER DEFAULT 0,
                    success BOOLEAN DEFAULT FALSE,
                    error_message TEXT,
                    learning_type TEXT, -- style_learning, persona_update, etc.
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # å­¦ä¹ ä¼šè¯è¡¨
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS learning_sessions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT UNIQUE NOT NULL,
                    start_time REAL NOT NULL,
                    end_time REAL,
                    messages_processed INTEGER DEFAULT 0,
                    filtered_messages INTEGER DEFAULT 0,
                    style_updates INTEGER DEFAULT 0,
                    quality_score REAL DEFAULT 0.0,
                    success BOOLEAN DEFAULT FALSE,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # åˆ›å»ºç´¢å¼•
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_social_relations_from_user ON social_relations(from_user)') 
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_social_relations_to_user ON social_relations(to_user)') 
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_user_profiles_active ON user_profiles(last_active)') 
            await cursor.execute('CREATE INDEX IF NOT EXISTS idx_style_profiles_name ON style_profiles(profile_name)')
            
            # åˆ›å»ºå¥½æ„Ÿåº¦è¡¨
            await cursor.execute(''' 
                CREATE TABLE IF NOT EXISTS user_affection (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id TEXT NOT NULL,
                    group_id TEXT NOT NULL,
                    affection_level INTEGER DEFAULT 0,
                    last_interaction REAL NOT NULL,
                    last_updated REAL NOT NULL,
                    interaction_count INTEGER DEFAULT 0,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(user_id, group_id)
                )
            ''')
            
            # åˆ›å»ºbotæƒ…ç»ªè¡¨
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS bot_mood (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    group_id TEXT NOT NULL,
                    mood_type TEXT NOT NULL,
                    mood_intensity REAL DEFAULT 0.5,
                    mood_description TEXT,
                    start_time REAL NOT NULL,
                    end_time REAL,
                    is_active BOOLEAN DEFAULT TRUE,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # åˆ›å»ºå¥½æ„Ÿåº¦å˜åŒ–è®°å½•è¡¨
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS affection_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id TEXT NOT NULL,
                    group_id TEXT NOT NULL,
                    change_amount INTEGER NOT NULL,
                    previous_level INTEGER NOT NULL,
                    new_level INTEGER NOT NULL,
                    change_reason TEXT,
                    bot_mood TEXT,
                    timestamp REAL NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            await conn.commit() 
            logger.debug("ç¾¤æ•°æ®åº“è¡¨ç»“æ„åˆå§‹åŒ–å®Œæˆ") 
            
        except aiosqlite.Error as e: 
            logger.error(f"åˆå§‹åŒ–ç¾¤æ•°æ®åº“å¤±è´¥: {e}", exc_info=True) 
            raise DataStorageError(f"åˆå§‹åŒ–ç¾¤æ•°æ®åº“å¤±è´¥: {str(e)}")

    async def save_style_profile(self, group_id: str, profile_data: Dict[str, Any]):
        """ä¿å­˜é£æ ¼æ¡£æ¡ˆåˆ°æ•°æ®åº“"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()

        try:
            await cursor.execute('''
                INSERT OR REPLACE INTO style_profiles
                (profile_name, vocabulary_richness, sentence_complexity, emotional_expression,
                 interaction_tendency, topic_diversity, formality_level, creativity_score)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                profile_data['profile_name'],
                profile_data.get('vocabulary_richness'),
                profile_data.get('sentence_complexity'),
                profile_data.get('emotional_expression'),
                profile_data.get('interaction_tendency'),
                profile_data.get('topic_diversity'),
                profile_data.get('formality_level'),
                profile_data.get('creativity_score')
            ))
            await conn.commit()
            logger.debug(f"é£æ ¼æ¡£æ¡ˆ '{profile_data['profile_name']}' å·²ä¿å­˜åˆ°ç¾¤ {group_id} æ•°æ®åº“ã€‚")
        except aiosqlite.Error as e:
            logger.error(f"ä¿å­˜é£æ ¼æ¡£æ¡ˆå¤±è´¥: {e}", exc_info=True)
            raise DataStorageError(f"ä¿å­˜é£æ ¼æ¡£æ¡ˆå¤±è´¥: {str(e)}")

    async def load_style_profile(self, group_id: str, profile_name: str) -> Optional[Dict[str, Any]]:
        """ä»æ•°æ®åº“åŠ è½½é£æ ¼æ¡£æ¡ˆ"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()

        try:
            await cursor.execute('''
                SELECT profile_name, vocabulary_richness, sentence_complexity, emotional_expression,
                       interaction_tendency, topic_diversity, formality_level, creativity_score
                FROM style_profiles WHERE profile_name = ?
            ''', (profile_name,))
            row = await cursor.fetchone()
            if not row:
                return None
            return {
                'profile_name': row[0],
                'vocabulary_richness': row[1],
                'sentence_complexity': row[2],
                'emotional_expression': row[3],
                'interaction_tendency': row[4],
                'topic_diversity': row[5],
                'formality_level': row[6],
                'creativity_score': row[7]
            }
        except aiosqlite.Error as e:
            logger.error(f"åŠ è½½é£æ ¼æ¡£æ¡ˆå¤±è´¥: {e}", exc_info=True)
            return None

    async def save_user_profile(self, group_id: str, profile_data: Dict[str, Any]):
        """ä¿å­˜ç”¨æˆ·ç”»åƒåˆ°æ•°æ®åº“"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                INSERT OR REPLACE INTO user_profiles 
                (qq_id, qq_name, nicknames, activity_pattern, communication_style, 
                 topic_preferences, emotional_tendency, last_active, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                profile_data['qq_id'],
                profile_data.get('qq_name', ''),
                json.dumps(profile_data.get('nicknames', []), ensure_ascii=False),
                json.dumps(profile_data.get('activity_pattern', {}), ensure_ascii=False),
                json.dumps(profile_data.get('communication_style', {}), ensure_ascii=False),
                json.dumps(profile_data.get('topic_preferences', {}), ensure_ascii=False),
                json.dumps(profile_data.get('emotional_tendency', {}), ensure_ascii=False),
                profile_data.get('last_active', time.time()),  # ä½¿ç”¨profileä¸­çš„å€¼æˆ–å½“å‰æ—¶é—´
                datetime.now().isoformat()
            ))
            
            await conn.commit()
            
        except aiosqlite.Error as e:
            logger.error(f"ä¿å­˜ç”¨æˆ·ç”»åƒå¤±è´¥: {e}", exc_info=True)
            raise DataStorageError(f"ä¿å­˜ç”¨æˆ·ç”»åƒå¤±è´¥: {str(e)}")

    async def load_user_profile(self, group_id: str, qq_id: str) -> Optional[Dict[str, Any]]:
        """ä»æ•°æ®åº“åŠ è½½ç”¨æˆ·ç”»åƒ"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT qq_id, qq_name, nicknames, activity_pattern, communication_style,
                       topic_preferences, emotional_tendency, last_active
                FROM user_profiles WHERE qq_id = ?
            ''', (qq_id,))
            
            row = await cursor.fetchone()
            if not row:
                return None
            
            return {
                'qq_id': row[0],
                'qq_name': row[1],
                'nicknames': json.loads(row[2]) if row[2] else [],
                'activity_pattern': json.loads(row[3]) if row[3] else {},
                'communication_style': json.loads(row[4]) if row[4] else {},
                'topic_preferences': json.loads(row[5]) if row[5] else {},
                'emotional_tendency': json.loads(row[6]) if row[6] else {},
                'last_active': row[7]
            }
            
        except aiosqlite.Error as e:
            logger.error(f"åŠ è½½ç”¨æˆ·ç”»åƒå¤±è´¥: {e}", exc_info=True)
            return None

    async def save_social_relation(self, group_id: str, relation_data: Dict[str, Any]):
        """ä¿å­˜ç¤¾äº¤å…³ç³»åˆ°æ•°æ®åº“"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()

        try:
            await cursor.execute('''
                INSERT OR REPLACE INTO social_relations
                (from_user, to_user, relation_type, strength, frequency, last_interaction, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                relation_data['from_user'],
                relation_data['to_user'],
                relation_data['relation_type'],
                relation_data['strength'],
                relation_data['frequency'],
                relation_data['last_interaction'],
                datetime.now().isoformat()
            ))

            await conn.commit()

        except aiosqlite.Error as e:
            logger.error(f"ä¿å­˜ç¤¾äº¤å…³ç³»å¤±è´¥: {e}", exc_info=True)
            raise DataStorageError(f"ä¿å­˜ç¤¾äº¤å…³ç³»å¤±è´¥: {str(e)}")

    async def get_social_relations_by_group(self, group_id: str) -> List[Dict[str, Any]]:
        """è·å–æŒ‡å®šç¾¤ç»„çš„ç¤¾äº¤å…³ç³»"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()

        try:
            await cursor.execute('''
                SELECT from_user, to_user, relation_type, strength, frequency, last_interaction
                FROM social_relations
                ORDER BY frequency DESC, strength DESC
            ''')

            rows = await cursor.fetchall()
            relations = []

            for row in rows:
                relations.append({
                    'from_user': row[0],
                    'to_user': row[1],
                    'relation_type': row[2],
                    'strength': row[3],
                    'frequency': row[4],
                    'last_interaction': row[5]
                })

            return relations

        except aiosqlite.Error as e:
            logger.error(f"è·å–ç¤¾äº¤å…³ç³»å¤±è´¥: {e}", exc_info=True)
            return []

    async def get_user_social_relations(self, group_id: str, user_id: str) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šç”¨æˆ·åœ¨ç¾¤ç»„ä¸­çš„ç¤¾äº¤å…³ç³»

        Args:
            group_id: ç¾¤ç»„ID
            user_id: ç”¨æˆ·ID

        Returns:
            åŒ…å«ç”¨æˆ·ç¤¾äº¤å…³ç³»çš„å­—å…¸ï¼ŒåŒ…æ‹¬ï¼š
            - outgoing: è¯¥ç”¨æˆ·å‘èµ·çš„å…³ç³»åˆ—è¡¨
            - incoming: æŒ‡å‘è¯¥ç”¨æˆ·çš„å…³ç³»åˆ—è¡¨
            - total_relations: æ€»å…³ç³»æ•°
        """
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()

        try:
            user_key = f"{group_id}:{user_id}"

            # è·å–è¯¥ç”¨æˆ·å‘èµ·çš„å…³ç³»ï¼ˆoutgoingï¼‰
            await cursor.execute('''
                SELECT from_user, to_user, relation_type, strength, frequency, last_interaction
                FROM social_relations
                WHERE from_user = ? OR from_user = ?
                ORDER BY frequency DESC, strength DESC
                LIMIT 10
            ''', (user_key, user_id))

            outgoing_rows = await cursor.fetchall()
            outgoing_relations = []

            for row in outgoing_rows:
                outgoing_relations.append({
                    'from_user': row[0],
                    'to_user': row[1],
                    'relation_type': row[2],
                    'strength': row[3],
                    'frequency': row[4],
                    'last_interaction': row[5]
                })

            # è·å–æŒ‡å‘è¯¥ç”¨æˆ·çš„å…³ç³»ï¼ˆincomingï¼‰
            await cursor.execute('''
                SELECT from_user, to_user, relation_type, strength, frequency, last_interaction
                FROM social_relations
                WHERE to_user = ? OR to_user = ?
                ORDER BY frequency DESC, strength DESC
                LIMIT 10
            ''', (user_key, user_id))

            incoming_rows = await cursor.fetchall()
            incoming_relations = []

            for row in incoming_rows:
                incoming_relations.append({
                    'from_user': row[0],
                    'to_user': row[1],
                    'relation_type': row[2],
                    'strength': row[3],
                    'frequency': row[4],
                    'last_interaction': row[5]
                })

            return {
                'user_id': user_id,
                'group_id': group_id,
                'outgoing': outgoing_relations,
                'incoming': incoming_relations,
                'total_relations': len(outgoing_relations) + len(incoming_relations)
            }

        except aiosqlite.Error as e:
            logger.error(f"è·å–ç”¨æˆ·ç¤¾äº¤å…³ç³»å¤±è´¥: {e}", exc_info=True)
            return {
                'user_id': user_id,
                'group_id': group_id,
                'outgoing': [],
                'incoming': [],
                'total_relations': 0
            }


    async def save_raw_message(self, message_data) -> int:
        """
        å°†åŸå§‹æ¶ˆæ¯ä¿å­˜åˆ°å…¨å±€æ¶ˆæ¯æ•°æ®åº“ã€‚
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                # æ£€æŸ¥message_dataæ˜¯å¦ä¸ºå­—å…¸æˆ–å¯¹è±¡
                if hasattr(message_data, 'sender_id'):
                    # å¦‚æœæ˜¯å¯¹è±¡ï¼Œç›´æ¥è®¿é—®å±æ€§
                    await cursor.execute('''
                        INSERT INTO raw_messages (sender_id, sender_name, message, group_id, platform, timestamp)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (
                        message_data.sender_id,
                        message_data.sender_name,
                        message_data.message,
                        message_data.group_id,
                        message_data.platform,
                        message_data.timestamp
                    ))
                else:
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œä½¿ç”¨å­—å…¸è®¿é—®
                    await cursor.execute('''
                        INSERT INTO raw_messages (sender_id, sender_name, message, group_id, platform, timestamp)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (
                        message_data.get('sender_id'),
                        message_data.get('sender_name'),
                        message_data.get('message'),
                        message_data.get('group_id'),
                        message_data.get('platform'),
                        message_data.get('timestamp')
                    ))
                
                message_id = cursor.lastrowid
                await conn.commit()
                logger.info(f"ğŸ’¾ æ•°æ®åº“å†™å…¥æˆåŠŸ: ID={message_id}, timestamp={message_data.timestamp if hasattr(message_data, 'timestamp') else message_data.get('timestamp')}")
                return message_id
                
            except aiosqlite.Error as e:
                logger.error(f"ä¿å­˜åŸå§‹æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
                raise DataStorageError(f"ä¿å­˜åŸå§‹æ¶ˆæ¯å¤±è´¥: {str(e)}")
            finally:
                await cursor.close()

    async def get_unprocessed_messages(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        è·å–æœªå¤„ç†çš„åŸå§‹æ¶ˆæ¯
        
        Args:
            limit: é™åˆ¶è¿”å›çš„æ¶ˆæ¯æ•°é‡
            
        Returns:
            æœªå¤„ç†çš„æ¶ˆæ¯åˆ—è¡¨
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                if limit:
                    await cursor.execute('''
                        SELECT id, sender_id, sender_name, message, group_id, platform, timestamp
                        FROM raw_messages 
                        WHERE processed = FALSE 
                        ORDER BY timestamp ASC 
                        LIMIT ?
                    ''', (limit,))
                else:
                    await cursor.execute('''
                        SELECT id, sender_id, sender_name, message, group_id, platform, timestamp
                        FROM raw_messages 
                        WHERE processed = FALSE 
                        ORDER BY timestamp ASC
                    ''')
                
                messages = []
                for row in await cursor.fetchall():
                    messages.append({
                        'id': row[0],
                        'sender_id': row[1],
                        'sender_name': row[2],
                        'message': row[3],
                        'group_id': row[4],
                        'platform': row[5],
                        'timestamp': row[6]
                    })
                
                logger.debug(f"è·å–åˆ° {len(messages)} æ¡æœªå¤„ç†æ¶ˆæ¯")
                return messages
                
            except aiosqlite.Error as e:
                logger.error(f"è·å–æœªå¤„ç†æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
                raise DataStorageError(f"è·å–æœªå¤„ç†æ¶ˆæ¯å¤±è´¥: {str(e)}")
            finally:
                await cursor.close()

    async def mark_messages_processed(self, message_ids: List[int]) -> bool:
        """
        æ ‡è®°æ¶ˆæ¯ä¸ºå·²å¤„ç†
        
        Args:
            message_ids: æ¶ˆæ¯IDåˆ—è¡¨
            
        Returns:
            æ˜¯å¦æˆåŠŸæ ‡è®°
        """
        if not message_ids:
            return True
            
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                # æ‰¹é‡æ›´æ–°æ¶ˆæ¯çŠ¶æ€
                placeholders = ','.join(['?' for _ in message_ids])
                await cursor.execute(f'''
                    UPDATE raw_messages 
                    SET processed = TRUE 
                    WHERE id IN ({placeholders})
                ''', message_ids)
                
                await conn.commit()
                logger.debug(f"å·²æ ‡è®° {len(message_ids)} æ¡æ¶ˆæ¯ä¸ºå·²å¤„ç†")
                return True
                
            except aiosqlite.Error as e:
                logger.error(f"æ ‡è®°æ¶ˆæ¯å¤„ç†çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
                raise DataStorageError(f"æ ‡è®°æ¶ˆæ¯å¤„ç†çŠ¶æ€å¤±è´¥: {str(e)}")
            finally:
                await cursor.close()

    async def add_filtered_message(self, filtered_data: Dict[str, Any]) -> int:
        """
        æ·»åŠ ç­›é€‰åçš„æ¶ˆæ¯
        
        Args:
            filtered_data: ç­›é€‰åçš„æ¶ˆæ¯æ•°æ®
            
        Returns:
            ç­›é€‰æ¶ˆæ¯çš„ID
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                await cursor.execute('''
                    INSERT INTO filtered_messages 
                    (raw_message_id, message, sender_id, confidence, filter_reason, timestamp, quality_scores, group_id)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    filtered_data.get('raw_message_id'),
                    filtered_data.get('message'),
                    filtered_data.get('sender_id'),
                    filtered_data.get('confidence', 0.8),
                    filtered_data.get('filter_reason', ''),
                    filtered_data.get('timestamp') or time.time(),
                    json.dumps(filtered_data.get('quality_scores', {}), ensure_ascii=False),
                    filtered_data.get('group_id')
                ))
                
                filtered_id = cursor.lastrowid
                await conn.commit()
                logger.debug(f"ç­›é€‰æ¶ˆæ¯å·²ä¿å­˜ï¼ŒID: {filtered_id}")
                return filtered_id
                
            except aiosqlite.Error as e:
                logger.error(f"æ·»åŠ ç­›é€‰æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
                raise DataStorageError(f"æ·»åŠ ç­›é€‰æ¶ˆæ¯å¤±è´¥: {str(e)}")
            finally:
                await cursor.close()

    async def get_filtered_messages_for_learning(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        è·å–ç”¨äºå­¦ä¹ çš„ç­›é€‰æ¶ˆæ¯
        
        Args:
            limit: é™åˆ¶è¿”å›çš„æ¶ˆæ¯æ•°é‡
            
        Returns:
            ç­›é€‰æ¶ˆæ¯åˆ—è¡¨
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                if limit:
                    await cursor.execute('''
                        SELECT id, message, sender_id, confidence, quality_scores, timestamp, group_id
                        FROM filtered_messages 
                        WHERE used_for_learning = FALSE 
                        ORDER BY timestamp DESC 
                        LIMIT ?
                    ''', (limit,))
                else:
                    await cursor.execute('''
                        SELECT id, message, sender_id, confidence, quality_scores, timestamp, group_id
                        FROM filtered_messages 
                        WHERE used_for_learning = FALSE 
                        ORDER BY timestamp DESC
                    ''')
                
                messages = []
                for row in await cursor.fetchall():
                    quality_scores = {}
                    try:
                        if row[4]:  # quality_scores
                            quality_scores = json.loads(row[4])
                    except (json.JSONDecodeError, TypeError):
                        pass
                    
                    messages.append({
                        'id': row[0],
                        'message': row[1],
                        'sender_id': row[2],
                        'confidence': row[3],
                        'quality_scores': quality_scores,
                        'timestamp': row[5],
                        'group_id': row[6]
                    })
                
                return messages
                
            except aiosqlite.Error as e:
                logger.error(f"è·å–å­¦ä¹ æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
                raise DataStorageError(f"è·å–å­¦ä¹ æ¶ˆæ¯å¤±è´¥: {str(e)}")
            finally:
                await cursor.close()

    async def get_recent_filtered_messages(self, group_id: str, limit: int = 5) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šç¾¤ç»„æœ€è¿‘çš„ç­›é€‰æ¶ˆæ¯
        
        Args:
            group_id: ç¾¤ç»„ID
            limit: æ¶ˆæ¯æ•°é‡é™åˆ¶
            
        Returns:
            ç­›é€‰æ¶ˆæ¯åˆ—è¡¨
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                await cursor.execute('''
                    SELECT id, message, sender_id, confidence, quality_scores, timestamp
                    FROM filtered_messages 
                    WHERE group_id = ? 
                    ORDER BY timestamp DESC 
                    LIMIT ?
                ''', (group_id, limit))
                
                messages = []
                for row in await cursor.fetchall():
                    quality_scores = {}
                    try:
                        if row[4]:
                            quality_scores = json.loads(row[4])
                    except json.JSONDecodeError:
                        pass
                        
                    messages.append({
                        'id': row[0],
                        'message': row[1],
                        'sender_id': row[2],
                        'confidence': row[3],
                        'quality_scores': quality_scores,
                        'timestamp': row[5]
                    })
                    
                return messages
                
            except aiosqlite.Error as e:
                logger.error(f"è·å–æœ€è¿‘ç­›é€‰æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
                return []
            finally:
                await cursor.close()

    async def get_recent_raw_messages(self, group_id: str, limit: int = 25) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šç¾¤ç»„æœ€è¿‘çš„åŸå§‹æ¶ˆæ¯ï¼Œç”¨äºè¡¨è¾¾é£æ ¼å­¦ä¹ 
        
        Args:
            group_id: ç¾¤ç»„ID
            limit: æ¶ˆæ¯æ•°é‡é™åˆ¶
            
        Returns:
            åŸå§‹æ¶ˆæ¯åˆ—è¡¨
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                await cursor.execute('''
                    SELECT id, sender_id, sender_name, message, group_id, platform, timestamp
                    FROM raw_messages 
                    WHERE group_id = ? 
                    ORDER BY timestamp DESC 
                    LIMIT ?
                ''', (group_id, limit))
                
                messages = []
                for row in await cursor.fetchall():
                    messages.append({
                        'id': row[0],
                        'sender_id': row[1],
                        'sender_name': row[2],
                        'message': row[3],
                        'group_id': row[4],
                        'platform': row[5],
                        'timestamp': row[6]
                    })
                    
                return messages
                
            except aiosqlite.Error as e:
                logger.error(f"è·å–æœ€è¿‘åŸå§‹æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
                return []
            finally:
                await cursor.close()

    async def get_messages_statistics(self) -> Dict[str, Any]:
        """
        è·å–æ¶ˆæ¯ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                # è·å–åŸå§‹æ¶ˆæ¯ç»Ÿè®¡
                await cursor.execute('SELECT COUNT(*) FROM raw_messages')
                total_messages = (await cursor.fetchone())[0]
                
                await cursor.execute('SELECT COUNT(*) FROM raw_messages WHERE processed = FALSE')
                unprocessed_messages = (await cursor.fetchone())[0]
                
                # è·å–ç­›é€‰æ¶ˆæ¯ç»Ÿè®¡
                await cursor.execute('SELECT COUNT(*) FROM filtered_messages')
                filtered_messages = (await cursor.fetchone())[0]
                
                await cursor.execute('SELECT COUNT(*) FROM filtered_messages WHERE used_for_learning = FALSE')
                unused_filtered_messages = (await cursor.fetchone())[0]
                
                return {
                    'total_messages': total_messages,
                    'unprocessed_messages': unprocessed_messages,
                    'filtered_messages': filtered_messages,
                    'unused_filtered_messages': unused_filtered_messages,
                    'raw_messages': total_messages  # å…¼å®¹æ—§æ¥å£
                }
                
            except aiosqlite.Error as e:
                self._logger.error(f"è·å–æ¶ˆæ¯ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
                return {
                    'total_messages': 0,
                    'unprocessed_messages': 0,
                    'filtered_messages': 0,
                    'unused_filtered_messages': 0,
                    'raw_messages': 0
                }
            finally:
                await cursor.close()

    async def get_pending_style_reviews(self, limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–å¾…å®¡æŸ¥çš„é£æ ¼å­¦ä¹ è®°å½•"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                # ç¡®ä¿è¡¨å­˜åœ¨
                await self._ensure_style_review_table_exists(cursor)
                
                await cursor.execute('''
                    SELECT id, type, group_id, timestamp, learned_patterns, few_shots_content, 
                           status, description, created_at
                    FROM style_learning_reviews
                    WHERE status = 'pending'
                    ORDER BY timestamp DESC
                    LIMIT ?
                ''', (limit,))
                
                reviews = []
                for row in await cursor.fetchall():
                    learned_patterns = []
                    try:
                        if row[4]:  # learned_patterns
                            learned_patterns = json.loads(row[4])
                    except json.JSONDecodeError:
                        pass
                        
                    reviews.append({
                        'id': row[0],
                        'type': row[1],
                        'group_id': row[2],
                        'timestamp': row[3],
                        'learned_patterns': learned_patterns,
                        'few_shots_content': row[5],
                        'status': row[6],
                        'description': row[7],
                        'created_at': row[8]
                    })
                
                return reviews
                
            except Exception as e:
                self._logger.error(f"è·å–å¾…å®¡æŸ¥é£æ ¼å­¦ä¹ è®°å½•å¤±è´¥: {e}")
                return []
            finally:
                await cursor.close()

    async def get_reviewed_style_learning_updates(self, limit: int = 50, offset: int = 0, status_filter: str = None) -> List[Dict[str, Any]]:
        """è·å–å·²å®¡æŸ¥çš„é£æ ¼å­¦ä¹ è®°å½•"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                # ç¡®ä¿è¡¨å­˜åœ¨
                await self._ensure_style_review_table_exists(cursor)
                
                # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                where_clause = "WHERE status != 'pending'"
                params = []
                
                if status_filter:
                    where_clause += " AND status = ?"
                    params.append(status_filter)
                
                params.extend([limit, offset])
                
                await cursor.execute(f'''
                    SELECT id, type, group_id, timestamp, learned_patterns, few_shots_content, 
                           status, description, created_at, updated_at
                    FROM style_learning_reviews
                    {where_clause}
                    ORDER BY updated_at DESC
                    LIMIT ? OFFSET ?
                ''', params)
                
                reviews = []
                for row in await cursor.fetchall():
                    learned_patterns = []
                    try:
                        if row[4]:  # learned_patterns
                            learned_patterns = json.loads(row[4])
                    except json.JSONDecodeError:
                        pass
                        
                    reviews.append({
                        'id': row[0],
                        'type': row[1],
                        'group_id': row[2],
                        'timestamp': row[3],
                        'learned_patterns': learned_patterns,
                        'few_shots_content': row[5],
                        'status': row[6],
                        'description': row[7],
                        'created_at': row[8],
                        'review_time': row[9] if len(row) > 9 else None
                    })
                
                return reviews
                
            except Exception as e:
                self._logger.error(f"è·å–å·²å®¡æŸ¥é£æ ¼å­¦ä¹ è®°å½•å¤±è´¥: {e}")
                return []
            finally:
                await cursor.close()

    async def get_detailed_metrics(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†ç›‘æ§æ•°æ®"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                detailed_data = {
                    'api_metrics': {
                        'hours': list(range(24)),
                        'response_times': [100 + i * 10 for i in range(24)]
                    },
                    'database_metrics': {
                        'table_stats': {}
                    },
                    'system_metrics': {
                        'memory_percent': 45.2,
                        'cpu_percent': 23.1,
                        'disk_percent': 67.8
                    },
                    'connection_pool_stats': {
                        'total_connections': self.connection_pool.total_connections,
                        'active_connections': self.connection_pool.active_connections,
                        'max_connections': self.connection_pool.max_connections,
                        'pool_usage': round(self.connection_pool.active_connections / self.connection_pool.max_connections * 100, 1) if self.connection_pool.max_connections > 0 else 0
                    }
                }
                
                # è·å–æ•°æ®åº“è¡¨ç»Ÿè®¡
                try:
                    tables = ['raw_messages', 'filtered_messages', 'expression_patterns']
                    for table in tables:
                        try:
                            await cursor.execute(f'SELECT COUNT(*) FROM {table}')
                            count = (await cursor.fetchone())[0]
                            detailed_data['database_metrics']['table_stats'][table] = {'count': count}
                        except:
                            detailed_data['database_metrics']['table_stats'][table] = {'count': 0}
                            
                except Exception as e:
                    self._logger.warning(f"è·å–æ•°æ®åº“è¡¨ç»Ÿè®¡å¤±è´¥: {e}")
                
                return detailed_data
                
            except Exception as e:
                self._logger.error(f"è·å–è¯¦ç»†ç›‘æ§æ•°æ®å¤±è´¥: {e}")
                return {
                    'api_metrics': {'hours': [], 'response_times': []},
                    'database_metrics': {'table_stats': {}},
                    'system_metrics': {'memory_percent': 0, 'cpu_percent': 0, 'disk_percent': 0},
                    'connection_pool_stats': {'total_connections': 0, 'active_connections': 0, 'max_connections': 0, 'pool_usage': 0}
                }
            finally:
                await cursor.close()

    async def get_message_statistics(self, group_id: str = None) -> Dict[str, Any]:
        """è·å–æ¶ˆæ¯ç»Ÿè®¡ä¿¡æ¯ï¼Œå…¼å®¹ webui.py çš„è°ƒç”¨"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                if group_id:
                    # è·å–ç‰¹å®šç¾¤ç»„çš„ç»Ÿè®¡
                    await cursor.execute('SELECT COUNT(*) FROM raw_messages WHERE group_id = ?', (group_id,))
                    total_messages = (await cursor.fetchone())[0]
                    
                    await cursor.execute('SELECT COUNT(*) FROM raw_messages WHERE group_id = ? AND processed = FALSE', (group_id,))
                    unprocessed_messages = (await cursor.fetchone())[0]
                    
                    await cursor.execute('SELECT COUNT(*) FROM filtered_messages WHERE group_id = ?', (group_id,))
                    filtered_messages = (await cursor.fetchone())[0]
                    
                    await cursor.execute('SELECT COUNT(*) FROM filtered_messages WHERE group_id = ? AND used_for_learning = FALSE', (group_id,))
                    unused_filtered_messages = (await cursor.fetchone())[0]
                else:
                    # è·å–å…¨å±€ç»Ÿè®¡
                    return await self.get_messages_statistics()
                
                return {
                    'total_messages': total_messages,
                    'unprocessed_messages': unprocessed_messages,
                    'filtered_messages': filtered_messages,
                    'unused_filtered_messages': unused_filtered_messages,
                    'raw_messages': total_messages,
                    'group_id': group_id
                }
                
            except aiosqlite.Error as e:
                self._logger.error(f"è·å–æ¶ˆæ¯ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
                return {
                    'total_messages': 0,
                    'unprocessed_messages': 0,
                    'filtered_messages': 0,
                    'unused_filtered_messages': 0,
                    'raw_messages': 0,
                    'group_id': group_id
                }
            finally:
                await cursor.close()

    async def get_recent_learning_batches(self, limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„å­¦ä¹ æ‰¹æ¬¡è®°å½•"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                # ç¡®ä¿è¡¨å­˜åœ¨
                await cursor.execute('''
                    CREATE TABLE IF NOT EXISTS learning_batches (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        group_id TEXT NOT NULL,
                        batch_name TEXT NOT NULL,
                        start_time REAL NOT NULL,
                        end_time REAL,
                        quality_score REAL,
                        processed_messages INTEGER DEFAULT 0,
                        message_count INTEGER DEFAULT 0,
                        filtered_count INTEGER DEFAULT 0,
                        success BOOLEAN DEFAULT FALSE,
                        error_message TEXT
                    )
                ''')
                
                await cursor.execute('''
                    SELECT group_id, batch_name, start_time, end_time, quality_score,
                           processed_messages, message_count, filtered_count, success, error_message
                    FROM learning_batches 
                    ORDER BY start_time DESC 
                    LIMIT ?
                ''', (limit,))
                
                batches = []
                for row in await cursor.fetchall():
                    batches.append({
                        'group_id': row[0],
                        'batch_name': row[1],
                        'start_time': row[2],
                        'end_time': row[3],
                        'quality_score': row[4] or 0,
                        'processed_messages': row[5] or 0,
                        'message_count': row[6] or 0,
                        'filtered_count': row[7] or 0,
                        'success': bool(row[8]),
                        'error_message': row[9]
                    })
                
                return batches
                
            except Exception as e:
                self._logger.error(f"è·å–æœ€è¿‘å­¦ä¹ æ‰¹æ¬¡å¤±è´¥: {e}")
                return []
            finally:
                await cursor.close()

    async def get_style_progress_data(self) -> List[Dict[str, Any]]:
        """è·å–é£æ ¼è¿›åº¦æ•°æ®"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                # ä»å­¦ä¹ æ‰¹æ¬¡ä¸­è·å–è¿›åº¦æ•°æ®
                await cursor.execute('''
                    SELECT group_id, start_time, quality_score, success
                    FROM learning_batches 
                    WHERE quality_score IS NOT NULL
                    ORDER BY start_time DESC 
                    LIMIT 30
                ''')
                
                progress_data = []
                for row in await cursor.fetchall():
                    progress_data.append({
                        'group_id': row[0],
                        'timestamp': row[1],
                        'quality_score': row[2],
                        'success': bool(row[3])
                    })
                
                return progress_data
                
            except Exception as e:
                self._logger.warning(f"ä»learning_batchesè¡¨è·å–è¿›åº¦æ•°æ®å¤±è´¥: {e}")
                return []
            finally:
                await cursor.close()

    async def get_style_learning_statistics(self) -> Dict[str, Any]:
        """è·å–é£æ ¼å­¦ä¹ ç»Ÿè®¡æ•°æ®"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                stats = {
                    'unique_styles': 0,
                    'avg_confidence': 0,
                    'total_samples': 0,
                    'latest_update': None
                }
                
                # ä»è¡¨è¾¾æ¨¡å¼è¡¨è·å–ç»Ÿè®¡
                try:
                    await cursor.execute('SELECT COUNT(*) FROM expression_patterns')
                    stats['total_samples'] = (await cursor.fetchone())[0] or 0
                    
                    await cursor.execute('SELECT AVG(weight), MAX(created_time) FROM expression_patterns')
                    row = await cursor.fetchone()
                    if row[0]:
                        stats['avg_confidence'] = round((row[0] or 0) * 100, 1)
                    
                    if row[1]:
                        stats['latest_update'] = datetime.fromtimestamp(row[1]).strftime('%Y-%m-%d %H:%M')
                    
                    # è®¡ç®—ç‹¬ç‰¹é£æ ¼æ•°é‡ï¼ˆåŸºäºç¾¤ç»„ï¼‰
                    await cursor.execute('SELECT COUNT(DISTINCT group_id) FROM expression_patterns')
                    stats['unique_styles'] = (await cursor.fetchone())[0] or 0
                    
                except Exception as e:
                    self._logger.warning(f"ä»expression_patternsè¡¨è·å–ç»Ÿè®¡å¤±è´¥: {e}")
                
                return stats
                
            except Exception as e:
                self._logger.error(f"è·å–é£æ ¼å­¦ä¹ ç»Ÿè®¡å¤±è´¥: {e}")
                return {
                    'unique_styles': 0,
                    'avg_confidence': 0,
                    'total_samples': 0,
                    'latest_update': None
                }
            finally:
                await cursor.close()

    async def get_group_messages_statistics(self, group_id: str) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šç¾¤ç»„çš„æ¶ˆæ¯ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            group_id: ç¾¤ç»„ID
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                # è·å–åŸå§‹æ¶ˆæ¯ç»Ÿè®¡
                await cursor.execute('SELECT COUNT(*) FROM raw_messages WHERE group_id = ?', (group_id,))
                total_messages = (await cursor.fetchone())[0]
                
                await cursor.execute('SELECT COUNT(*) FROM raw_messages WHERE group_id = ? AND processed = FALSE', (group_id,))
                unprocessed_messages = (await cursor.fetchone())[0]
                
                # è·å–ç­›é€‰æ¶ˆæ¯ç»Ÿè®¡
                await cursor.execute('SELECT COUNT(*) FROM filtered_messages WHERE group_id = ?', (group_id,))
                filtered_messages = (await cursor.fetchone())[0]
                
                await cursor.execute('SELECT COUNT(*) FROM filtered_messages WHERE group_id = ? AND used_for_learning = FALSE', (group_id,))
                unused_filtered_messages = (await cursor.fetchone())[0]
                
                return {
                    'total_messages': total_messages,
                    'unprocessed_messages': unprocessed_messages,
                    'filtered_messages': filtered_messages,
                    'unused_filtered_messages': unused_filtered_messages,
                    'raw_messages': total_messages  # å…¼å®¹æ—§æ¥å£
                }
                
            except aiosqlite.Error as e:
                logger.error(f"è·å–ç¾¤ç»„æ¶ˆæ¯ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
                return {
                    'total_messages': 0,
                    'unprocessed_messages': 0,
                    'filtered_messages': 0,
                    'unused_filtered_messages': 0,
                    'raw_messages': 0
                }
            finally:
                await cursor.close()

    async def load_social_graph(self, group_id: str) -> List[Dict[str, Any]]:
        """åŠ è½½å®Œæ•´ç¤¾äº¤å›¾è°±"""
        self._logger.debug(f"[æ•°æ®åº“] å¼€å§‹åŠ è½½ç¾¤ç»„ {group_id} çš„ç¤¾äº¤å›¾è°±")
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()

        try:
            await cursor.execute('''
                SELECT from_user, to_user, relation_type, strength, frequency, last_interaction
                FROM social_relations ORDER BY strength DESC
            ''')

            relations = []
            for row in await cursor.fetchall():
                relations.append({
                    'from_user': row[0],
                    'to_user': row[1],
                    'relation_type': row[2],
                    'strength': row[3],
                    'frequency': row[4],
                    'last_interaction': row[5]
                })

            self._logger.info(f"[æ•°æ®åº“] æˆåŠŸåŠ è½½ç¾¤ç»„ {group_id} çš„ç¤¾äº¤å›¾è°±: {len(relations)} æ¡å…³ç³»è®°å½•")
            if len(relations) == 0:
                self._logger.warning(f"[æ•°æ®åº“] è­¦å‘Š: ç¾¤ç»„ {group_id} çš„social_relationsè¡¨ä¸­æ²¡æœ‰æ•°æ®!")
            else:
                # è¾“å‡ºå‰3æ¡ç¤ºä¾‹
                self._logger.debug(f"[æ•°æ®åº“] ç¤¾äº¤å…³ç³»ç¤ºä¾‹: {relations[:3]}")

            return relations

        except aiosqlite.Error as e:
            self._logger.error(f"[æ•°æ®åº“] åŠ è½½ç¤¾äº¤å›¾è°±å¤±è´¥ (ç¾¤ç»„: {group_id}): {e}", exc_info=True)
            return []

    async def get_messages_for_replay(self, group_id: str, days: int, limit: int) -> List[Dict[str, Any]]:
        """
        ä»å…¨å±€æ¶ˆæ¯æ•°æ®åº“è·å–æŒ‡å®šç¾¤ç»„åœ¨è¿‡å»ä¸€æ®µæ—¶é—´å†…çš„åŸå§‹æ¶ˆæ¯ï¼Œç”¨äºè®°å¿†é‡æ”¾ã€‚
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                start_timestamp = time.time() - (days * 86400) # è½¬æ¢ä¸ºç§’
                
                await cursor.execute('''
                    SELECT id, sender_id, sender_name, message, group_id, platform, timestamp
                    FROM raw_messages 
                    WHERE group_id = ? AND timestamp > ?
                    ORDER BY timestamp DESC 
                    LIMIT ?
                ''', (group_id, start_timestamp, limit))
                
                messages = []
                for row in await cursor.fetchall():
                    messages.append({
                        'id': row[0],
                        'sender_id': row[1],
                        'sender_name': row[2],
                        'message': row[3],
                        'group_id': row[4],
                        'platform': row[5],
                        'timestamp': row[6]
                    })
                
                return messages
                
            except aiosqlite.Error as e:
                self._logger.error(f"è·å–è®°å¿†é‡æ”¾æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
                return []
            finally:
                await cursor.close()

    async def backup_persona(self, group_id: str, backup_data: Dict[str, Any]) -> int:
        """å¤‡ä»½äººæ ¼æ•°æ®"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            # è·å–å½“å‰æ—¶é—´æˆ³
            current_timestamp = time.time()
            
            await cursor.execute(''' 
                INSERT INTO persona_backups (backup_name, timestamp, original_persona, imitation_dialogues, backup_reason)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                backup_data['backup_name'],
                current_timestamp,
                json.dumps(backup_data['original_persona'], ensure_ascii=False),
                json.dumps(backup_data.get('imitation_dialogues', []), ensure_ascii=False),
                backup_data.get('backup_reason', 'Auto backup before update')
            ))
            
            backup_id = cursor.lastrowid
            await conn.commit()
            
            logger.info(f"äººæ ¼æ•°æ®å·²å¤‡ä»½ï¼Œå¤‡ä»½ID: {backup_id}")
            return backup_id
            
        except aiosqlite.Error as e:
            logger.error(f"å¤‡ä»½äººæ ¼æ•°æ®å¤±è´¥: {e}", exc_info=True)
            raise DataStorageError(f"å¤‡ä»½äººæ ¼æ•°æ®å¤±è´¥: {str(e)}")

    async def get_persona_backups(self, group_id: str, limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„äººæ ¼å¤‡ä»½"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT id, backup_name, created_at FROM persona_backups 
                ORDER BY created_at DESC LIMIT ?
            ''', (limit,))
            
            backups = []
            for row in await cursor.fetchall():
                backups.append({
                    'id': row[0],
                    'backup_name': row[1],
                    'created_at': row[2]
                })
            
            return backups
            
        except aiosqlite.Error as e:
            logger.error(f"è·å–äººæ ¼å¤‡ä»½å¤±è´¥: {e}", exc_info=True)
            return []

    async def restore_persona(self, group_id: str, backup_id: int) -> Optional[Dict[str, Any]]:
        """ä»å¤‡ä»½æ¢å¤äººæ ¼æ•°æ®"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT backup_name, original_persona, imitation_dialogues, backup_reason 
                FROM persona_backups WHERE id = ?
            ''', (backup_id,))
            
            row = await cursor.fetchone()
            if not row:
                return None
            
            return {
                'backup_name': row[0],
                'original_persona': json.loads(row[1]),
                'imitation_dialogues': json.loads(row[2]),
                'backup_reason': row[3]
            }
            
        except aiosqlite.Error as e:
            logger.error(f"æ¢å¤äººæ ¼æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return None

    async def save_persona_update_record(self, record: Dict[str, Any]) -> int:
        """ä¿å­˜äººæ ¼æ›´æ–°è®°å½•åˆ°æ•°æ®åº“"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                await cursor.execute('''
                    INSERT INTO persona_update_records (timestamp, group_id, update_type, original_content, new_content, reason, status)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    record.get('timestamp', time.time()),
                    record.get('group_id'),
                    record.get('update_type'),
                    record.get('original_content'),
                    record.get('new_content'),
                    record.get('reason'),
                    record.get('status', 'pending')
                ))
                
                record_id = cursor.lastrowid
                await conn.commit()
                logger.debug(f"äººæ ¼æ›´æ–°è®°å½•å·²ä¿å­˜ï¼ŒID: {record_id}")
                return record_id
                
            except aiosqlite.Error as e:
                logger.error(f"ä¿å­˜äººæ ¼æ›´æ–°è®°å½•å¤±è´¥: {e}", exc_info=True)
                raise DataStorageError(f"ä¿å­˜äººæ ¼æ›´æ–°è®°å½•å¤±è´¥: {str(e)}")
            finally:
                await cursor.close()

    async def get_pending_persona_update_records(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å¾…å®¡æŸ¥çš„äººæ ¼æ›´æ–°è®°å½•"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                # é¦–å…ˆæ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ä»¥åŠåŒ…å«ä»€ä¹ˆæ•°æ®
                await cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='persona_update_records'")
                if not await cursor.fetchone():
                    self._logger.info("persona_update_records è¡¨ä¸å­˜åœ¨")
                    return []
                
                # æ£€æŸ¥è¡¨ä¸­æ€»å…±æœ‰å¤šå°‘è®°å½•
                await cursor.execute('SELECT COUNT(*) FROM persona_update_records')
                total_count = (await cursor.fetchone())[0]
                self._logger.info(f"persona_update_records è¡¨ä¸­æ€»å…±æœ‰ {total_count} æ¡è®°å½•")
                
                # æ£€æŸ¥å„ç§çŠ¶æ€çš„è®°å½•æ•°é‡
                await cursor.execute('SELECT status, COUNT(*) FROM persona_update_records GROUP BY status')
                status_counts = await cursor.fetchall()
                self._logger.info(f"å„çŠ¶æ€è®°å½•æ•°é‡: {dict(status_counts)}")
                
                # ä¼˜å…ˆæŸ¥è¯¢pendingçŠ¶æ€çš„è®°å½•
                await cursor.execute('''
                    SELECT id, timestamp, group_id, update_type, original_content, new_content, reason, status, reviewer_comment, review_time
                    FROM persona_update_records
                    WHERE status = 'pending'
                    ORDER BY timestamp DESC
                ''')
                
                records = []
                pending_rows = await cursor.fetchall()
                self._logger.info(f"æ‰¾åˆ° {len(pending_rows)} æ¡pendingçŠ¶æ€çš„è®°å½•")
                
                for row in pending_rows:
                    records.append({
                        'id': row[0],
                        'timestamp': row[1],
                        'group_id': row[2],
                        'update_type': row[3],
                        'original_content': row[4],
                        'new_content': row[5],
                        'reason': row[6],
                        'status': row[7],
                        'reviewer_comment': row[8],
                        'review_time': row[9]
                    })
                
                # å¦‚æœæ²¡æœ‰pendingçŠ¶æ€çš„è®°å½•ï¼Œå°è¯•æŸ¥è¯¢æ‰€æœ‰è®°å½•ï¼ˆå¯èƒ½statuså­—æ®µä¸ºç©ºæˆ–å…¶ä»–å€¼ï¼‰
                if not records and total_count > 0:
                    self._logger.info("æ²¡æœ‰pendingçŠ¶æ€è®°å½•ï¼ŒæŸ¥è¯¢æ‰€æœ‰è®°å½•...")
                    await cursor.execute('''
                        SELECT id, timestamp, group_id, update_type, original_content, new_content, reason, 
                               COALESCE(status, 'pending') as status, reviewer_comment, review_time
                        FROM persona_update_records
                        WHERE status IS NULL OR status = '' OR status = 'pending'
                        ORDER BY timestamp DESC
                        LIMIT 50
                    ''')
                    
                    all_rows = await cursor.fetchall()
                    self._logger.info(f"æ‰¾åˆ° {len(all_rows)} æ¡å¯èƒ½çš„å¾…å®¡æŸ¥è®°å½•")
                    
                    for row in all_rows:
                        records.append({
                            'id': row[0],
                            'timestamp': row[1],
                            'group_id': row[2],
                            'update_type': row[3],
                            'original_content': row[4],
                            'new_content': row[5],
                            'reason': row[6],
                            'status': 'pending',  # å¼ºåˆ¶è®¾ç½®ä¸ºpending
                            'reviewer_comment': row[8],
                            'review_time': row[9]
                        })
                
                return records
                
            except aiosqlite.Error as e:
                logger.error(f"è·å–å¾…å®¡æŸ¥äººæ ¼æ›´æ–°è®°å½•å¤±è´¥: {e}", exc_info=True)
                return []
            finally:
                await cursor.close()

    async def update_persona_update_record_status(self, record_id: int, status: str, reviewer_comment: Optional[str] = None) -> bool:
        """æ›´æ–°äººæ ¼æ›´æ–°è®°å½•çš„çŠ¶æ€"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                review_time = time.time()
                await cursor.execute('''
                    UPDATE persona_update_records
                    SET status = ?, reviewer_comment = ?, review_time = ?
                    WHERE id = ?
                ''', (status, reviewer_comment, review_time, record_id))
                
                await conn.commit()
                logger.debug(f"äººæ ¼æ›´æ–°è®°å½• {record_id} çŠ¶æ€å·²æ›´æ–°ä¸º {status}")
                return cursor.rowcount > 0
                
            except aiosqlite.Error as e:
                logger.error(f"æ›´æ–°äººæ ¼æ›´æ–°è®°å½•çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
                raise DataStorageError(f"æ›´æ–°äººæ ¼æ›´æ–°è®°å½•çŠ¶æ€å¤±è´¥: {str(e)}")
            finally:
                await cursor.close()

    async def delete_persona_update_record(self, record_id: int) -> bool:
        """åˆ é™¤äººæ ¼æ›´æ–°è®°å½•"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                await cursor.execute('''
                    DELETE FROM persona_update_records
                    WHERE id = ?
                ''', (record_id,))
                
                await conn.commit()
                logger.debug(f"äººæ ¼æ›´æ–°è®°å½• {record_id} å·²åˆ é™¤")
                return cursor.rowcount > 0
                
            except aiosqlite.Error as e:
                logger.error(f"åˆ é™¤äººæ ¼æ›´æ–°è®°å½•å¤±è´¥: {e}", exc_info=True)
                raise DataStorageError(f"åˆ é™¤äººæ ¼æ›´æ–°è®°å½•å¤±è´¥: {str(e)}")
            finally:
                await cursor.close()

    async def get_persona_update_record_by_id(self, record_id: int) -> Optional[Dict[str, Any]]:
        """æ ¹æ®IDè·å–äººæ ¼æ›´æ–°è®°å½•"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()

            try:
                await cursor.execute('''
                    SELECT id, timestamp, group_id, update_type, original_content, new_content, reason, status, reviewer_comment, review_time
                    FROM persona_update_records
                    WHERE id = ?
                ''', (record_id,))

                row = await cursor.fetchone()
                if row:
                    return {
                        'id': row[0],
                        'timestamp': row[1],
                        'group_id': row[2],
                        'update_type': row[3],
                        'original_content': row[4],
                        'new_content': row[5],
                        'reason': row[6],
                        'status': row[7],
                        'reviewer_comment': row[8],
                        'review_time': row[9]
                    }
                return None

            except aiosqlite.Error as e:
                logger.error(f"è·å–äººæ ¼æ›´æ–°è®°å½•å¤±è´¥: {e}", exc_info=True)
                return None
            finally:
                await cursor.close()

    # ========== é«˜çº§åŠŸèƒ½æ•°æ®åº“æ“ä½œæ–¹æ³• ==========

    async def save_emotion_profile(self, group_id: str, user_id: str, profile_data: Dict[str, Any]) -> bool:
        """ä¿å­˜æƒ…æ„Ÿæ¡£æ¡ˆ"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS emotion_profiles (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id TEXT NOT NULL,
                    group_id TEXT NOT NULL,
                    dominant_emotions TEXT, -- JSONæ ¼å¼
                    emotion_patterns TEXT, -- JSONæ ¼å¼
                    empathy_level REAL DEFAULT 0.5,
                    emotional_stability REAL DEFAULT 0.5,
                    last_updated REAL NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(user_id, group_id)
                )
            ''')
            
            await cursor.execute('''
                INSERT OR REPLACE INTO emotion_profiles 
                (user_id, group_id, dominant_emotions, emotion_patterns, empathy_level, emotional_stability, last_updated)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                user_id,
                group_id,
                json.dumps(profile_data.get('dominant_emotions', {}), ensure_ascii=False),
                json.dumps(profile_data.get('emotion_patterns', {}), ensure_ascii=False),
                profile_data.get('empathy_level', 0.5),
                profile_data.get('emotional_stability', 0.5),
                profile_data.get('last_updated', time.time())
            ))
            
            await conn.commit()
            return True
            
        except Exception as e:
            self._logger.error(f"ä¿å­˜æƒ…æ„Ÿæ¡£æ¡ˆå¤±è´¥: {e}")
            return False

    async def load_emotion_profile(self, group_id: str, user_id: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½æƒ…æ„Ÿæ¡£æ¡ˆ"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT dominant_emotions, emotion_patterns, empathy_level, emotional_stability, last_updated
                FROM emotion_profiles WHERE user_id = ? AND group_id = ?
            ''', (user_id, group_id))
            
            row = await cursor.fetchone()
            if not row:
                return None
                
            return {
                'user_id': user_id,
                'group_id': group_id,
                'dominant_emotions': json.loads(row[0]) if row[0] else {},
                'emotion_patterns': json.loads(row[1]) if row[1] else {},
                'empathy_level': row[2],
                'emotional_stability': row[3],
                'last_updated': row[4]
            }
            
        except Exception as e:
            self._logger.error(f"åŠ è½½æƒ…æ„Ÿæ¡£æ¡ˆå¤±è´¥: {e}")
            return None

    async def save_knowledge_entity(self, group_id: str, entity_data: Dict[str, Any]) -> bool:
        """ä¿å­˜çŸ¥è¯†å®ä½“"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS knowledge_entities (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    entity_id TEXT UNIQUE NOT NULL,
                    name TEXT NOT NULL,
                    entity_type TEXT NOT NULL,
                    attributes TEXT, -- JSONæ ¼å¼
                    relationships TEXT, -- JSONæ ¼å¼
                    confidence REAL DEFAULT 0.5,
                    source_messages TEXT, -- JSONæ ¼å¼
                    last_mentioned REAL NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            await cursor.execute('''
                INSERT OR REPLACE INTO knowledge_entities 
                (entity_id, name, entity_type, attributes, relationships, confidence, source_messages, last_mentioned)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                entity_data.get('entity_id'),
                entity_data.get('name', ''),
                entity_data.get('entity_type', 'unknown'),
                json.dumps(entity_data.get('attributes', {}), ensure_ascii=False),
                json.dumps(entity_data.get('relationships', []), ensure_ascii=False),
                entity_data.get('confidence', 0.5),
                json.dumps(entity_data.get('source_messages', []), ensure_ascii=False),
                entity_data.get('last_mentioned', time.time())
            ))
            
            await conn.commit()
            return True
            
        except Exception as e:
            self._logger.error(f"ä¿å­˜çŸ¥è¯†å®ä½“å¤±è´¥: {e}")
            return False

    async def get_knowledge_entities(self, group_id: str, limit: int = 100) -> List[Dict[str, Any]]:
        """è·å–çŸ¥è¯†å®ä½“åˆ—è¡¨"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT entity_id, name, entity_type, attributes, relationships, confidence, source_messages, last_mentioned
                FROM knowledge_entities 
                ORDER BY last_mentioned DESC
                LIMIT ?
            ''', (limit,))
            
            entities = []
            for row in await cursor.fetchall():
                entities.append({
                    'entity_id': row[0],
                    'name': row[1],
                    'entity_type': row[2],
                    'attributes': json.loads(row[3]) if row[3] else {},
                    'relationships': json.loads(row[4]) if row[4] else [],
                    'confidence': row[5],
                    'source_messages': json.loads(row[6]) if row[6] else [],
                    'last_mentioned': row[7]
                })
            
            return entities
            
        except Exception as e:
            self._logger.error(f"è·å–çŸ¥è¯†å®ä½“å¤±è´¥: {e}")
            return []

    # æ–°å¢å¼ºåŒ–å­¦ä¹ ç›¸å…³æ–¹æ³•
    async def save_reinforcement_learning_result(self, group_id: str, result_data: Dict[str, Any]) -> bool:
        """ä¿å­˜å¼ºåŒ–å­¦ä¹ ç»“æœ"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                await cursor.execute('''
                    INSERT INTO reinforcement_learning_results 
                    (group_id, timestamp, replay_analysis, optimization_strategy, reinforcement_feedback, next_action)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    group_id,
                    result_data.get('timestamp', time.time()),
                    json.dumps(result_data.get('replay_analysis', {}), ensure_ascii=False),
                    json.dumps(result_data.get('optimization_strategy', {}), ensure_ascii=False),
                    json.dumps(result_data.get('reinforcement_feedback', {}), ensure_ascii=False),
                    result_data.get('next_action', '')
                ))
                
                await conn.commit()
                return True
                
            except Exception as e:
                logger.error(f"ä¿å­˜å¼ºåŒ–å­¦ä¹ ç»“æœå¤±è´¥: {e}")
                return False
            finally:
                await cursor.close()

    async def get_learning_history_for_reinforcement(self, group_id: str, limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–ç”¨äºå¼ºåŒ–å­¦ä¹ çš„å†å²æ•°æ®"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT timestamp, quality_score, success, successful_pattern, failed_pattern
                FROM learning_performance_history 
                WHERE group_id = ?
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (group_id, limit))
            
            history = []
            for row in await cursor.fetchall():
                history.append({
                    'timestamp': row[0],
                    'quality_score': row[1],
                    'success': bool(row[2]),
                    'successful_pattern': row[3] or '',
                    'failed_pattern': row[4] or ''
                })
            
            return history
            
        except Exception as e:
            logger.error(f"è·å–å¼ºåŒ–å­¦ä¹ å†å²æ•°æ®å¤±è´¥: {e}")
            return []
        finally:
            await cursor.close()

    async def save_persona_fusion_result(self, group_id: str, fusion_data: Dict[str, Any]) -> bool:
        """ä¿å­˜äººæ ¼èåˆç»“æœ"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                INSERT INTO persona_fusion_history 
                (group_id, timestamp, base_persona_hash, incremental_hash, fusion_result, compatibility_score)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                group_id,
                fusion_data.get('timestamp', time.time()),
                fusion_data.get('base_persona_hash'),
                fusion_data.get('incremental_hash'),
                json.dumps(fusion_data.get('fusion_result', {}), ensure_ascii=False),
                fusion_data.get('compatibility_score', 0.0)
            ))
            
            await conn.commit()
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜äººæ ¼èåˆç»“æœå¤±è´¥: {e}")
            return False
        finally:
            await cursor.close()

    async def get_persona_fusion_history(self, group_id: str, limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–äººæ ¼èåˆå†å²"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT timestamp, base_persona_hash, incremental_hash, fusion_result, compatibility_score
                FROM persona_fusion_history 
                WHERE group_id = ?
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (group_id, limit))
            
            history = []
            for row in await cursor.fetchall():
                fusion_result = {}
                try:
                    fusion_result = json.loads(row[3]) if row[3] else {}
                except json.JSONDecodeError:
                    logger.warning(f"è§£æèåˆç»“æœJSONå¤±è´¥: {row[3]}")
                
                history.append({
                    'timestamp': row[0],
                    'base_persona_hash': row[1],
                    'incremental_hash': row[2],
                    'fusion_result': fusion_result,
                    'compatibility_score': row[4]
                })
            
            return history
            
        except Exception as e:
            logger.error(f"è·å–äººæ ¼èåˆå†å²å¤±è´¥: {e}")
            return []
        finally:
            await cursor.close()

    async def save_strategy_optimization_result(self, group_id: str, optimization_data: Dict[str, Any]) -> bool:
        """ä¿å­˜ç­–ç•¥ä¼˜åŒ–ç»“æœ"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                INSERT INTO strategy_optimization_results 
                (group_id, timestamp, original_strategy, optimization_result, expected_improvement)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                group_id,
                optimization_data.get('timestamp', time.time()),
                json.dumps(optimization_data.get('original_strategy', {}), ensure_ascii=False),
                json.dumps(optimization_data.get('optimization_result', {}), ensure_ascii=False),
                json.dumps(optimization_data.get('expected_improvement', {}), ensure_ascii=False)
            ))
            
            await conn.commit()
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç­–ç•¥ä¼˜åŒ–ç»“æœå¤±è´¥: {e}")
            return False
        finally:
            await cursor.close()

    async def get_learning_performance_history(self, group_id: str, limit: int = 30) -> List[Dict[str, Any]]:
        """è·å–å­¦ä¹ æ€§èƒ½å†å²æ•°æ®"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT session_id, timestamp, quality_score, learning_time, success
                FROM learning_performance_history 
                WHERE group_id = ?
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (group_id, limit))
            
            history = []
            for row in await cursor.fetchall():
                history.append({
                    'session_id': row[0],
                    'timestamp': row[1],
                    'quality_score': row[2] or 0.0,
                    'learning_time': row[3] or 0.0,
                    'success': bool(row[4])
                })
            
            return history
            
        except Exception as e:
            logger.error(f"è·å–å­¦ä¹ æ€§èƒ½å†å²å¤±è´¥: {e}")
            return []
        finally:
            await cursor.close()

    async def save_learning_performance_record(self, group_id: str, performance_data: Dict[str, Any]) -> bool:
        """ä¿å­˜å­¦ä¹ æ€§èƒ½è®°å½•"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                INSERT INTO learning_performance_history 
                (group_id, session_id, timestamp, quality_score, learning_time, success, successful_pattern, failed_pattern)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                group_id,
                performance_data.get('session_id', ''),
                performance_data.get('timestamp', time.time()),
                performance_data.get('quality_score', 0.0),
                performance_data.get('learning_time', 0.0),
                performance_data.get('success', False),
                performance_data.get('successful_pattern', ''),
                performance_data.get('failed_pattern', '')
            ))
            
            await conn.commit()
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜å­¦ä¹ æ€§èƒ½è®°å½•å¤±è´¥: {e}")
            return False
        finally:
            await cursor.close()

    async def get_messages_for_replay(self, group_id: str, days: int = 30, limit: int = 100) -> List[Dict[str, Any]]:
        """è·å–ç”¨äºè®°å¿†é‡æ”¾çš„æ¶ˆæ¯"""
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()
            
            try:
                # è·å–æŒ‡å®šå¤©æ•°å†…çš„æ¶ˆæ¯
                cutoff_time = time.time() - (days * 24 * 3600)
                
                await cursor.execute('''
                    SELECT id, message, sender_id, group_id, timestamp
                    FROM raw_messages 
                    WHERE group_id = ? AND timestamp > ? AND processed = TRUE
                    ORDER BY timestamp DESC
                    LIMIT ?
                ''', (group_id, cutoff_time, limit))
                
                messages = []
                for row in await cursor.fetchall():
                    messages.append({
                        'message_id': row[0],
                        'message': row[1],
                        'sender_id': row[2],
                        'group_id': row[3],
                        'timestamp': row[4]
                    })
                
                return messages
                
            except Exception as e:
                logger.error(f"è·å–è®°å¿†é‡æ”¾æ¶ˆæ¯å¤±è´¥: {e}")
                return []
            finally:
                await cursor.close()

    async def save_user_preferences(self, group_id: str, user_id: str, preferences: Dict[str, Any]) -> bool:
        """ä¿å­˜ç”¨æˆ·åå¥½è®¾ç½®"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS user_preferences (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id TEXT NOT NULL,
                    group_id TEXT NOT NULL,
                    favorite_topics TEXT, -- JSONæ ¼å¼
                    interaction_style TEXT, -- JSONæ ¼å¼
                    learning_preferences TEXT, -- JSONæ ¼å¼
                    adaptive_rate REAL DEFAULT 0.5,
                    updated_at REAL NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(user_id, group_id)
                )
            ''')
            
            await cursor.execute('''
                INSERT OR REPLACE INTO user_preferences 
                (user_id, group_id, favorite_topics, interaction_style, learning_preferences, adaptive_rate, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                user_id,
                group_id,
                json.dumps(preferences.get('favorite_topics', []), ensure_ascii=False),
                json.dumps(preferences.get('interaction_style', {}), ensure_ascii=False),
                json.dumps(preferences.get('learning_preferences', {}), ensure_ascii=False),
                preferences.get('adaptive_rate', 0.5),
                time.time()
            ))
            
            await conn.commit()
            return True
            
        except Exception as e:
            self._logger.error(f"ä¿å­˜ç”¨æˆ·åå¥½å¤±è´¥: {e}")
            return False

    async def load_user_preferences(self, group_id: str, user_id: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½ç”¨æˆ·åå¥½è®¾ç½®"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT favorite_topics, interaction_style, learning_preferences, adaptive_rate, updated_at
                FROM user_preferences WHERE user_id = ? AND group_id = ?
            ''', (user_id, group_id))
            
            row = await cursor.fetchone()
            if not row:
                return None
                
            return {
                'favorite_topics': json.loads(row[0]) if row[0] else [],
                'interaction_style': json.loads(row[1]) if row[1] else {},
                'learning_preferences': json.loads(row[2]) if row[2] else {},
                'adaptive_rate': row[3],
                'updated_at': row[4]
            }
            
        except Exception as e:
            self._logger.error(f"åŠ è½½ç”¨æˆ·åå¥½å¤±è´¥: {e}")
            return None

    async def save_conversation_context(self, group_id: str, context_data: Dict[str, Any]) -> bool:
        """ä¿å­˜å¯¹è¯ä¸Šä¸‹æ–‡"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS conversation_contexts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    group_id TEXT NOT NULL,
                    context_id TEXT UNIQUE NOT NULL,
                    participants TEXT, -- JSONæ ¼å¼å­˜å‚¨å‚ä¸è€…åˆ—è¡¨
                    current_topic TEXT,
                    emotion_state TEXT, -- JSONæ ¼å¼å­˜å‚¨æƒ…æ„ŸçŠ¶æ€
                    context_messages TEXT, -- JSONæ ¼å¼å­˜å‚¨ä¸Šä¸‹æ–‡æ¶ˆæ¯
                    start_time REAL NOT NULL,
                    last_updated REAL NOT NULL,
                    is_active BOOLEAN DEFAULT TRUE,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            await cursor.execute('''
                INSERT OR REPLACE INTO conversation_contexts 
                (group_id, context_id, participants, current_topic, emotion_state, context_messages, start_time, last_updated, is_active)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                group_id,
                context_data.get('context_id'),
                json.dumps(list(context_data.get('participants', set())), ensure_ascii=False),
                context_data.get('current_topic'),
                json.dumps(context_data.get('emotion_state', {}), ensure_ascii=False),
                json.dumps(context_data.get('messages', []), ensure_ascii=False),
                context_data.get('start_time', time.time()),
                time.time(),
                context_data.get('is_active', True)
            ))
            
            await conn.commit()
            return True
            
        except Exception as e:
            self._logger.error(f"ä¿å­˜å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return False

    async def get_active_conversation_contexts(self, group_id: str) -> List[Dict[str, Any]]:
        """è·å–æ´»è·ƒçš„å¯¹è¯ä¸Šä¸‹æ–‡"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT context_id, participants, current_topic, emotion_state, context_messages, start_time, last_updated
                FROM conversation_contexts 
                WHERE group_id = ? AND is_active = TRUE
                ORDER BY last_updated DESC
            ''', (group_id,))
            
            contexts = []
            for row in await cursor.fetchall():
                contexts.append({
                    'context_id': row[0],
                    'participants': set(json.loads(row[1])) if row[1] else set(),
                    'current_topic': row[2],
                    'emotion_state': json.loads(row[3]) if row[3] else {},
                    'messages': json.loads(row[4]) if row[4] else [],
                    'start_time': row[5],
                    'last_updated': row[6]
                })
            
            return contexts
            
        except Exception as e:
            self._logger.error(f"è·å–å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return []

    async def save_learning_session_record(self, group_id: str, session_data: Dict[str, Any]) -> bool:
        """ä¿å­˜å­¦ä¹ ä¼šè¯è®°å½•"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                INSERT OR REPLACE INTO learning_sessions
                (session_id, start_time, end_time, messages_processed, filtered_messages, 
                 style_updates, quality_score, success)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                session_data.get('session_id'),
                session_data.get('start_time'),
                session_data.get('end_time'),
                session_data.get('messages_processed', 0),
                session_data.get('filtered_messages', 0),
                session_data.get('style_updates', 0),
                session_data.get('quality_score', 0.0),
                session_data.get('success', False)
            ))
            
            await conn.commit()
            return True
            
        except Exception as e:
            self._logger.error(f"ä¿å­˜å­¦ä¹ ä¼šè¯è®°å½•å¤±è´¥: {e}")
            return False

    async def get_recent_learning_sessions(self, group_id: str, days: int = 7) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„å­¦ä¹ ä¼šè¯è®°å½•"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            start_time = time.time() - (days * 24 * 3600)
            
            await cursor.execute('''
                SELECT session_id, start_time, end_time, messages_processed, filtered_messages,
                       style_updates, quality_score, success
                FROM learning_sessions 
                WHERE start_time >= ?
                ORDER BY start_time DESC
            ''', (start_time,))
            
            sessions = []
            for row in await cursor.fetchall():
                sessions.append({
                    'session_id': row[0],
                    'start_time': row[1],
                    'end_time': row[2],
                    'messages_processed': row[3],
                    'filtered_messages': row[4],
                    'style_updates': row[5],
                    'quality_score': row[6],
                    'success': row[7]
                })
            
            return sessions
            
        except Exception as e:
            self._logger.error(f"è·å–å­¦ä¹ ä¼šè¯è®°å½•å¤±è´¥: {e}")
            return []

    # ========== å¥½æ„Ÿåº¦ç³»ç»Ÿæ•°æ®åº“æ“ä½œæ–¹æ³• ==========

    async def get_user_affection(self, group_id: str, user_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ç”¨æˆ·å¥½æ„Ÿåº¦"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT affection_level, last_interaction, last_updated, interaction_count
                FROM user_affection WHERE user_id = ? AND group_id = ?
            ''', (user_id, group_id))
            
            row = await cursor.fetchone()
            if not row:
                return None
                
            return {
                'user_id': user_id,
                'group_id': group_id,
                'affection_level': row[0],
                'last_interaction': row[1],
                'last_updated': row[2],
                'interaction_count': row[3]
            }
            
        except Exception as e:
            self._logger.error(f"è·å–ç”¨æˆ·å¥½æ„Ÿåº¦å¤±è´¥: {e}")
            return None

    async def update_user_affection(self, group_id: str, user_id: str, 
                                  new_level: int, change_reason: str = "", 
                                  bot_mood: str = "") -> bool:
        """æ›´æ–°ç”¨æˆ·å¥½æ„Ÿåº¦"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            current_time = time.time()
            
            # è·å–å½“å‰å¥½æ„Ÿåº¦
            current_affection = await self.get_user_affection(group_id, user_id)
            previous_level = current_affection['affection_level'] if current_affection else 0
            interaction_count = current_affection['interaction_count'] if current_affection else 0
            
            # æ›´æ–°æˆ–æ’å…¥å¥½æ„Ÿåº¦è®°å½•
            await cursor.execute('''
                INSERT OR REPLACE INTO user_affection 
                (user_id, group_id, affection_level, last_interaction, last_updated, interaction_count)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (user_id, group_id, new_level, current_time, current_time, interaction_count + 1))
            
            # è®°å½•å¥½æ„Ÿåº¦å˜åŒ–å†å²
            change_amount = new_level - previous_level
            if change_amount != 0:
                await cursor.execute('''
                    INSERT INTO affection_history 
                    (user_id, group_id, change_amount, previous_level, new_level, 
                     change_reason, bot_mood, timestamp)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (user_id, group_id, change_amount, previous_level, new_level, 
                      change_reason, bot_mood, current_time))
            
            await conn.commit()
            return True
            
        except Exception as e:
            self._logger.error(f"æ›´æ–°ç”¨æˆ·å¥½æ„Ÿåº¦å¤±è´¥: {e}")
            return False

    async def get_all_user_affections(self, group_id: str) -> List[Dict[str, Any]]:
        """è·å–ç¾¤å†…æ‰€æœ‰ç”¨æˆ·å¥½æ„Ÿåº¦"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT user_id, affection_level, last_interaction, last_updated, interaction_count
                FROM user_affection 
                WHERE group_id = ?
                ORDER BY affection_level DESC
            ''', (group_id,))
            
            affections = []
            for row in await cursor.fetchall():
                affections.append({
                    'user_id': row[0],
                    'group_id': group_id,
                    'affection_level': row[1],
                    'last_interaction': row[2],
                    'last_updated': row[3],
                    'interaction_count': row[4]
                })
            
            return affections
            
        except Exception as e:
            self._logger.error(f"è·å–æ‰€æœ‰ç”¨æˆ·å¥½æ„Ÿåº¦å¤±è´¥: {e}")
            return []

    async def get_total_affection(self, group_id: str) -> int:
        """è·å–ç¾¤å†…æ€»å¥½æ„Ÿåº¦"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            await cursor.execute('''
                SELECT SUM(affection_level) FROM user_affection WHERE group_id = ?
            ''', (group_id,))
            
            result = await cursor.fetchone()
            return result[0] if result[0] is not None else 0
            
        except Exception as e:
            self._logger.error(f"è·å–æ€»å¥½æ„Ÿåº¦å¤±è´¥: {e}")
            return 0

    async def save_bot_mood(self, group_id: str, mood_type: str, mood_intensity: float,
                           mood_description: str, duration_hours: int = 24) -> bool:
        """ä¿å­˜botæƒ…ç»ªçŠ¶æ€"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            current_time = time.time()
            end_time = current_time + (duration_hours * 3600)
            
            # å°†ä¹‹å‰çš„æƒ…ç»ªè®¾ä¸ºéæ´»è·ƒçŠ¶æ€
            await cursor.execute('''
                UPDATE bot_mood SET is_active = FALSE, end_time = ? WHERE group_id = ? AND is_active = TRUE
            ''', (current_time, group_id))
            
            # æ’å…¥æ–°çš„æƒ…ç»ªçŠ¶æ€
            await cursor.execute('''
                INSERT INTO bot_mood 
                (group_id, mood_type, mood_intensity, mood_description, start_time, end_time, is_active)
                VALUES (?, ?, ?, ?, ?, ?, TRUE)
            ''', (group_id, mood_type, mood_intensity, mood_description, current_time, end_time))
            
            await conn.commit()
            return True
            
        except Exception as e:
            self._logger.error(f"ä¿å­˜botæƒ…ç»ªå¤±è´¥: {e}")
            return False

    async def get_current_bot_mood(self, group_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å½“å‰botæƒ…ç»ª"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            current_time = time.time()
            
            await cursor.execute('''
                SELECT mood_type, mood_intensity, mood_description, start_time, end_time
                FROM bot_mood 
                WHERE group_id = ? AND is_active = TRUE AND start_time <= ? AND (end_time IS NULL OR end_time > ?)
                ORDER BY start_time DESC
                LIMIT 1
            ''', (group_id, current_time, current_time))
            
            row = await cursor.fetchone()
            if not row:
                return None
                
            return {
                'mood_type': row[0],
                'mood_intensity': row[1],
                'mood_description': row[2],
                'start_time': row[3],
                'end_time': row[4]
            }
            
        except Exception as e:
            self._logger.error(f"è·å–å½“å‰botæƒ…ç»ªå¤±è´¥: {e}")
            return None

    async def get_affection_history(self, group_id: str, user_id: str = None, 
                                   days: int = 7) -> List[Dict[str, Any]]:
        """è·å–å¥½æ„Ÿåº¦å˜åŒ–å†å²"""
        conn = await self.get_group_connection(group_id)
        cursor = await conn.cursor()
        
        try:
            start_time = time.time() - (days * 24 * 3600)
            
            if user_id:
                await cursor.execute('''
                    SELECT user_id, change_amount, previous_level, new_level, 
                           change_reason, bot_mood, timestamp
                    FROM affection_history 
                    WHERE group_id = ? AND user_id = ? AND timestamp >= ?
                    ORDER BY timestamp DESC
                ''', (group_id, user_id, start_time))
            else:
                await cursor.execute('''
                    SELECT user_id, change_amount, previous_level, new_level, 
                           change_reason, bot_mood, timestamp
                    FROM affection_history 
                    WHERE group_id = ? AND timestamp >= ?
                    ORDER BY timestamp DESC
                ''', (group_id, start_time))
            
            history = []
            for row in await cursor.fetchall():
                history.append({
                    'user_id': row[0],
                    'change_amount': row[1],
                    'previous_level': row[2],
                    'new_level': row[3],
                    'change_reason': row[4],
                    'bot_mood': row[5],
                    'timestamp': row[6]
                })
            
            return history
            
        except Exception as e:
            self._logger.error(f"è·å–å¥½æ„Ÿåº¦å†å²å¤±è´¥: {e}")
            return []

    async def record_llm_call_statistics(self, provider_type: str, model_name: str, 
                                        success: bool, response_time_ms: int) -> bool:
        """è®°å½•LLMè°ƒç”¨ç»Ÿè®¡æ•°æ®"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
                
                current_time = time.time()
                
                # æŸ¥è¯¢å½“å‰ç»Ÿè®¡æ•°æ®
                await cursor.execute('''
                    SELECT total_calls, success_calls, failed_calls, total_response_time_ms
                    FROM llm_call_statistics 
                    WHERE provider_type = ? AND model_name = ?
                ''', (provider_type, model_name))
                
                row = await cursor.fetchone()
                if row:
                    # æ›´æ–°ç°æœ‰è®°å½•
                    total_calls = row[0] + 1
                    success_calls = row[1] + (1 if success else 0)
                    failed_calls = row[2] + (0 if success else 1)
                    total_response_time = row[3] + response_time_ms
                    avg_response_time = total_response_time / total_calls
                    success_rate = success_calls / total_calls
                    
                    await cursor.execute('''
                        UPDATE llm_call_statistics 
                        SET total_calls = ?, success_calls = ?, failed_calls = ?, 
                            total_response_time_ms = ?, avg_response_time_ms = ?, 
                            success_rate = ?, last_call_time = ?, updated_at = CURRENT_TIMESTAMP
                        WHERE provider_type = ? AND model_name = ?
                    ''', (total_calls, success_calls, failed_calls, total_response_time,
                          avg_response_time, success_rate, current_time, provider_type, model_name))
                else:
                    # æ’å…¥æ–°è®°å½•
                    success_calls = 1 if success else 0
                    failed_calls = 0 if success else 1
                    success_rate = 1.0 if success else 0.0
                    
                    await cursor.execute('''
                        INSERT INTO llm_call_statistics 
                        (provider_type, model_name, total_calls, success_calls, failed_calls,
                         total_response_time_ms, avg_response_time_ms, success_rate, last_call_time)
                        VALUES (?, ?, 1, ?, ?, ?, ?, ?, ?)
                    ''', (provider_type, model_name, success_calls, failed_calls,
                          response_time_ms, response_time_ms, success_rate, current_time))
                
                await conn.commit()
                return True
                
        except Exception as e:
            self._logger.error(f"è®°å½•LLMè°ƒç”¨ç»Ÿè®¡å¤±è´¥: {e}")
            return False
        finally:
            await cursor.close()

    async def get_llm_call_statistics(self) -> Dict[str, Any]:
        """è·å–LLMè°ƒç”¨ç»Ÿè®¡æ•°æ®"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
                
                await cursor.execute('''
                    SELECT provider_type, model_name, total_calls, success_calls, failed_calls,
                           avg_response_time_ms, success_rate, last_call_time
                    FROM llm_call_statistics
                    ORDER BY provider_type, total_calls DESC
                ''')
                
                statistics = {}
                total_calls = 0
                
                for row in await cursor.fetchall():
                    provider_type = row[0]
                    model_name = row[1] or f"{provider_type}_model"
                    
                    stats = {
                        "total_calls": row[2],
                        "success_calls": row[3], 
                        "failed_calls": row[4],
                        "avg_response_time_ms": row[5] or 0,
                        "success_rate": row[6] or 0,
                        "last_call_time": row[7]
                    }
                    
                    statistics[f"{provider_type}_{model_name}"] = stats
                    total_calls += row[2]
                
                # å¦‚æœæ²¡æœ‰ç»Ÿè®¡æ•°æ®ï¼Œè¿”å›é»˜è®¤ç»“æ„
                if not statistics:
                    statistics = {
                        "filter_provider": {"total_calls": 0, "avg_response_time_ms": 0, "success_rate": 0, "error_count": 0},
                        "refine_provider": {"total_calls": 0, "avg_response_time_ms": 0, "success_rate": 0, "error_count": 0}, 
                        "reinforce_provider": {"total_calls": 0, "avg_response_time_ms": 0, "success_rate": 0, "error_count": 0}
                    }
                
                return {
                    "statistics": statistics,
                    "total_calls": total_calls
                }
                
        except Exception as e:
            self._logger.error(f"è·å–LLMè°ƒç”¨ç»Ÿè®¡å¤±è´¥: {e}")
            return {
                "statistics": {
                    "filter_provider": {"total_calls": 0, "avg_response_time_ms": 0, "success_rate": 0, "error_count": 0},
                    "refine_provider": {"total_calls": 0, "avg_response_time_ms": 0, "success_rate": 0, "error_count": 0},
                    "reinforce_provider": {"total_calls": 0, "avg_response_time_ms": 0, "success_rate": 0, "error_count": 0}
                },
                "total_calls": 0
            }
        finally:
            await cursor.close()

    async def export_messages_learning_data(self) -> Dict[str, Any]:
        """å¯¼å‡ºæ¶ˆæ¯å­¦ä¹ æ•°æ®"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()

            # å¯¼å‡ºåŸå§‹æ¶ˆæ¯
            await cursor.execute('''
                SELECT id, sender_id, sender_name, message, group_id, platform, timestamp, processed
                FROM raw_messages ORDER BY timestamp DESC
            ''')
            raw_messages = []
            for row in await cursor.fetchall():
                raw_messages.append({
                    'id': row[0],
                    'sender_id': row[1],
                    'sender_name': row[2],
                    'message': row[3],
                    'group_id': row[4],
                    'platform': row[5],
                    'timestamp': row[6],
                    'processed': bool(row[7])
                })

            # å¯¼å‡ºç­›é€‰æ¶ˆæ¯
            await cursor.execute('''
                SELECT id, raw_message_id, message, sender_id, group_id, confidence,
                       filter_reason, timestamp, used_for_learning, quality_scores
                FROM filtered_messages ORDER BY timestamp DESC
            ''')
            filtered_messages = []
            for row in await cursor.fetchall():
                quality_scores = {}
                try:
                    if row[9]:  # quality_scores
                        quality_scores = json.loads(row[9])
                except (json.JSONDecodeError, TypeError):
                    pass

                filtered_messages.append({
                    'id': row[0],
                    'raw_message_id': row[1],
                    'message': row[2],
                    'sender_id': row[3],
                    'group_id': row[4],
                    'confidence': row[5],
                    'filter_reason': row[6],
                    'timestamp': row[7],
                    'used_for_learning': bool(row[8]),
                    'quality_scores': quality_scores
                })

            # å¯¼å‡ºå­¦ä¹ æ‰¹æ¬¡è®°å½•
            await cursor.execute('''
                SELECT id, group_id, start_time, end_time, quality_score,
                       processed_messages, batch_name, message_count,
                       filtered_count, success, error_message
                FROM learning_batches ORDER BY start_time DESC
            ''')
            learning_batches = []
            for row in await cursor.fetchall():
                learning_batches.append({
                    'id': row[0],
                    'group_id': row[1],
                    'start_time': row[2],
                    'end_time': row[3],
                    'quality_score': row[4],
                    'processed_messages': row[5],
                    'batch_name': row[6],
                    'message_count': row[7],
                    'filtered_count': row[8],
                    'success': bool(row[9]),
                    'error_message': row[10]
                })

            # å¯¼å‡ºäººæ ¼æ›´æ–°è®°å½•
            await cursor.execute('''
                SELECT id, timestamp, group_id, update_type, original_content,
                       new_content, reason, status, reviewer_comment, review_time
                FROM persona_update_records ORDER BY timestamp DESC
            ''')
            persona_update_records = []
            for row in await cursor.fetchall():
                persona_update_records.append({
                    'id': row[0],
                    'timestamp': row[1],
                    'group_id': row[2],
                    'update_type': row[3],
                    'original_content': row[4],
                    'new_content': row[5],
                    'reason': row[6],
                    'status': row[7],
                    'reviewer_comment': row[8],
                    'review_time': row[9]
                })

            # è·å–ç»Ÿè®¡ä¿¡æ¯
            statistics = await self.get_messages_statistics()

            export_data = {
                'export_timestamp': time.time(),
                'export_date': datetime.now().isoformat(),
                'statistics': statistics,
                'raw_messages': raw_messages,
                'filtered_messages': filtered_messages,
                'learning_batches': learning_batches,
                'persona_update_records': persona_update_records
            }

            self._logger.info(f"æˆåŠŸå¯¼å‡ºå­¦ä¹ æ•°æ®: {len(raw_messages)} æ¡åŸå§‹æ¶ˆæ¯, {len(filtered_messages)} æ¡ç­›é€‰æ¶ˆæ¯")
            return export_data

        except Exception as e:
            self._logger.error(f"å¯¼å‡ºæ¶ˆæ¯å­¦ä¹ æ•°æ®å¤±è´¥: {e}", exc_info=True)
            raise DataStorageError(f"å¯¼å‡ºæ¶ˆæ¯å­¦ä¹ æ•°æ®å¤±è´¥: {str(e)}")
        finally:
            await cursor.close()

    async def clear_all_messages_data(self):
        """æ¸…ç©ºæ‰€æœ‰æ¶ˆæ¯æ•°æ®"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()

            # æ¸…ç©ºæ‰€æœ‰è¡¨çš„æ•°æ®
            tables_to_clear = [
                'raw_messages',
                'filtered_messages',
                'learning_batches',
                'persona_update_records',
                'reinforcement_learning_results',
                'persona_fusion_history',
                'strategy_optimization_results',
                'learning_performance_history'
            ]

            for table in tables_to_clear:
                await cursor.execute(f'DELETE FROM {table}')
                self._logger.debug(f"å·²æ¸…ç©ºè¡¨: {table}")

            await conn.commit()
            self._logger.info("æ‰€æœ‰æ¶ˆæ¯æ•°æ®å·²æ¸…ç©º")

        except Exception as e:
            self._logger.error(f"æ¸…ç©ºæ‰€æœ‰æ¶ˆæ¯æ•°æ®å¤±è´¥: {e}", exc_info=True)
            raise DataStorageError(f"æ¸…ç©ºæ‰€æœ‰æ¶ˆæ¯æ•°æ®å¤±è´¥: {str(e)}")
        finally:
            await cursor.close()

    # Webç•Œé¢éœ€è¦çš„ç»Ÿè®¡æ–¹æ³•
    async def get_style_learning_statistics(self) -> Dict[str, Any]:
        """è·å–é£æ ¼å­¦ä¹ ç»Ÿè®¡æ•°æ®"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # è·å–åŸºç¡€ç»Ÿè®¡
            await cursor.execute('''
                SELECT 
                    COUNT(DISTINCT group_id) as unique_groups,
                    AVG(confidence) as avg_confidence,
                    COUNT(*) as total_samples
                FROM filtered_messages
            ''')
            
            row = await cursor.fetchone()
            if row:
                unique_styles = row[0] or 0
                avg_confidence = row[1] or 0.0
                total_samples = row[2] or 0
            else:
                unique_styles = 0
                avg_confidence = 0.0
                total_samples = 0
            
            # è·å–æœ€æ–°æ›´æ–°æ—¶é—´
            await cursor.execute('''
                SELECT MAX(timestamp) FROM filtered_messages
            ''')
            latest_update = await cursor.fetchone()
            latest_update_time = latest_update[0] if latest_update and latest_update[0] else None
            
            return {
                'unique_styles': unique_styles,
                'avg_confidence': round(avg_confidence, 2),
                'total_samples': total_samples,
                'latest_update': latest_update_time  # è¿”å›æ—¶é—´æˆ³è€Œä¸æ˜¯ISOæ ¼å¼
            }
            
        except Exception as e:
            self._logger.error(f"è·å–é£æ ¼å­¦ä¹ ç»Ÿè®¡å¤±è´¥: {e}")
            return {
                'unique_styles': 0,
                'avg_confidence': 0,
                'total_samples': 0,
                'latest_update': None
            }
        finally:
            await cursor.close()

    async def get_style_progress_data(self) -> List[Dict[str, Any]]:
        """è·å–é£æ ¼è¿›åº¦æ•°æ®"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # è·å–å­¦ä¹ æ‰¹æ¬¡çš„è¿›åº¦æ•°æ®
            await cursor.execute('''
                SELECT 
                    group_id,
                    end_time,
                    quality_score,
                    filtered_count,
                    message_count
                FROM learning_batches
                WHERE success = 1 AND end_time IS NOT NULL
                ORDER BY end_time DESC
                LIMIT 20
            ''')
            
            progress_data = []
            for row in await cursor.fetchall():
                progress_data.append({
                    'group_id': row[0],
                    'timestamp': row[1],
                    'quality_score': row[2] or 0,
                    'filtered_count': row[3] or 0,
                    'message_count': row[4] or 0,
                    'efficiency': (row[3] / row[4] * 100) if row[4] > 0 else 0
                })
            
            return progress_data
            
        except Exception as e:
            self._logger.error(f"è·å–é£æ ¼è¿›åº¦æ•°æ®å¤±è´¥: {e}")
            return []
        finally:
            await cursor.close()

    async def get_learning_patterns_data(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ æ¨¡å¼æ•°æ®"""
        try:
            # é¦–å…ˆå°è¯•è·å–è¡¨è¾¾æ¨¡å¼æ•°æ®ï¼ˆæ¥è‡ªexpression_patternsè¡¨ï¼‰
            expression_patterns = await self.get_expression_patterns_for_webui()
            
            # è·å–å…¶ä»–å­¦ä¹ æ•°æ®
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰åŸå§‹æ¶ˆæ¯æ•°æ®
            await cursor.execute('SELECT COUNT(*) FROM raw_messages')
            raw_data_count = (await cursor.fetchone())[0]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç­›é€‰æ¶ˆæ¯æ•°æ®
            await cursor.execute('SELECT COUNT(*) FROM filtered_messages')
            filtered_data_count = (await cursor.fetchone())[0]
            
            # å¦‚æœæœ‰è¡¨è¾¾æ¨¡å¼æ•°æ®ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤æç¤º
            if expression_patterns:
                emotion_patterns = []
                for pattern in expression_patterns[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                    situation = pattern.get('situation', 'åœºæ™¯æè¿°').strip()
                    expression = pattern.get('expression', 'è¡¨è¾¾æ–¹å¼').strip()
                    weight = pattern.get('weight', 0)
                    
                    # ç¡®ä¿ä¸æ˜¾ç¤ºç©ºçš„æˆ–æ— æ„ä¹‰çš„æ•°æ®
                    if situation and expression and situation != 'æœªçŸ¥' and expression != 'æœªçŸ¥':
                        pattern_name = f"æƒ…æ„Ÿè¡¨è¾¾-{situation[:10]}"  # æˆªå–å‰10ä¸ªå­—ç¬¦ä½œä¸ºæ¨¡å¼å
                        emotion_patterns.append({
                            'pattern': pattern_name,
                            'confidence': round(weight * 20, 2),  # å°†æƒé‡è½¬æ¢ä¸ºç½®ä¿¡åº¦ç™¾åˆ†æ¯”
                            'frequency': max(1, int(weight))  # ç¡®ä¿é¢‘ç‡è‡³å°‘ä¸º1
                        })
                
                # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„è¡¨è¾¾æ¨¡å¼ï¼Œæ·»åŠ ä¸€ä¸ªè¯´æ˜
                if not emotion_patterns:
                    emotion_patterns.append({
                        'pattern': 'æ­£åœ¨å­¦ä¹ è¡¨è¾¾æ¨¡å¼',
                        'confidence': 30.0,
                        'frequency': 1
                    })
            else:
                # å¦‚æœæ²¡æœ‰è¡¨è¾¾æ¨¡å¼ï¼Œä½†æœ‰åŸå§‹æ•°æ®ï¼Œæ˜¾ç¤ºå­¦ä¹ ä¸­çŠ¶æ€
                if raw_data_count > 0:
                    emotion_patterns = [{
                        'pattern': 'æ­£åœ¨å­¦ä¹ è¡¨è¾¾æ¨¡å¼ï¼Œè¯·ç¨å€™...',
                        'confidence': 50.0,
                        'frequency': raw_data_count
                    }]
                else:
                    emotion_patterns = [{
                        'pattern': 'æš‚æ— å¯¹è¯æ•°æ®ï¼Œè¯·å…ˆè¿›è¡Œå¯¹è¯',
                        'confidence': 0.0,
                        'frequency': 0
                    }]
            
            # è¯­è¨€é£æ ¼åˆ†æï¼ˆåŸºäºåŸå§‹æ¶ˆæ¯é•¿åº¦åˆ†å¸ƒï¼‰
            await cursor.execute('''
                SELECT 
                    CASE 
                        WHEN LENGTH(message) < 10 THEN 'ç®€çŸ­è¡¨è¾¾'
                        WHEN LENGTH(message) < 30 THEN 'é€‚ä¸­è¡¨è¾¾'
                        WHEN LENGTH(message) < 100 THEN 'è¯¦ç»†è¡¨è¾¾'
                        ELSE 'é•¿ç¯‡è¡¨è¾¾'
                    END as style_type,
                    COUNT(*) as count
                FROM raw_messages
                WHERE message IS NOT NULL AND LENGTH(TRIM(message)) > 0
                GROUP BY style_type
            ''')
            
            language_patterns = []
            for row in await cursor.fetchall():
                language_patterns.append({
                    'style': row[0],  # æ”¹ä¸ºstyleå­—æ®µä»¥åŒ¹é…å‰ç«¯
                    'type': row[0],   # ä¿ç•™typeç”¨äºå…¼å®¹æ€§
                    'count': row[1],
                    'frequency': row[1],  # æ·»åŠ frequencyå­—æ®µç”¨äºå‰ç«¯æ˜¾ç¤º
                    'context': 'general',
                    'environment': 'general'
                })
            
            # å¦‚æœæ²¡æœ‰è¯­è¨€æ¨¡å¼æ•°æ®
            if not language_patterns:
                language_patterns = [{
                    'style': 'æš‚æ— è¯­è¨€é£æ ¼æ•°æ®',
                    'type': 'æš‚æ— è¯­è¨€é£æ ¼æ•°æ®',
                    'count': 0,
                    'frequency': 0,
                    'context': 'general',
                    'environment': 'general'
                }]
            
            # è¯é¢˜åå¥½åˆ†æï¼ˆåŸºäºç¾¤ç»„æ´»è·ƒåº¦å’Œæ™ºèƒ½ä¸»é¢˜è¯†åˆ«ï¼‰
            topic_preferences = []
            
            # è·å–å„ä¸ªç¾¤ç»„çš„æ¶ˆæ¯æ•°æ®è¿›è¡Œä¸»é¢˜åˆ†æ
            await cursor.execute('''
                SELECT 
                    group_id,
                    COUNT(*) as message_count,
                    AVG(LENGTH(message)) as avg_length
                FROM raw_messages
                WHERE group_id IS NOT NULL AND LENGTH(TRIM(message)) > 3
                GROUP BY group_id
                HAVING COUNT(*) > 10
                ORDER BY message_count DESC
                LIMIT 8
            ''')
            
            group_data = await cursor.fetchall()
            
            for row in group_data:
                group_id = row[0]
                message_count = row[1]
                avg_length = row[2]
                
                # è·å–è¯¥ç¾¤ç»„çš„ä»£è¡¨æ€§æ¶ˆæ¯è¿›è¡Œä¸»é¢˜åˆ†æ
                await cursor.execute('''
                    SELECT message 
                    FROM raw_messages 
                    WHERE group_id = ? AND LENGTH(TRIM(message)) > 5 AND LENGTH(TRIM(message)) < 200
                    ORDER BY LENGTH(message) DESC, timestamp DESC 
                    LIMIT 20
                ''', (group_id,))
                
                messages = await cursor.fetchall()
                if not messages:
                    continue
                    
                # æ™ºèƒ½ä¸»é¢˜è¯†åˆ«
                topic_analysis = self._analyze_topic_from_messages([msg[0] for msg in messages])
                topic_name = topic_analysis['topic']
                conversation_style = topic_analysis['style']
                
                # æ ¹æ®æ¶ˆæ¯é•¿åº¦å’Œæ•°é‡æ¨æ–­å…´è¶£åº¦
                interest_level = min(100, max(10, (message_count * avg_length) / 50))
                
                topic_preferences.append({
                    'topic': topic_name,
                    'style': conversation_style,
                    'interest_level': round(interest_level, 1)
                })

            # å»é‡ï¼šç¡®ä¿æ¯ä¸ªè¯é¢˜åªå‡ºç°ä¸€æ¬¡ï¼Œä¿ç•™å…´è¶£åº¦æœ€é«˜çš„
            seen_topics = {}
            for pref in topic_preferences:
                topic = pref['topic']
                if topic not in seen_topics or pref['interest_level'] > seen_topics[topic]['interest_level']:
                    seen_topics[topic] = pref

            topic_preferences = list(seen_topics.values())

            # å¦‚æœæ²¡æœ‰è¯é¢˜åå¥½æ•°æ®
            if not topic_preferences:
                topic_preferences = [{
                    'topic': 'æš‚æ— è¯é¢˜æ•°æ®',
                    'style': 'ç­‰å¾…ä¸­',
                    'interest_level': 0.0
                }]
            
            return {
                'emotion_patterns': emotion_patterns,
                'language_patterns': language_patterns,
                'topic_preferences': topic_preferences
            }
            
        except Exception as e:
            self._logger.error(f"è·å–å­¦ä¹ æ¨¡å¼æ•°æ®å¤±è´¥: {e}")
            return {
                'emotion_patterns': [
                    {'pattern': 'æ•°æ®è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»ŸçŠ¶æ€', 'confidence': 0, 'frequency': 0}
                ],
                'language_patterns': [
                    {'type': 'æ•°æ®è·å–å¤±è´¥', 'count': 0, 'environment': 'general'}
                ],
                'topic_preferences': [
                    {'topic': 'æ•°æ®è·å–å¤±è´¥', 'style': 'normal', 'interest_level': 0}
                ]
            }
        finally:
            if 'cursor' in locals():
                await cursor.close()

    async def get_expression_patterns_for_webui(self, limit: int = 20) -> List[Dict[str, Any]]:
        """è·å–è¡¨è¾¾æ¨¡å¼æ•°æ®ç”¨äºWebUIæ˜¾ç¤º"""
        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            await cursor.execute('''
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name='expression_patterns'
            ''')
            
            table_exists = await cursor.fetchone()
            if not table_exists:
                self._logger.debug("expression_patternsè¡¨ä¸å­˜åœ¨")
                return []
            
            # è·å–è¡¨è¾¾æ¨¡å¼æ•°æ®
            await cursor.execute('''
                SELECT situation, expression, weight, last_active_time, group_id
                FROM expression_patterns
                ORDER BY weight DESC, last_active_time DESC
                LIMIT ?
            ''', (limit,))
            
            patterns = []
            for row in await cursor.fetchall():
                patterns.append({
                    'situation': row[0],
                    'expression': row[1],
                    'weight': row[2],
                    'last_active_time': row[3],
                    'group_id': row[4]
                })
            
            return patterns
            
        except Exception as e:
            self._logger.error(f"è·å–è¡¨è¾¾æ¨¡å¼å¤±è´¥: {e}")
            return []
        finally:
            await cursor.close()

    async def create_style_learning_review(self, review_data: Dict[str, Any]) -> int:
        """åˆ›å»ºå¯¹è¯é£æ ¼å­¦ä¹ å®¡æŸ¥è®°å½•"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # ç¡®ä¿å®¡æŸ¥è¡¨å­˜åœ¨
            await self._ensure_style_review_table_exists(cursor)
            
            # æ’å…¥å®¡æŸ¥è®°å½•
            await cursor.execute('''
                INSERT INTO style_learning_reviews 
                (type, group_id, timestamp, learned_patterns, few_shots_content, status, description)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                review_data['type'],
                review_data['group_id'],
                review_data['timestamp'],
                json.dumps(review_data['learned_patterns'], ensure_ascii=False),
                review_data['few_shots_content'],
                review_data['status'],
                review_data['description']
            ))
            
            review_id = cursor.lastrowid
            await conn.commit()
            
            self._logger.info(f"åˆ›å»ºé£æ ¼å­¦ä¹ å®¡æŸ¥è®°å½•æˆåŠŸï¼ŒID: {review_id}")
            return review_id
            
        except Exception as e:
            self._logger.error(f"åˆ›å»ºé£æ ¼å­¦ä¹ å®¡æŸ¥è®°å½•å¤±è´¥: {e}")
            raise DataStorageError(f"åˆ›å»ºé£æ ¼å­¦ä¹ å®¡æŸ¥è®°å½•å¤±è´¥: {str(e)}")

    async def _ensure_style_review_table_exists(self, cursor):
        """ç¡®ä¿é£æ ¼å­¦ä¹ å®¡æŸ¥è¡¨å­˜åœ¨"""
        await cursor.execute('''
            CREATE TABLE IF NOT EXISTS style_learning_reviews (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                type TEXT NOT NULL,
                group_id TEXT NOT NULL,
                timestamp REAL NOT NULL,
                learned_patterns TEXT,  -- JSONæ ¼å¼å­˜å‚¨å­¦ä¹ åˆ°çš„æ¨¡å¼
                few_shots_content TEXT,  -- Few shotså¯¹è¯å†…å®¹
                status TEXT DEFAULT 'pending',  -- pending, approved, rejected
                description TEXT,
                created_at REAL DEFAULT (strftime('%s', 'now')),
                updated_at REAL DEFAULT (strftime('%s', 'now'))
            )
        ''')

    async def get_pending_style_reviews(self, limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–å¾…å®¡æŸ¥çš„é£æ ¼å­¦ä¹ è®°å½•"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # ç¡®ä¿è¡¨å­˜åœ¨
            await self._ensure_style_review_table_exists(cursor)
            
            await cursor.execute('''
                SELECT id, type, group_id, timestamp, learned_patterns, few_shots_content, 
                       status, description, created_at
                FROM style_learning_reviews
                WHERE status = 'pending'
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (limit,))
            
            reviews = []
            for row in await cursor.fetchall():
                learned_patterns = []
                try:
                    if row[4]:  # learned_patterns
                        learned_patterns = json.loads(row[4])
                except json.JSONDecodeError:
                    pass
                    
                reviews.append({
                    'id': row[0],
                    'type': row[1],
                    'group_id': row[2],
                    'timestamp': row[3],
                    'learned_patterns': learned_patterns,
                    'few_shots_content': row[5],
                    'status': row[6],
                    'description': row[7],
                    'created_at': row[8]
                })
            
            return reviews
            
        except Exception as e:
            self._logger.error(f"è·å–å¾…å®¡æŸ¥é£æ ¼å­¦ä¹ è®°å½•å¤±è´¥: {e}")
            return []

    async def get_pending_persona_learning_reviews(self, limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–å¾…å®¡æŸ¥çš„äººæ ¼å­¦ä¹ è®°å½•ï¼ˆè´¨é‡ä¸è¾¾æ ‡çš„å­¦ä¹ ç»“æœï¼‰"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # ç¡®ä¿è¡¨å­˜åœ¨ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„ç»“æ„ï¼‰
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS persona_update_reviews (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL NOT NULL,
                    group_id TEXT NOT NULL,
                    update_type TEXT NOT NULL,
                    original_content TEXT,
                    new_content TEXT,
                    proposed_content TEXT, -- å»ºè®®çš„æ–°å†…å®¹ï¼ˆå…¼å®¹å­—æ®µï¼‰
                    confidence_score REAL, -- ç½®ä¿¡åº¦å¾—åˆ†
                    reason TEXT,
                    status TEXT NOT NULL DEFAULT 'pending',
                    reviewer_comment TEXT,
                    review_time REAL
                )
            ''')
            
            # å°è¯•æ·»åŠ metadataåˆ—ï¼ˆå¦‚æœè¡¨å·²å­˜åœ¨ä½†æ²¡æœ‰æ­¤åˆ—ï¼‰
            try:
                await cursor.execute('ALTER TABLE persona_update_reviews ADD COLUMN metadata TEXT')
            except:
                pass  # åˆ—å·²å­˜åœ¨

            await cursor.execute('''
                SELECT id, timestamp, group_id, update_type, original_content,
                       new_content, proposed_content, confidence_score, reason, status,
                       reviewer_comment, review_time, metadata
                FROM persona_update_reviews
                WHERE status = 'pending'
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (limit,))

            reviews = []
            import json
            for row in await cursor.fetchall():
                # ç¡®ä¿æœ‰proposed_contentå­—æ®µï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨new_content
                proposed_content = row[6] if row[6] else row[5]  # proposed_contentæˆ–new_content
                confidence_score = row[7] if row[7] is not None else 0.5  # ä½¿ç”¨æ•°æ®åº“ä¸­çš„ç½®ä¿¡åº¦

                # è§£æmetadata JSON
                metadata = {}
                if row[12]:  # metadataå­—æ®µ
                    try:
                        metadata = json.loads(row[12])
                    except:
                        metadata = {}

                reviews.append({
                    'id': row[0],
                    'timestamp': row[1],
                    'group_id': row[2],
                    'update_type': row[3],
                    'original_content': row[4],
                    'new_content': row[5],
                    'proposed_content': proposed_content,
                    'confidence_score': confidence_score,
                    'reason': row[8],
                    'status': row[9],
                    'reviewer_comment': row[10],
                    'review_time': row[11],
                    'metadata': metadata  # æ·»åŠ metadataå­—æ®µ
                })
            
            return reviews
            
        except Exception as e:
            self._logger.error(f"è·å–å¾…å®¡æŸ¥äººæ ¼å­¦ä¹ è®°å½•å¤±è´¥: {e}")
            return []

    async def update_persona_learning_review_status(self, review_id: int, status: str, comment: str = None, modified_content: str = None) -> bool:
        """æ›´æ–°äººæ ¼å­¦ä¹ å®¡æŸ¥çŠ¶æ€"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # å¦‚æœæœ‰ä¿®æ”¹åçš„å†…å®¹ï¼Œä¹Ÿè¦æ›´æ–°proposed_contentå­—æ®µ
            if modified_content:
                await cursor.execute('''
                    UPDATE persona_update_reviews
                    SET status = ?, reviewer_comment = ?, review_time = ?, proposed_content = ?, new_content = ?
                    WHERE id = ?
                ''', (status, comment, time.time(), modified_content, modified_content, review_id))
            else:
                await cursor.execute('''
                    UPDATE persona_update_reviews
                    SET status = ?, reviewer_comment = ?, review_time = ?
                    WHERE id = ?
                ''', (status, comment, time.time(), review_id))
            
            await conn.commit()
            return cursor.rowcount > 0
            
        except Exception as e:
            self._logger.error(f"æ›´æ–°äººæ ¼å­¦ä¹ å®¡æŸ¥çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    async def delete_persona_learning_review_by_id(self, review_id: int) -> bool:
        """åˆ é™¤æŒ‡å®šIDçš„äººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # åˆ é™¤å®¡æŸ¥è®°å½•
            await cursor.execute('''
                DELETE FROM persona_update_reviews WHERE id = ?
            ''', (review_id,))
            
            await conn.commit()
            deleted_count = cursor.rowcount
            
            if deleted_count > 0:
                self._logger.info(f"æˆåŠŸåˆ é™¤äººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•ï¼ŒID: {review_id}")
                return True
            else:
                self._logger.warning(f"æœªæ‰¾åˆ°è¦åˆ é™¤çš„äººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•ï¼ŒID: {review_id}")
                return False
            
        except Exception as e:
            self._logger.error(f"åˆ é™¤äººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•å¤±è´¥: {e}")
            return False
    
    async def get_persona_learning_review_by_id(self, review_id: int) -> Optional[Dict[str, Any]]:
        """è·å–æŒ‡å®šIDçš„äººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•è¯¦æƒ…"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            await cursor.execute('''
                SELECT id, group_id, original_content, new_content, proposed_content, 
                       confidence_score, reason, status, reviewer_comment, review_time, timestamp
                FROM persona_update_reviews
                WHERE id = ?
            ''', (review_id,))
            
            row = await cursor.fetchone()
            if row:
                return {
                    'id': row[0],
                    'group_id': row[1],
                    'original_content': row[2],
                    'new_content': row[3],
                    'proposed_content': row[4] if row[4] else row[3],  # proposed_contentæˆ–new_content
                    'confidence_score': row[5] if row[5] is not None else 0.5,
                    'reason': row[6],
                    'status': row[7],
                    'reviewer_comment': row[8],
                    'review_time': row[9],
                    'timestamp': row[10]
                }
            return None
            
        except Exception as e:
            self._logger.error(f"è·å–äººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•å¤±è´¥: {e}")
            return None

    async def save_style_learning_record(self, record_data: Dict[str, Any]) -> bool:
        """ä¿å­˜é£æ ¼å­¦ä¹ è®°å½•åˆ°æ•°æ®åº“"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            await cursor.execute('''
                INSERT INTO style_learning_records 
                (style_type, learned_patterns, confidence_score, sample_count, group_id, learning_time)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                record_data.get('style_type'),
                record_data.get('learned_patterns'),
                record_data.get('confidence_score'),
                record_data.get('sample_count'),
                record_data.get('group_id'),
                record_data.get('learning_time')
            ))
            
            await conn.commit()
            return True
            
        except Exception as e:
            self._logger.error(f"ä¿å­˜é£æ ¼å­¦ä¹ è®°å½•å¤±è´¥: {e}")
            return False

    async def save_language_style_pattern(self, pattern_data: Dict[str, Any]) -> bool:
        """ä¿å­˜è¯­è¨€é£æ ¼æ¨¡å¼åˆ°æ•°æ®åº“"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # å…ˆæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„è¯­è¨€é£æ ¼
            await cursor.execute('''
                SELECT id FROM language_style_patterns 
                WHERE language_style = ? AND group_id = ?
            ''', (pattern_data.get('language_style'), pattern_data.get('group_id')))
            
            existing = await cursor.fetchone()
            
            if existing:
                # æ›´æ–°ç°æœ‰è®°å½•
                await cursor.execute('''
                    UPDATE language_style_patterns 
                    SET example_phrases = ?, usage_frequency = ?, context_type = ?, last_updated = ?
                    WHERE id = ?
                ''', (
                    pattern_data.get('example_phrases'),
                    pattern_data.get('usage_frequency'),
                    pattern_data.get('context_type'),
                    pattern_data.get('last_updated'),
                    existing[0]
                ))
            else:
                # æ’å…¥æ–°è®°å½•
                await cursor.execute('''
                    INSERT INTO language_style_patterns 
                    (language_style, example_phrases, usage_frequency, context_type, group_id, last_updated)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    pattern_data.get('language_style'),
                    pattern_data.get('example_phrases'),
                    pattern_data.get('usage_frequency'),
                    pattern_data.get('context_type'),
                    pattern_data.get('group_id'),
                    pattern_data.get('last_updated')
                ))
            
            await conn.commit()
            return True
            
        except Exception as e:
            self._logger.error(f"ä¿å­˜è¯­è¨€é£æ ¼æ¨¡å¼å¤±è´¥: {e}")
            return False

    async def get_reviewed_persona_learning_updates(self, limit: int = 50, offset: int = 0, status_filter: str = None) -> List[Dict[str, Any]]:
        """è·å–å·²å®¡æŸ¥çš„äººæ ¼å­¦ä¹ æ›´æ–°è®°å½•"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            where_clause = "WHERE status != 'pending'"
            params = []
            
            if status_filter:
                where_clause += " AND status = ?"
                params.append(status_filter)
            
            # é¦–å…ˆæ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨å¹¶è·å–è¡¨ç»“æ„
            await cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='persona_update_reviews'")
            table_exists = await cursor.fetchone()
            
            if not table_exists:
                self._logger.info("persona_update_reviewsè¡¨ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºåˆ—è¡¨")
                return []
            
            # æ£€æŸ¥è¡¨ç»“æ„ï¼Œç¡®å®šæ­£ç¡®çš„å­—æ®µå
            await cursor.execute("PRAGMA table_info(persona_update_reviews)")
            columns = await cursor.fetchall()
            column_names = [col[1] for col in columns]
            
            # æ ¹æ®å®é™…çš„åˆ—åæ„å»ºæŸ¥è¯¢
            if 'proposed_content' in column_names:
                content_field = 'proposed_content'
            elif 'new_content' in column_names:
                content_field = 'new_content'
            else:
                # å¦‚æœä¸¤ä¸ªå­—æ®µéƒ½ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹å†…å®¹
                content_field = 'original_content'

            # æ£€æŸ¥æ˜¯å¦æœ‰metadataåˆ—
            has_metadata = 'metadata' in column_names

            # ä½¿ç”¨å®é™…å­˜åœ¨çš„å­—æ®µè¿›è¡ŒæŸ¥è¯¢ï¼Œå¹¶å¤„ç†NULLå€¼
            metadata_field = ', metadata' if has_metadata else ''
            await cursor.execute(f'''
                SELECT id, group_id, original_content, {content_field}, reason,
                       status, reviewer_comment, review_time, timestamp{metadata_field}
                FROM persona_update_reviews
                {where_clause}
                ORDER BY COALESCE(review_time, timestamp) DESC
                LIMIT ? OFFSET ?
            ''', params + [limit, offset])

            rows = await cursor.fetchall()
            updates = []

            import json
            for row in rows:
                # è§£æmetadataï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                metadata = {}
                if has_metadata and len(row) > 9 and row[9]:
                    try:
                        metadata = json.loads(row[9])
                    except:
                        metadata = {}

                updates.append({
                    'id': f"persona_learning_{row[0]}",
                    'group_id': row[1] or 'default',
                    'original_content': row[2] or '',
                    'proposed_content': row[3] or '',  # ä½¿ç”¨å®é™…å­˜åœ¨çš„å­—æ®µ
                    'reason': row[4] or 'äººæ ¼å­¦ä¹ æ›´æ–°',
                    'confidence_score': metadata.get('confidence_score', 0.8),  # ä»metadataè·å–æˆ–ä½¿ç”¨é»˜è®¤å€¼
                    'status': row[5],
                    'reviewer_comment': row[6] or '',
                    'review_time': row[7] if row[7] else 0,
                    'timestamp': row[8] if row[8] else 0,
                    'update_type': 'persona_learning_review',
                    # æ·»åŠ metadataä¸­çš„å…³é”®å­—æ®µ
                    'features_content': metadata.get('features_content', ''),
                    'llm_response': metadata.get('llm_response', ''),
                    'total_raw_messages': metadata.get('total_raw_messages', 0),
                    'messages_analyzed': metadata.get('messages_analyzed', 0),
                    'metadata': metadata
                })
            
            return updates
            
        except Exception as e:
            self._logger.error(f"è·å–å·²å®¡æŸ¥äººæ ¼å­¦ä¹ è®°å½•å¤±è´¥: {e}")
            # å¦‚æœæ˜¯è¡¨æˆ–åˆ—ä¸å­˜åœ¨çš„é”™è¯¯ï¼Œè¿”å›ç©ºåˆ—è¡¨
            if "no such table" in str(e).lower() or "no such column" in str(e).lower():
                self._logger.info("äººæ ¼å­¦ä¹ å®¡æŸ¥è¡¨æˆ–å­—æ®µä¸å­˜åœ¨ï¼Œè¿”å›ç©ºåˆ—è¡¨")
                return []
            return []

    async def get_reviewed_style_learning_updates(self, limit: int = 50, offset: int = 0, status_filter: str = None) -> List[Dict[str, Any]]:
        """è·å–å·²å®¡æŸ¥çš„é£æ ¼å­¦ä¹ æ›´æ–°è®°å½•"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            where_clause = "WHERE status != 'pending'"
            params = []
            
            if status_filter:
                where_clause += " AND status = ?"
                params.append(status_filter)
            
            # ä½¿ç”¨æ­£ç¡®çš„å­—æ®µåï¼Œæ²¡æœ‰review_timeå­—æ®µï¼Œä½¿ç”¨updated_atï¼Œå¹¶å¤„ç†NULLå€¼
            await cursor.execute(f'''
                SELECT id, type, group_id, timestamp, learned_patterns, status, updated_at, description
                FROM style_learning_reviews
                {where_clause}
                ORDER BY COALESCE(updated_at, timestamp) DESC
                LIMIT ? OFFSET ?
            ''', params + [limit, offset])
            
            rows = await cursor.fetchall()
            updates = []
            
            for row in rows:
                # å°è¯•è§£ælearned_patternsä»¥è·å–æ›´å¤šä¿¡æ¯
                try:
                    learned_patterns = json.loads(row[4]) if row[4] else {}
                    reason = learned_patterns.get('reason', 'é£æ ¼å­¦ä¹ æ›´æ–°')
                    original_content = learned_patterns.get('original_content', 'åŸå§‹é£æ ¼ç‰¹å¾')
                    proposed_content = learned_patterns.get('proposed_content', row[4])  # ä½¿ç”¨å®Œæ•´çš„learned_patternsä½œä¸ºproposed_content
                    confidence_score = learned_patterns.get('confidence_score', 0.8)
                except (json.JSONDecodeError, AttributeError):
                    reason = row[7] or 'é£æ ¼å­¦ä¹ æ›´æ–°'  # ä½¿ç”¨descriptionå­—æ®µ
                    original_content = 'åŸå§‹é£æ ¼ç‰¹å¾'
                    proposed_content = row[4] or 'æ— å†…å®¹'
                    confidence_score = 0.8
                
                updates.append({
                    'id': row[0],
                    'group_id': row[2],
                    'original_content': original_content,
                    'proposed_content': proposed_content,
                    'reason': reason,
                    'confidence_score': confidence_score,
                    'status': row[5],
                    'reviewer_comment': '',  # é£æ ¼å®¡æŸ¥æ²¡æœ‰å¤‡æ³¨å­—æ®µ
                    'review_time': row[6],  # ä½¿ç”¨updated_atå­—æ®µ
                    'timestamp': row[3],
                    'update_type': f'style_learning_{row[1]}'
                })
            
            return updates
            
        except Exception as e:
            self._logger.error(f"è·å–å·²å®¡æŸ¥é£æ ¼å­¦ä¹ è®°å½•å¤±è´¥: {e}")
            # å¦‚æœè¡¨ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
            if "no such table" in str(e).lower():
                self._logger.info("é£æ ¼å­¦ä¹ å®¡æŸ¥è¡¨ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºåˆ—è¡¨")
                return []
            return []

    async def get_reviewed_persona_update_records(self, limit: int = 50, offset: int = 0, status_filter: str = None) -> List[Dict[str, Any]]:
        """è·å–å·²å®¡æŸ¥çš„ä¼ ç»Ÿäººæ ¼æ›´æ–°è®°å½•"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            where_clause = "WHERE status != 'pending'"
            params = []
            
            if status_filter:
                where_clause += " AND status = ?"
                params.append(status_filter)
            
            await cursor.execute(f'''
                SELECT id, timestamp, group_id, update_type, original_content, new_content, 
                       reason, status, reviewer_comment, review_time
                FROM persona_update_records
                {where_clause}
                ORDER BY review_time DESC
                LIMIT ? OFFSET ?
            ''', params + [limit, offset])
            
            rows = await cursor.fetchall()
            records = []
            
            for row in rows:
                records.append({
                    'id': row[0],
                    'timestamp': row[1],
                    'group_id': row[2],
                    'update_type': row[3],
                    'original_content': row[4],
                    'new_content': row[5],
                    'reason': row[6],
                    'status': row[7],
                    'reviewer_comment': row[8],
                    'review_time': row[9]
                })
            
            return records
            
        except Exception as e:
            self._logger.error(f"è·å–å·²å®¡æŸ¥ä¼ ç»Ÿäººæ ¼æ›´æ–°è®°å½•å¤±è´¥: {e}")
            return []

    async def update_style_review_status(self, review_id: int, status: str, group_id: str = None) -> bool:
        """æ›´æ–°é£æ ¼å­¦ä¹ å®¡æŸ¥çŠ¶æ€"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()

            await cursor.execute('''
                UPDATE style_learning_reviews
                SET status = ?, updated_at = ?
                WHERE id = ?
            ''', (status, time.time(), review_id))

            await conn.commit()

            if cursor.rowcount > 0:
                self._logger.info(f"æ›´æ–°é£æ ¼å­¦ä¹ å®¡æŸ¥çŠ¶æ€æˆåŠŸ: ID={review_id}, çŠ¶æ€={status}")
                return True
            else:
                self._logger.warning(f"æ›´æ–°é£æ ¼å­¦ä¹ å®¡æŸ¥çŠ¶æ€å¤±è´¥: æœªæ‰¾åˆ°ID={review_id}çš„è®°å½•")
                return False

        except Exception as e:
            self._logger.error(f"æ›´æ–°é£æ ¼å­¦ä¹ å®¡æŸ¥çŠ¶æ€å¤±è´¥: {e}")
            return False

    async def delete_style_review_by_id(self, review_id: int) -> bool:
        """åˆ é™¤æŒ‡å®šIDçš„é£æ ¼å­¦ä¹ å®¡æŸ¥è®°å½•"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()

                # åˆ é™¤å®¡æŸ¥è®°å½•
                await cursor.execute('''
                    DELETE FROM style_learning_reviews WHERE id = ?
                ''', (review_id,))

                await conn.commit()
                deleted_count = cursor.rowcount

                await cursor.close()

                if deleted_count > 0:
                    self._logger.info(f"æˆåŠŸåˆ é™¤é£æ ¼å­¦ä¹ å®¡æŸ¥è®°å½•ï¼ŒID: {review_id}")
                    return True
                else:
                    self._logger.warning(f"æœªæ‰¾åˆ°è¦åˆ é™¤çš„é£æ ¼å­¦ä¹ å®¡æŸ¥è®°å½•ï¼ŒID: {review_id}")
                    return False

        except Exception as e:
            self._logger.error(f"åˆ é™¤é£æ ¼å­¦ä¹ å®¡æŸ¥è®°å½•å¤±è´¥: {e}")
            return False

    async def get_detailed_metrics(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†æ€§èƒ½ç›‘æ§æ•°æ®"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # APIæŒ‡æ ‡ï¼ˆåŸºäºå­¦ä¹ æ‰¹æ¬¡çš„æ‰§è¡Œæ—¶é—´ï¼‰
            await cursor.execute('''
                SELECT 
                    strftime('%H', datetime(start_time, 'unixepoch')) as hour,
                    AVG((CASE WHEN end_time IS NOT NULL THEN end_time - start_time ELSE 0 END)) as avg_response_time
                FROM learning_batches
                WHERE start_time > ? AND end_time IS NOT NULL
                GROUP BY hour
                ORDER BY hour
            ''', (time.time() - 86400,))  # æœ€è¿‘24å°æ—¶
            
            api_hours = []
            api_response_times = []
            for row in await cursor.fetchall():
                api_hours.append(f"{row[0]}:00")
                api_response_times.append(round(row[1] * 1000, 2))  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # æ•°æ®åº“è¡¨ç»Ÿè®¡
            tables_to_check = ['raw_messages', 'filtered_messages', 'learning_batches', 'persona_update_records']
            table_stats = {}
            
            for table in tables_to_check:
                try:
                    await cursor.execute(f'SELECT COUNT(*) FROM {table}')
                    count = await cursor.fetchone()
                    table_stats[table] = count[0] if count else 0
                except Exception as table_error:
                    self._logger.debug(f"æ— æ³•è·å–è¡¨ {table} ç»Ÿè®¡: {table_error}")
                    table_stats[table] = 0
            
            # ç³»ç»ŸæŒ‡æ ‡
            import psutil
            try:
                memory = psutil.virtual_memory()
                # åœ¨Windowsä¸Šä½¿ç”¨ä¸»é©±åŠ¨å™¨
                disk_path = 'C:\\' if os.name == 'nt' else '/'
                disk = psutil.disk_usage(disk_path)
                
                system_metrics = {
                    'memory_percent': memory.percent,
                    'cpu_percent': psutil.cpu_percent(),
                    'disk_percent': round(disk.used / disk.total * 100, 2)
                }
            except Exception as system_error:
                self._logger.warning(f"è·å–ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {system_error}")
                system_metrics = {
                    'memory_percent': 0,
                    'cpu_percent': 0,
                    'disk_percent': 0
                }
            
            return {
                'api_metrics': {
                    'hours': api_hours,
                    'response_times': api_response_times
                },
                'database_metrics': {
                    'table_stats': table_stats
                },
                'system_metrics': system_metrics
            }
            
        except Exception as e:
            self._logger.error(f"è·å–è¯¦ç»†ç›‘æ§æ•°æ®å¤±è´¥: {e}")
            return {
                'api_metrics': {
                    'hours': [],
                    'response_times': []
                },
                'database_metrics': {
                    'table_stats': {}
                },
                'system_metrics': {
                    'memory_percent': 0,
                    'cpu_percent': 0,
                    'disk_percent': 0
                }
            }

    async def get_trends_data(self) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡è¶‹åŠ¿æ•°æ®"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            # è®¡ç®—7å¤©å’Œ30å¤©å‰çš„æ—¶é—´æˆ³
            now = time.time()
            week_ago = now - (7 * 24 * 3600)
            month_ago = now - (30 * 24 * 3600)
            
            # æ¶ˆæ¯å¢é•¿è¶‹åŠ¿
            await cursor.execute('''
                SELECT 
                    COUNT(CASE WHEN timestamp > ? THEN 1 END) as week_count,
                    COUNT(CASE WHEN timestamp > ? THEN 1 END) as month_count,
                    COUNT(*) as total_count
                FROM raw_messages
            ''', (week_ago, month_ago))
            
            message_stats = await cursor.fetchone()
            if message_stats:
                week_messages = message_stats[0] or 0
                month_messages = message_stats[1] or 0
                total_messages = message_stats[2] or 0
                
                # è®¡ç®—å¢é•¿ç‡
                if month_messages > week_messages:
                    message_growth = ((week_messages * 4 - (month_messages - week_messages)) / (month_messages - week_messages) * 100) if (month_messages - week_messages) > 0 else 0
                else:
                    message_growth = 0
            else:
                message_growth = 0
            
            # ç­›é€‰æ¶ˆæ¯å¢é•¿è¶‹åŠ¿
            await cursor.execute('''
                SELECT 
                    COUNT(CASE WHEN timestamp > ? THEN 1 END) as week_filtered,
                    COUNT(CASE WHEN timestamp > ? THEN 1 END) as month_filtered
                FROM filtered_messages
            ''', (week_ago, month_ago))
            
            filtered_stats = await cursor.fetchone()
            if filtered_stats:
                week_filtered = filtered_stats[0] or 0
                month_filtered = filtered_stats[1] or 0
                
                if month_filtered > week_filtered:
                    filtered_growth = ((week_filtered * 4 - (month_filtered - week_filtered)) / (month_filtered - week_filtered) * 100) if (month_filtered - week_filtered) > 0 else 0
                else:
                    filtered_growth = 0
            else:
                filtered_growth = 0
            
            # LLMè°ƒç”¨å¢é•¿ï¼ˆåŸºäºå­¦ä¹ æ‰¹æ¬¡ï¼‰
            await cursor.execute('''
                SELECT 
                    COUNT(CASE WHEN start_time > ? THEN 1 END) as week_sessions,
                    COUNT(CASE WHEN start_time > ? THEN 1 END) as month_sessions
                FROM learning_batches
            ''', (week_ago, month_ago))
            
            session_stats = await cursor.fetchone()
            if session_stats:
                week_sessions = session_stats[0] or 0
                month_sessions = session_stats[1] or 0
                
                if month_sessions > week_sessions:
                    sessions_growth = ((week_sessions * 4 - (month_sessions - week_sessions)) / (month_sessions - week_sessions) * 100) if (month_sessions - week_sessions) > 0 else 0
                else:
                    sessions_growth = 0
            else:
                sessions_growth = 0
            
            return {
                'message_growth': round(message_growth, 1),
                'filtered_growth': round(filtered_growth, 1),
                'llm_growth': round(sessions_growth, 1),
                'sessions_growth': round(sessions_growth, 1)
            }
            
        except Exception as e:
            self._logger.error(f"è·å–è¶‹åŠ¿æ•°æ®å¤±è´¥: {e}")
            return {
                'message_growth': 0,
                'filtered_growth': 0,
                'llm_growth': 0,
                'sessions_growth': 0
            }

    def _analyze_topic_from_messages(self, messages: List[str]) -> Dict[str, str]:
        """
        åŸºäºæ¶ˆæ¯å†…å®¹æ™ºèƒ½åˆ†æç¾¤èŠä¸»é¢˜
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            åŒ…å«topicå’Œstyleçš„å­—å…¸
        """
        try:
            if not messages:
                return {'topic': 'ç©ºç¾¤èŠ', 'style': 'unknown'}
            
            # åˆå¹¶æ‰€æœ‰æ¶ˆæ¯æ–‡æœ¬
            all_text = ' '.join(messages).lower()
            
            # å®šä¹‰ä¸»é¢˜å…³é”®è¯åº“
            topic_keywords = {
                'æŠ€æœ¯è®¨è®º': ['ä»£ç ', 'ç¼–ç¨‹', 'python', 'java', 'javascript', 'bug', 'ç®—æ³•', 'å¼€å‘', 'å‰ç«¯', 'åç«¯', 'api', 'æ•°æ®åº“', 'sql', 'git', 'é¡¹ç›®', 'éœ€æ±‚', 'æµ‹è¯•', 'éƒ¨ç½²'],
                'æ¸¸æˆå¨±ä¹': ['æ¸¸æˆ', 'ç©å®¶', 'æ”»ç•¥', 'è£…å¤‡', 'å‰¯æœ¬', 'å…¬ä¼š', 'pvp', 'è§’è‰²', 'æŠ€èƒ½', 'ç­‰çº§', 'ç»éªŒ', 'ä»»åŠ¡', 'æ´»åŠ¨', 'å……å€¼', 'æŠ½å¡', 'å¼€é»‘', 'ä¸Šåˆ†'],
                'å­¦ä¹ äº¤æµ': ['å­¦ä¹ ', 'ä½œä¸š', 'è€ƒè¯•', 'å¤ä¹ ', 'ç¬”è®°', 'è¯¾ç¨‹', 'è€å¸ˆ', 'åŒå­¦', 'çŸ¥è¯†', 'é—®é¢˜', 'ç­”æ¡ˆ', 'æ•™ç¨‹', 'èµ„æ–™', 'ä¹¦ç±', 'è®ºæ–‡', 'ç ”ç©¶'],
                'å·¥ä½œåä½œ': ['å·¥ä½œ', 'ä¼šè®®', 'é¡¹ç›®', 'ä»»åŠ¡', 'è¿›åº¦', 'æ±‡æŠ¥', 'å®¢æˆ·', 'åˆä½œ', 'å›¢é˜Ÿ', 'é¢†å¯¼', 'åŒäº‹', 'ä¸šåŠ¡', 'æ–¹æ¡ˆ', 'æ–‡æ¡£', 'æµç¨‹', 'å®¡æ‰¹'],
                'ç”Ÿæ´»æ—¥å¸¸': ['åƒé¥­', 'ç¡è§‰', 'å¤©æ°”', 'å¿ƒæƒ…', 'å®¶äºº', 'æœ‹å‹', 'è´­ç‰©', 'ç”µå½±', 'éŸ³ä¹', 'æ—…æ¸¸', 'ç¾é£Ÿ', 'å¥åº·', 'è¿åŠ¨', 'ä¼‘æ¯', 'å‘¨æœ«'],
                'å…´è¶£çˆ±å¥½': ['æ‘„å½±', 'ç»˜ç”»', 'éŸ³ä¹', 'ç”µå½±', 'ä¹¦ç±', 'æ—…è¡Œ', 'ç¾é£Ÿ', 'è¿åŠ¨', 'å¥èº«', 'ç‘œä¼½', 'è·‘æ­¥', 'éª‘è¡Œ', 'çˆ¬å±±', 'æ¸¸æ³³', 'ç¯®çƒ'],
                'å•†åŠ¡åˆä½œ': ['åˆä½œ', 'å•†åŠ¡', 'ä¸šåŠ¡', 'å®¢æˆ·', 'é¡¹ç›®', 'æ–¹æ¡ˆ', 'æŠ¥ä»·', 'åˆåŒ', 'ä»˜æ¬¾', 'å‘ç¥¨', 'äº§å“', 'æœåŠ¡', 'å¸‚åœº', 'é”€å”®', 'æ¨å¹¿'],
                'æŠ€æœ¯æ”¯æŒ': ['é—®é¢˜', 'æ•…éšœ', 'é”™è¯¯', 'ä¿®å¤', 'è§£å†³', 'å¸®åŠ©', 'æ”¯æŒ', 'æ•™ç¨‹', 'æŒ‡å¯¼', 'æ“ä½œ', 'é…ç½®', 'å®‰è£…', 'æ›´æ–°', 'ç»´æŠ¤', 'ä¼˜åŒ–'],
                'é—²èŠçŒæ°´': ['å“ˆå“ˆ', 'å˜¿å˜¿', 'ğŸ˜‚', 'ğŸ˜„', 'ç¬‘æ­»', 'æœ‰è¶£', 'æ— èŠ', 'éšä¾¿', 'èŠå¤©', 'æ‰¯æ·¡', 'åæ§½', 'æç¬‘', 'æ®µå­', 'è¡¨æƒ…', 'å‘å‘†'],
                'é€šçŸ¥å…¬å‘Š': ['é€šçŸ¥', 'å…¬å‘Š', 'é‡è¦', 'æ³¨æ„', 'æé†’', 'æˆªæ­¢', 'æ—¶é—´', 'å®‰æ’', 'æ´»åŠ¨', 'æŠ¥å', 'å‚åŠ ', 'ä¼šè®®', 'åŸ¹è®­', 'è®²åº§', 'æ´»åŠ¨']
            }
            
            # åˆ†æä¸»é¢˜åŒ¹é…åº¦
            topic_scores = {}
            for topic, keywords in topic_keywords.items():
                score = 0
                for keyword in keywords:
                    score += all_text.count(keyword)
                topic_scores[topic] = score
            
            # è·å–å¾—åˆ†æœ€é«˜çš„ä¸»é¢˜
            best_topic = max(topic_scores.items(), key=lambda x: x[1])
            
            if best_topic[1] == 0:  # æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å…³é”®è¯
                return {'topic': 'ç»¼åˆèŠå¤©', 'style': 'æ—¥å¸¸å¯¹è¯'}
            
            # æ ¹æ®ä¸»é¢˜ç¡®å®šå¯¹è¯é£æ ¼
            style_mapping = {
                'æŠ€æœ¯è®¨è®º': 'æŠ€æœ¯äº¤æµ',
                'æ¸¸æˆå¨±ä¹': 'è½»æ¾å¨±ä¹', 
                'å­¦ä¹ äº¤æµ': 'å­¦æœ¯è®¨è®º',
                'å·¥ä½œåä½œ': 'å·¥ä½œåè°ƒ',
                'ç”Ÿæ´»æ—¥å¸¸': 'æ—¥å¸¸é—²èŠ',
                'å…´è¶£çˆ±å¥½': 'å…´è¶£åˆ†äº«',
                'å•†åŠ¡åˆä½œ': 'å•†åŠ¡æ²Ÿé€š',
                'æŠ€æœ¯æ”¯æŒ': 'æŠ€æœ¯ç­”ç–‘',
                'é—²èŠçŒæ°´': 'è½»æ¾èŠå¤©',
                'é€šçŸ¥å…¬å‘Š': 'ä¿¡æ¯é€šçŸ¥'
            }
            
            topic = best_topic[0]
            style = style_mapping.get(topic, 'æ—¥å¸¸å¯¹è¯')
            
            return {
                'topic': topic,
                'style': style
            }
            
        except Exception as e:
            self._logger.error(f"ä¸»é¢˜åˆ†æå¤±è´¥: {e}")
            return {'topic': 'æœªçŸ¥ä¸»é¢˜', 'style': 'æ—¥å¸¸å¯¹è¯'}

    async def get_recent_learning_batches(self, limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„å­¦ä¹ æ‰¹æ¬¡è®°å½•"""
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()
            
            await cursor.execute('''
                SELECT id, group_id, start_time, end_time, quality_score,
                       processed_messages, batch_name, message_count, 
                       filtered_count, success, error_message
                FROM learning_batches 
                ORDER BY start_time DESC 
                LIMIT ?
            ''', (limit,))
            
            batches = []
            for row in await cursor.fetchall():
                batches.append({
                    'id': row[0],
                    'group_id': row[1],
                    'start_time': row[2],
                    'end_time': row[3],
                    'quality_score': row[4],
                    'processed_messages': row[5],
                    'batch_name': row[6],
                    'message_count': row[7],
                    'filtered_count': row[8],
                    'success': bool(row[9]),
                    'error_message': row[10]
                })
            
            return batches

        except Exception as e:
            self._logger.error(f"è·å–å­¦ä¹ æ‰¹æ¬¡è®°å½•å¤±è´¥: {e}")
            return []

    async def add_persona_learning_review(
        self,
        group_id: str,
        proposed_content: str,
        learning_source: str = "expression_learning",
        confidence_score: float = 0.5,
        raw_analysis: str = "",
        metadata: Dict[str, Any] = None
    ) -> int:
        """æ·»åŠ äººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•

        Args:
            group_id: ç¾¤ç»„ID
            proposed_content: å»ºè®®çš„äººæ ¼å†…å®¹
            learning_source: å­¦ä¹ æ¥æº
            confidence_score: ç½®ä¿¡åº¦åˆ†æ•°
            raw_analysis: åŸå§‹åˆ†æç»“æœ
            metadata: å…ƒæ•°æ®(åŒ…å«features_content, llm_response, sample countsç­‰)

        Returns:
            æ’å…¥è®°å½•çš„ID
        """
        try:
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()

            # ç¡®ä¿è¡¨å­˜åœ¨å¹¶æ·»åŠ metadataåˆ—
            await cursor.execute('''
                CREATE TABLE IF NOT EXISTS persona_update_reviews (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL NOT NULL,
                    group_id TEXT NOT NULL,
                    update_type TEXT NOT NULL,
                    original_content TEXT,
                    new_content TEXT,
                    proposed_content TEXT,
                    confidence_score REAL,
                    reason TEXT,
                    status TEXT NOT NULL DEFAULT 'pending',
                    reviewer_comment TEXT,
                    review_time REAL,
                    metadata TEXT
                )
            ''')

            # å°è¯•æ·»åŠ metadataåˆ—ï¼ˆå¦‚æœè¡¨å·²å­˜åœ¨ä½†æ²¡æœ‰æ­¤åˆ—ï¼‰
            try:
                await cursor.execute('ALTER TABLE persona_update_reviews ADD COLUMN metadata TEXT')
            except:
                pass  # åˆ—å·²å­˜åœ¨

            # å‡†å¤‡å…ƒæ•°æ®JSON
            import json
            metadata_json = json.dumps(metadata if metadata else {}, ensure_ascii=False)

            # æ’å…¥è®°å½•
            await cursor.execute('''
                INSERT INTO persona_update_reviews
                (timestamp, group_id, update_type, original_content, new_content,
                 proposed_content, confidence_score, reason, status, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                time.time(),
                group_id,
                learning_source,  # update_typeå°±æ˜¯learning_source
                "",  # original_contentæš‚æ—¶ä¸ºç©º
                proposed_content,  # new_content
                proposed_content,  # proposed_content
                confidence_score,
                raw_analysis,  # reasonå­—æ®µå­˜å‚¨raw_analysis
                'pending',
                metadata_json
            ))

            await conn.commit()
            record_id = cursor.lastrowid

            self._logger.info(f"æ·»åŠ äººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•æˆåŠŸï¼ŒID: {record_id}, ç¾¤ç»„: {group_id}")
            return record_id

        except Exception as e:
            self._logger.error(f"æ·»åŠ äººæ ¼å­¦ä¹ å®¡æŸ¥è®°å½•å¤±è´¥: {e}")
            raise

    async def get_messages_by_group_and_timerange(
        self,
        group_id: str,
        start_time: float = None,
        end_time: float = None,
        limit: int = 100
    ) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šç¾¤ç»„åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„èŠå¤©è®°å½•

        Args:
            group_id: ç¾¤ç»„ID
            start_time: å¼€å§‹æ—¶é—´æˆ³ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶
            end_time: ç»“æŸæ—¶é—´æˆ³ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶
            limit: è¿”å›æ¶ˆæ¯æ•°é‡é™åˆ¶

        Returns:
            æ¶ˆæ¯è®°å½•åˆ—è¡¨
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()

            try:
                query = '''
                    SELECT id, sender_id, sender_name, message, group_id, platform, timestamp, processed
                    FROM raw_messages
                    WHERE group_id = ?
                '''
                params = [group_id]

                if start_time is not None:
                    query += ' AND timestamp >= ?'
                    params.append(start_time)

                if end_time is not None:
                    query += ' AND timestamp <= ?'
                    params.append(end_time)

                query += ' ORDER BY timestamp DESC LIMIT ?'
                params.append(limit)

                await cursor.execute(query, params)

                messages = []
                for row in await cursor.fetchall():
                    messages.append({
                        'id': row[0],
                        'sender_id': row[1],
                        'sender_name': row[2],
                        'content': row[3],  # å¤–éƒ¨APIä½¿ç”¨ 'content' å­—æ®µå
                        'group_id': row[4],
                        'platform': row[5],
                        'timestamp': row[6],
                        'processed': row[7]
                    })

                self._logger.info(f"ğŸ“– APIæŸ¥è¯¢ç»“æœ: group={group_id}, è¿”å›{len(messages)}æ¡æ¶ˆæ¯, æœ€æ–°timestamp={messages[0]['timestamp'] if messages else 'N/A'}")
                return messages

            except aiosqlite.Error as e:
                self._logger.error(f"è·å–æ—¶é—´èŒƒå›´æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
                return []
            finally:
                await cursor.close()

    async def get_new_messages_since(
        self,
        group_id: str,
        last_message_id: int = None,
        last_timestamp: float = None
    ) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šç¾¤ç»„çš„å¢é‡æ¶ˆæ¯ï¼ˆè‡ªä¸Šæ¬¡è·å–åçš„æ–°æ¶ˆæ¯ï¼‰

        Args:
            group_id: ç¾¤ç»„ID
            last_message_id: ä¸Šæ¬¡è·å–çš„æœ€åä¸€æ¡æ¶ˆæ¯ID
            last_timestamp: ä¸Šæ¬¡è·å–çš„æœ€åä¸€æ¡æ¶ˆæ¯æ—¶é—´æˆ³

        Returns:
            æ–°æ¶ˆæ¯åˆ—è¡¨
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()

            try:
                # ä¼˜å…ˆä½¿ç”¨message_idï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨timestamp
                if last_message_id is not None:
                    query = '''
                        SELECT id, sender_id, sender_name, message, group_id, platform, timestamp, processed
                        FROM raw_messages
                        WHERE group_id = ? AND id > ?
                        ORDER BY timestamp ASC
                    '''
                    params = (group_id, last_message_id)
                elif last_timestamp is not None:
                    query = '''
                        SELECT id, sender_id, sender_name, message, group_id, platform, timestamp, processed
                        FROM raw_messages
                        WHERE group_id = ? AND timestamp > ?
                        ORDER BY timestamp ASC
                    '''
                    params = (group_id, last_timestamp)
                else:
                    # å¦‚æœä¸¤ä¸ªå‚æ•°éƒ½æ²¡æœ‰ï¼Œè¿”å›æœ€è¿‘çš„æ¶ˆæ¯
                    query = '''
                        SELECT id, sender_id, sender_name, message, group_id, platform, timestamp, processed
                        FROM raw_messages
                        WHERE group_id = ?
                        ORDER BY timestamp DESC
                        LIMIT 20
                    '''
                    params = (group_id,)

                await cursor.execute(query, params)

                messages = []
                for row in await cursor.fetchall():
                    messages.append({
                        'id': row[0],
                        'sender_id': row[1],
                        'sender_name': row[2],
                        'content': row[3],  # å¤–éƒ¨APIä½¿ç”¨ 'content' å­—æ®µå
                        'group_id': row[4],
                        'platform': row[5],
                        'timestamp': row[6],
                        'processed': row[7]
                    })

                return messages

            except aiosqlite.Error as e:
                self._logger.error(f"è·å–å¢é‡æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
                return []
            finally:
                await cursor.close()

    async def get_current_topic_summary(self, group_id: str, recent_messages_count: int = 20) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šç¾¤ç»„å½“å‰çš„èŠå¤©è¯é¢˜æ€»ç»“

        ä¼˜å…ˆä»æ•°æ®åº“ä¸­è¯»å–æœ€è¿‘çš„è¯é¢˜æ€»ç»“,å¦‚æœæ²¡æœ‰æˆ–è¿‡æœŸ(è¶…è¿‡30åˆ†é’Ÿ),åˆ™åˆ†ææœ€è¿‘æ¶ˆæ¯ç”Ÿæˆæ–°çš„æ€»ç»“

        Args:
            group_id: ç¾¤ç»„ID
            recent_messages_count: åˆ†æçš„æœ€è¿‘æ¶ˆæ¯æ•°é‡

        Returns:
            è¯é¢˜æ€»ç»“ä¿¡æ¯
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()

            try:
                # é¦–å…ˆå°è¯•ä»æ•°æ®åº“è·å–æœ€è¿‘30åˆ†é’Ÿå†…çš„è¯é¢˜æ€»ç»“
                thirty_minutes_ago = time.time() - 1800
                await cursor.execute('''
                    SELECT topic, summary, participants, message_count,
                           start_timestamp, end_timestamp, generated_at
                    FROM topic_summaries
                    WHERE group_id = ? AND generated_at > ?
                    ORDER BY generated_at DESC
                    LIMIT 1
                ''', (group_id, thirty_minutes_ago))

                cached_summary = await cursor.fetchone()

                if cached_summary:
                    # è¿”å›ç¼“å­˜çš„è¯é¢˜æ€»ç»“
                    import json
                    participants = json.loads(cached_summary[2]) if cached_summary[2] else []

                    return {
                        'group_id': group_id,
                        'topic': cached_summary[0],
                        'summary': cached_summary[1],
                        'participants': participants,
                        'message_count': cached_summary[3],
                        'start_timestamp': cached_summary[4],
                        'latest_timestamp': cached_summary[5],
                        'generated_at': cached_summary[6],
                        'from_cache': True
                    }

                # å¦‚æœæ²¡æœ‰ç¼“å­˜,è·å–æœ€è¿‘çš„æ¶ˆæ¯ç”Ÿæˆæ–°æ€»ç»“
                await cursor.execute('''
                    SELECT message, sender_name, timestamp
                    FROM raw_messages
                    WHERE group_id = ?
                    ORDER BY timestamp DESC
                    LIMIT ?
                ''', (group_id, recent_messages_count))

                messages = []
                latest_timestamp = None
                earliest_timestamp = None
                for row in await cursor.fetchall():
                    messages.append({
                        'message': row[0],
                        'sender_name': row[1],
                        'timestamp': row[2]
                    })
                    if latest_timestamp is None or row[2] > latest_timestamp:
                        latest_timestamp = row[2]
                    if earliest_timestamp is None or row[2] < earliest_timestamp:
                        earliest_timestamp = row[2]

                if not messages:
                    return {
                        'group_id': group_id,
                        'topic': 'æš‚æ— èŠå¤©è®°å½•',
                        'participants': [],
                        'message_count': 0,
                        'latest_timestamp': 0,
                        'summary': 'ç¾¤ç»„æš‚æ— èŠå¤©æ´»åŠ¨',
                        'from_cache': False
                    }

                # ç»Ÿè®¡å‚ä¸è€…
                participants = list(set([msg['sender_name'] for msg in messages]))

                # ä½¿ç”¨å·²æœ‰çš„è¯é¢˜åˆ†ææ–¹æ³•
                messages_text = [msg['message'] for msg in messages]
                topic_analysis = self._analyze_topic_from_messages(messages_text)

                topic_result = {
                    'group_id': group_id,
                    'topic': topic_analysis['topic'],
                    'summary': f"æœ€è¿‘{len(messages)}æ¡æ¶ˆæ¯è®¨è®ºäº†{topic_analysis['topic']},å¯¹è¯é£æ ¼ä¸º{topic_analysis['style']}",
                    'participants': participants,
                    'message_count': len(messages),
                    'start_timestamp': earliest_timestamp,
                    'latest_timestamp': latest_timestamp,
                    'generated_at': time.time(),
                    'recent_messages': messages[:5],  # è¿”å›æœ€è¿‘5æ¡æ¶ˆæ¯å†…å®¹ä¾›å‚è€ƒ
                    'from_cache': False
                }

                # ä¿å­˜åˆ°æ•°æ®åº“ä»¥ä¾›åç»­æŸ¥è¯¢
                # ä¸ç­‰å¾…ä¿å­˜å®Œæˆ,é¿å…é˜»å¡APIå“åº”
                asyncio.create_task(self._save_topic_summary(group_id, topic_result))

                return topic_result

            except aiosqlite.Error as e:
                self._logger.error(f"è·å–è¯é¢˜æ€»ç»“å¤±è´¥: {e}", exc_info=True)
                return {
                    'group_id': group_id,
                    'topic': 'è·å–å¤±è´¥',
                    'participants': [],
                    'message_count': 0,
                    'latest_timestamp': 0,
                    'summary': f'è·å–è¯é¢˜å¤±è´¥: {str(e)}',
                    'from_cache': False
                }
            finally:
                await cursor.close()

    async def _save_topic_summary(self, group_id: str, topic_data: Dict[str, Any]):
        """
        ä¿å­˜è¯é¢˜æ€»ç»“åˆ°æ•°æ®åº“

        Args:
            group_id: ç¾¤ç»„ID
            topic_data: è¯é¢˜æ•°æ®
        """
        try:
            import json
            async with self.get_db_connection() as conn:
                cursor = await conn.cursor()

                await cursor.execute('''
                    INSERT INTO topic_summaries
                    (group_id, topic, summary, participants, message_count,
                     start_timestamp, end_timestamp, generated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    group_id,
                    topic_data.get('topic', ''),
                    topic_data.get('summary', ''),
                    json.dumps(topic_data.get('participants', []), ensure_ascii=False),
                    topic_data.get('message_count', 0),
                    topic_data.get('start_timestamp'),
                    topic_data.get('latest_timestamp'),
                    topic_data.get('generated_at', time.time())
                ))

                await conn.commit()
                await cursor.close()

                self._logger.debug(f"å·²ä¿å­˜ç¾¤ç»„ {group_id} çš„è¯é¢˜æ€»ç»“")

        except Exception as e:
            self._logger.error(f"ä¿å­˜è¯é¢˜æ€»ç»“å¤±è´¥: {e}", exc_info=True)

    def _extract_simple_keywords(self, messages: List[str], max_keywords: int = 10) -> List[str]:
        """
        ç®€å•çš„å…³é”®è¯æå–ï¼ˆåç»­å¯ä»¥ç”¨LLMä¼˜åŒ–ï¼‰

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            max_keywords: æœ€å¤§å…³é”®è¯æ•°é‡

        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        # åˆå¹¶æ‰€æœ‰æ¶ˆæ¯
        text = ' '.join(messages)

        # ç®€å•çš„è¯é¢‘ç»Ÿè®¡ï¼ˆè¿™é‡Œå¯ä»¥ç”¨jiebaç­‰å·¥å…·ä¼˜åŒ–ï¼‰
        import re
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—
        words = re.findall(r'[\u4e00-\u9fa5]+|[a-zA-Z]+', text)

        # ç»Ÿè®¡è¯é¢‘
        word_freq = {}
        for word in words:
            if len(word) >= 2:  # åªç»Ÿè®¡é•¿åº¦>=2çš„è¯
                word_freq[word] = word_freq.get(word, 0) + 1

        # æŒ‰é¢‘ç‡æ’åº
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)

        return [word for word, freq in sorted_words[:max_keywords]]

    async def get_all_expression_patterns(self, group_id: str) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šç¾¤ç»„çš„æ‰€æœ‰è¡¨è¾¾æ¨¡å¼

        Args:
            group_id: ç¾¤ç»„ID

        Returns:
            è¡¨è¾¾æ¨¡å¼åˆ—è¡¨
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()

            try:
                await cursor.execute('''
                    SELECT context, expression, quality_score, last_used_timestamp
                    FROM expression_patterns
                    WHERE group_id = ?
                    ORDER BY quality_score DESC, last_used_timestamp DESC
                ''', (group_id,))

                patterns = []
                for row in await cursor.fetchall():
                    patterns.append({
                        'context': row[0],
                        'expression': row[1],
                        'quality_score': row[2],
                        'last_used_timestamp': row[3]
                    })

                return patterns

            except aiosqlite.Error as e:
                self._logger.error(f"è·å–è¡¨è¾¾æ¨¡å¼å¤±è´¥: {e}", exc_info=True)
                return []
            finally:
                await cursor.close()

    async def get_recent_week_expression_patterns(self, group_id: str, limit: int = 20, hours: int = 168) -> List[Dict[str, Any]]:
        """
        è·å–æœ€è¿‘æŒ‡å®šå°æ—¶å†…å­¦ä¹ åˆ°çš„è¡¨è¾¾æ¨¡å¼ï¼ˆæŒ‰è´¨é‡åˆ†æ•°å’Œæ—¶é—´æ’åºï¼‰

        Args:
            group_id: ç¾¤ç»„ID
            limit: è·å–æ•°é‡é™åˆ¶
            hours: æ—¶é—´èŒƒå›´(å°æ—¶)ï¼Œé»˜è®¤168å°æ—¶(ä¸€å‘¨)

        Returns:
            è¡¨è¾¾æ¨¡å¼åˆ—è¡¨ï¼ŒåŒ…å«åœºæ™¯(situation)å’Œè¡¨è¾¾(expression)
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()

            try:
                # è®¡ç®—æ—¶é—´é˜ˆå€¼
                time_threshold = time.time() - (hours * 3600)

                await cursor.execute('''
                    SELECT situation, expression, weight, last_active_time, create_time
                    FROM expression_patterns
                    WHERE group_id = ? AND last_active_time > ?
                    ORDER BY weight DESC, last_active_time DESC
                    LIMIT ?
                ''', (group_id, time_threshold, limit))

                patterns = []
                for row in await cursor.fetchall():
                    patterns.append({
                        'situation': row[0],  # åœºæ™¯æè¿°
                        'expression': row[1],  # è¡¨è¾¾æ–¹å¼
                        'weight': row[2],  # æƒé‡
                        'last_active_time': row[3],  # æœ€åæ´»è·ƒæ—¶é—´
                        'create_time': row[4]  # åˆ›å»ºæ—¶é—´
                    })

                return patterns

            except aiosqlite.Error as e:
                self._logger.error(f"è·å–æœ€è¿‘ä¸€å‘¨è¡¨è¾¾æ¨¡å¼å¤±è´¥: {e}", exc_info=True)
                return []
            finally:
                await cursor.close()

    async def get_recent_bot_responses(self, group_id: str, limit: int = 10) -> List[str]:
        """
        è·å–Botæœ€è¿‘çš„å›å¤å†…å®¹ï¼ˆç”¨äºåŒè´¨åŒ–åˆ†æï¼‰- ä»bot_messagesè¡¨è¯»å–

        Args:
            group_id: ç¾¤ç»„ID
            limit: è·å–æ•°é‡

        Returns:
            å›å¤å†…å®¹åˆ—è¡¨
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()

            try:
                # ä»bot_messagesè¡¨è¯»å–Botçš„å›å¤
                await cursor.execute('''
                    SELECT message
                    FROM bot_messages
                    WHERE group_id = ?
                    ORDER BY timestamp DESC
                    LIMIT ?
                ''', (group_id, limit))

                responses = []
                for row in await cursor.fetchall():
                    responses.append(row[0])

                return responses

            except aiosqlite.Error as e:
                self._logger.error(f"è·å–Botæœ€è¿‘å›å¤å¤±è´¥: {e}", exc_info=True)
                return []
            finally:
                await cursor.close()

    async def save_bot_message(
        self,
        group_id: str,
        user_id: str,
        message: str,
        response_to_message_id: Optional[int] = None,
        context_type: str = "normal",
        temperature: float = 0.7,
        language_style: Optional[str] = None,
        response_pattern: Optional[str] = None
    ) -> bool:
        """
        ä¿å­˜Botå‘é€çš„æ¶ˆæ¯åˆ°æ•°æ®åº“

        Args:
            group_id: ç¾¤ç»„ID
            user_id: å›å¤çš„ç”¨æˆ·ID
            message: Botçš„å›å¤å†…å®¹
            response_to_message_id: å›å¤çš„æ¶ˆæ¯ID (æ¥è‡ªraw_messagesè¡¨)
            context_type: ä¸Šä¸‹æ–‡ç±»å‹ (normal/creative/preciseç­‰)
            temperature: ä½¿ç”¨çš„temperatureå‚æ•°
            language_style: ä½¿ç”¨çš„è¯­è¨€é£æ ¼
            response_pattern: ä½¿ç”¨çš„å›å¤æ¨¡å¼

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¿å­˜
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()

            try:
                await cursor.execute('''
                    INSERT INTO bot_messages
                    (group_id, user_id, message, response_to_message_id, context_type,
                     temperature, language_style, response_pattern, timestamp)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    group_id,
                    user_id,
                    message,
                    response_to_message_id,
                    context_type,
                    temperature,
                    language_style,
                    response_pattern,
                    time.time()
                ))

                await conn.commit()
                self._logger.debug(f"âœ… Botæ¶ˆæ¯å·²ä¿å­˜: group={group_id}, msg_preview={message[:50]}...")
                return True

            except aiosqlite.Error as e:
                self._logger.error(f"ä¿å­˜Botæ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
                return False
            finally:
                await cursor.close()

    async def get_bot_message_statistics(self, group_id: str, time_range_hours: int = 24) -> Dict[str, Any]:
        """
        è·å–Botæ¶ˆæ¯ç»Ÿè®¡ä¿¡æ¯ (ç”¨äºå¤šæ ·æ€§åˆ†æ)

        Args:
            group_id: ç¾¤ç»„ID
            time_range_hours: ç»Ÿè®¡æ—¶é—´èŒƒå›´(å°æ—¶)

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        async with self.get_db_connection() as conn:
            cursor = await conn.cursor()

            try:
                cutoff_time = time.time() - (time_range_hours * 3600)

                # ç»Ÿè®¡æ¶ˆæ¯æ€»æ•°
                await cursor.execute('''
                    SELECT COUNT(*) as total,
                           AVG(temperature) as avg_temp,
                           COUNT(DISTINCT language_style) as unique_styles,
                           COUNT(DISTINCT response_pattern) as unique_patterns
                    FROM bot_messages
                    WHERE group_id = ? AND timestamp > ?
                ''', (group_id, cutoff_time))

                row = await cursor.fetchone()

                # è·å–æœ€å¸¸ç”¨çš„é£æ ¼å’Œæ¨¡å¼
                await cursor.execute('''
                    SELECT language_style, COUNT(*) as count
                    FROM bot_messages
                    WHERE group_id = ? AND timestamp > ? AND language_style IS NOT NULL
                    GROUP BY language_style
                    ORDER BY count DESC
                    LIMIT 5
                ''', (group_id, cutoff_time))

                top_styles = [{'style': row[0], 'count': row[1]} for row in await cursor.fetchall()]

                await cursor.execute('''
                    SELECT response_pattern, COUNT(*) as count
                    FROM bot_messages
                    WHERE group_id = ? AND timestamp > ? AND response_pattern IS NOT NULL
                    GROUP BY response_pattern
                    ORDER BY count DESC
                    LIMIT 5
                ''', (group_id, cutoff_time))

                top_patterns = [{'pattern': row[0], 'count': row[1]} for row in await cursor.fetchall()]

                return {
                    'total_messages': row[0] if row else 0,
                    'average_temperature': round(row[1], 2) if row and row[1] else 0.7,
                    'unique_styles_count': row[2] if row else 0,
                    'unique_patterns_count': row[3] if row else 0,
                    'top_styles': top_styles,
                    'top_patterns': top_patterns,
                    'time_range_hours': time_range_hours
                }

            except aiosqlite.Error as e:
                self._logger.error(f"è·å–Botæ¶ˆæ¯ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
                return {}
            finally:
                await cursor.close()

